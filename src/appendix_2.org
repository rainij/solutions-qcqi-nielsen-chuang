#+title:  Appendix 2 - Group Theory
#+author: Reinhard Stahn
#+setupfile: ./inc/setupfile.org
#+include: ./inc/latex-macros.org
#+property: header-args:python :session *appendix-2* :tangle appendix_2.py

#+toc: headlines 2

* Exercises
** Exercise A2.11 (Characters)
Prove the following properties of characters on a /finite/ (and complex) matrix group:

1. $\chi(I)=n$,
2. $\abs{\chi(g)}\leq n$,
3. $\abs{\chi(g)} = n \Rightarrow g = e^{i\theta} I$,
4. Characters are constant on conjugacy classes,
5. $\chi(g^{-1}) = \chi(g)^*$ (complex conjugate),
6. $\chi(g)$ is an algebraic number.

*** Proof of (1)
This should be clear since the identity matrix has exactly $n$ ones on the diagonal.

*** Proof of (2)
Recall that the trace is just the sum of all eigenvalues, counted with multiplicity
(exactly $n$ numbers). Let $\lambda$ be one of the eigenvalues and consider a
corresponding eigenvector $v$. Then

$$
  g^a \ket{v} = \lambda^a \ket{v} .
$$

Each element of a finite group has finite order. Hence there is an integer $r$ such that
$g^r=e$ and thus

<<root-of-unity-property>>
$$ \lambda^r=1 $$

holds for any eigenvalue. In particular $|\lambda|=1$. Hence, by the triangle inequality
we get the claim. QED.

*Remark:* The equation [[root-of-unity-property][above]] is a very interesting property. It shows that the [[https://en.wikipedia.org/wiki/Minimal_polynomial_(linear_algebra)][minimal
polynomial]] of an element of a /finite/ matrix group has a very special form. QED.

*** Proof of (3)
This follows from the [[root-of-unity-property][special form]] of the minimal polynomial too, together with the fact
that the triangle inequality is strict iff all summands are colinear.

*** Proof of (4)
We have to show $\chi(h^{-1}gh)=\chi(g)$. This follows from the cyclicity property of the trace:

$$
  \trace{ab} = \sum_{ij} a_{ij} b_{ji} = \sum_{ji} b_{ji} a_{ij} = \trace{ba} .
$$

QED.

*** Proof of (5)
Since we work on vector spaces of /complex/ numbers, the [[https://en.wikipedia.org/wiki/Characteristic_polynomial][characteristic polynomial]] (not
minimal polynomial this time) can be factored into /linear/ polynomials:

$$
  \prod_{i=1}^n (\lambda_i - g) .
$$

This assumes that the eigenvalues (including multiplicities are $\lambda_i$). Multiplying
this by $g^{-n}$ shows that the eigenvalues of $g^{-1}$ are $\lambda_i^{-1}$ (including
multiplicities). Again from the [[root-of-unity-property][minimal polynomial]] we get $\lambda_i^{-1}=\lambda_i^*$
which implies the claim. QED.

*** Proof of (6)
Again by the minimal polynomial the character is just a sum of roots of unity. The latter
are algebraic. According to [[https://en.wikipedia.org/wiki/Algebraic_number#Field][wikipedia]] algebraic numbers form a field (in fact, they are the
algebraic closure of the rational numbers). Hence sums of algebraic numbers are algebraic
too. QED.

** Exercise A2.12 (Unitary matrix groups)
A unitary matrix group is comprised solely of unitary matrices. Show that every finite
matrix group is equivalent to a unitary matrix group. If a representation of a group
consists entirely of unitary matrices, we may refer to it as being a /unitary
representation/.

- Remark ::
  - The solution of exercise A2.11 already shows that finite matrix groups are comprised
    of "very special" matrices which are "almost" unitary (in a sense). So it is nice to
    see an example of a non-unitary matrix group (see below).

*** Example for the remark
An example of a non-unitary matrix group is generated by

$$
  g = \begin{bmatrix} 1 & a \\ 0 & -1 \end{bmatrix} .
$$

Clearly $\langle g \rangle = \{I, g\}$, since $g^2=I$. Moreover $g$ is not unitary for any
$a\neq0$. On the other hand $g$ is diagonalizable (its eigenvalues are $\pm1$).

*** Proof
Let us define the positive semi-definite operator

$$
  p = \sum_{h\in G} h^\dagger h .
$$

This operator is invertible since $\bra{u}p\ket{u} > 0$ for any non-zero vector $u$. By
the functional calculus for hermitian matrices we can uniquely define a positive
semi-definite operator $\sqrt{p}$ whose square is $p$ (if $p$ is already diagonal just
take the square roots of each entry and else apply the spectral theorem first to make it
diagonal). The matrix $\sqrt{p}$ is invertible too.

Now define the mapping $\phi$ as the conjugation with $\sqrt{p}$:

$$
  \phi: g \mapsto \sqrt{p} g \sqrt{p}^{-1}.
$$

It is easy to see that this is an isomorphism of $G$ to some other matrix group
$G'$. Moreover this matrix group is unitary since every $g\in G$ acts as a permutation on
$G$ which implies:

$$
  \phi(g)^\dagger \phi(g) = \sqrt{p}^{-1} g^\dagger p g \sqrt{p}^{-1}
  = \sqrt{p}^{-1} \sum_{h\in G} (hg)^\dagger hg \sqrt{p}^{-1}
  = \sqrt{p}^{-1} p \sqrt{p}^{-1} = I .
$$

Since conjugation preserves the trace (exercise A2.11) we are done. QED.
