#+title:  Appendix 2 - Group Theory
#+author: Reinhard Stahn
#+setupfile: ./inc/setupfile.org
#+include: ./inc/latex-macros.org
#+property: header-args:python :session *appendix-2* :tangle appendix_2.py

#+toc: headlines 2
* COMMENT TODOs
- more complete version of Schur's lemma
- Present the minimal polynomial (FIXME: it is not the /minimal/ polynomial) property
  conclude that character values are sums of $d$ =r=-th roots of unity.
- What about character tables?
- Move the regular representation stuff from A2.17 here.
- Define the scalar product (and refer to Thm A2.4, A2.5)

* Setup
For me /Character Theory/ was rather new when I accountered the appendix for the first
time. I found it hard to learn it from this Appendix so I searched for alternative
resources. I think Chapters 1 and 2 of [cite:@Fulton2004] constitutes a gentle
introduction to the topic. I only skimmed over it, so I am not sure, but what I know is
that this made the topic much clearer to me.

In this section I briefly summarize /how I/ learned the /very basics/ of this nice
theory. I refer to the exercises when appropriate. It duplicates a lot of things from the
[cite:@ChuangNielsen2011]. But in my oppinion certain crucial things are missing from the
book. To make it self contained I decided to repeat certain things.

** Definitions
Let $(G,\cdot,e)$ be a group. A *matrix representation* of $G$ is a homomorphism of groups
$\rho:G\to M$ where $M$ is a group of matrices over some complex vector space $V$ (other
ground fields are possible but we do not care here). Homomorphism just means

$$
  \forall g,h: \rho(gh) = \rho(g)\rho(h) \; \text{ and } \; \rho(g\inv) = \rho(g)\inv
  \; \text{ and } \; \rho(e) = I .
$$

A matrix representation is called *irreducible* if it has no non-trivial invariant
subspaces $W$; non-trivial meaning $W\notin\{0,V\}$. Invariant means
$\rho(g)W\,\subseteq\,W$ for all $g$.

A matrix representation is called *indecomposable* if $\rho$ cannot be written as a direct
sum $\rho_1\oplus\rho_2$ over non-trivial subspaces $V_1\oplus V_2=V$. It is clear that
irreducible matrix groups are also indecomposable. The reverse direction also holds for
finite groups (see [cite:@Fulton2004] Proposition 1.5). The proof is not very difficult
once the fact that representations of finite groups are [[#unitary-representations][equivalent to unitary groups]] is
established.

Let $\rho$ be a finite-dimensional matrix representation over $\CC$. The *character* of
$\rho$ is $\chi_\rho:G\to\CC$ given by:

$$
  \chi_\rho(g) = \trace{\rho(g)} .
$$

The character is called *irreducible* if $\rho$ is irreducible. The *degree* of the
character is the dimension of the vector space.

Characters are a special case of the so called *class functions*, these are functions
$\alpha:G\to\CC$ such that

$$
  \forall g,h: \; \alpha(h^{-1} g h) = \alpha(g) .
$$

For characters this holds due to $\trace{AB}=\trace{BA}$.

Basic properties of characters are proved in [[#exercise-a2-11][exercise A2.11]]. The proof shows that for a
finite group $\chi(g)$ is a sum of $r$​th roots of unity where $r$ is the order of $g$.

Two representations are called *equivalent* if they are isomorphic and the isomorphism
preserves the corresponding characters. A linear map $S:V\to W\in\hom(V,W)$ is called
*G-linear* if

<<G-linear>>
$$
  \forall g: \rho_W(g) \, S = S \, \rho_V(g) .
$$

Let us denote by $\hom(\rho^V,\rho^W)$, or $\hom_G(V,W)$ (G-homomorphisms), the subset of
those homomorphisms between $V$ and $W$ ($\hom(V,W)$) which are G-linear. This makes the
class of representations of $G$ into a [[https://en.wikipedia.org/wiki/Category_(mathematics)][category]].

<<equivalence-G-iso>>
Clearly two representations are equivalent iff there exists a G-isomorphism between them.

[[#schurs-lemma][Schur's Lemma]] will tell us that up to a scalar factor there is at most one non-zero
G-homomorphisms between two irreducible finite dimensional representations, which is an
isomorphism if it exists.

** Unitary Representations
:PROPERTIES:
:CUSTOM_ID: unitary-representations
:END:
A matrix group is called /unitary/ if every matrix is unitary. In [[#exercise-a2-12][exercise A2.12]] it is
shown that every representation of a finite group is equivalent to a unitary
representation. The proof shows that the transformation is essentially a change of scalar
product:

$$
  \rho(g) \mapsto \sqrt{p} \rho(g) \sqrt{p}\inv ,
$$

where $p$ is some suitably chosen positive definite matrix. The technique to obtain $p$
via /averaging/ is standard in Character Theory.
** Constructing new from old representations
Assuming we have a representation on certain vector spaces $V$, $W$ we can construct new
ones like in the following listing. Note that sometimes we write $gv$ instead of
$\rho_V(g)v$ if we are not at risk of ambiguity. Just for this section we briefly allow a
general ground field $\KK$ instead of $\CC$. I think this aids understanding the
construction for dual spaces - in my opinion.

Tensor products $V\otimes W$:

$$ g(v\otimes w) := gv \otimes gw . $$

Direct sums $V\oplus W$:

$$ g(v\oplus w) := gv \oplus gw . $$

Homomorphism spaces $\hom(V, W)$:

$$
  g\phi = g \circ \phi \circ g\inv
$$

Dual spaces $V^*$:

$$
  \rho_{V^*}(g) = \rho_V(g\inv)^\dagger .
$$

The definition for dual spaces is natural since it is a consequence from the natural
requirement to preserve the natural [[https://en.wikipedia.org/wiki/Dual_system][dual pairing]]:

$$ \langle gv^*, gv \rangle_{V^*,V} = \langle v^*, v \rangle_{V^*,V} . $$

The formula for homomorphisms is motivated by $\hom(V,W)=V^*\otimes W$

\begin{align*}
  \rho_{V^*\otimes W}(g) \langle v^*, \cdot \rangle w
    &= \langle \rho_{V^*}(g)v^*, \cdot \rangle \rho_W(g)w \\
    &= \langle \rho_{V}(g\inv)^\dagger v^*, \cdot \rangle \rho_W(g)w \\
    &= \langle v^*, \rho_V(g\inv)(\cdot) \rangle \rho_W(g)w \\
    &= \rho_{\hom(V,W)}(g) \langle v^*, \cdot \rangle w .
\end{align*}

and is consistent with $V^*=\hom(V,\KK)$.

\begin{align*}
  \rho_{\hom(V,\KK)}(g) \langle v^*, \cdot\rangle
    &= \rho_\KK(g) \langle v^*, \rho_V(g\inv)(\cdot)\rangle \\
    &= \langle \rho_V(g\inv)^\dagger v^*, \cdot\rangle \\
    &= \rho_{V^*}(g) \langle v^*, \cdot\rangle .
\end{align*}

Moreover the dual representation behaves well for unitary representations with the natural
identification of the dual space with the Hilbert space itself: $\rho^*=\rho$ in this
case.

** Schur's Lemma
:PROPERTIES:
:CUSTOM_ID: schurs-lemma
:END:
Let $G$ be a group and $\rho_V$, $\rho_W$ two irreducible representations on non-trivial
complex vector spaces $V$ and $W$. Let $S:V\to W$ be a =G=-linear map, the latter meaning:

<<G-linearity>>
$$
  \forall g: \rho_W(g) \, S = S \, \rho_V(g) .
$$

Then either

1. $S=0$ or
2. $S$ is an *isomorphism* of vector spaces.

Moreover, if $\rho_V=\rho_W$ and the vector spaces are finite-dimensional, necessarily
$S=\alpha I$ for some $\alpha\in\CC$. If $\rho_V\neq\rho_W$ are finite-dimensional and
$S_1$, $S_2$ are two isomorphisms as above then each of them is a scalar multiple of the
other one.

- Remarks ::
  - One could weaken the assumptions by replacing $\rho_V(G)$ and $\rho_W(G)$ by any two matrix
    groups $G$ and $H$ which have equal cardinality $I$ and replace the above [[G-linearity][relation]] by
    $g_iS=Sh_i$ for $i\,\in\,I$. The proof below shows this implicitly. In the isomorphism case we
    see that $H$ and $G$ are in fact /equivalent/.
  - Schur's Lemma essentially says that for irreducible representations
    $\hom(\rho^V,\rho^W)$ is zero or one-dimensional. In the latter case the non-zero
    elements are (G-)isomorphisms.

PROOF: Let $N\subseteq V$ and $R\subseteq W$ the kernel (null-space) and image (range) of
$S$. Clearly those are invariant under the respective representations of $G$. By
irreducibility we have:

- $N \in \{0, V\}$,
- $R \in \{0, W\}$.

This leads to four cases two of which are impossible (both zero-space or both full-space) since $V$
and $W$ are non-trivial. The other two cases are:

- $N=\{0\}$ and $R=W$, meaning $S$ being an isomorphism,
- $N=V$ and $R=\{0\}$, meaning $S=0$.

This shows the first part. Now consider the second part where (among other things) $V=W$
is assumed. Since $\CC$ is algebraically closed and the vector spaces are finite
dimensional $S$ must have an eigenvalue $\alpha$. Clearly $S-\alpha$ satisfies the
[[G-linearity][G-linearity]] in place of $S$ too. By the first part and since $S-\alpha$ is no isomorphism
we must have $S=\alpha$.

The final part follows from the second part by considering the G-linear mappings
composed of G-linear mappings from $V$ to $W$ and back from $W$ to $V$. QED.

** Decomposition of representations
Let $V$ be a complex representation of a finite group $G$. Then the vector space $V$
decomposes into irreducible sub-representations

$$
  V = V^{\oplus a_1}_1 \oplus \ldots \oplus V^{\oplus a_n}_n
$$

with distinct (irreducible) $V_i$. Moreover the $V_i$ and the $a_i$ are unique. If the
representation is unitary the decomposition is orthogonal.

- Remarks ::
  - The statment probably holds on compact groups (use Haar measure in proof).
  - What is not unique (in general) is the decomposition of the $V_i^{\oplus a_i}$ into
    $a_i$ copies of $V_i$. In fact, look at the trivial group action of
    $\langle\,\mathrm{id}\rangle$ on $\CC^2$. The /concrete/ decomposition essentially
    amounts to a choice of a basis.

I could not find a proof of the /complete/ statement which I could understand. So I give
my own here.

PROOF: We may assume that the representation is unitary (see [[#unitary-representations][above]]).

If $V$ is not already reducible there must be a non-trivial invariant subspace $U$. Since the
representation is unitary the orthogonal complement $U^\perp$ is invariant too. Hence we have the
decomposition

$$
  V = U \oplus U^{\perp} .
$$

The existence now follows by induction on the dimension of $V$ and the fact that one-dimensional
representations are always irreducible. This concludes the existence part of the proof.

For the uniqueness consider another decomposition

$$
  V = W^{\oplus b_1}_1 \oplus \ldots \oplus W^{\oplus b_m}_m .
$$

Note that the identity induces an isomorphism

$$
  V^{\oplus a_1}_1 \oplus \ldots \oplus V^{\oplus a_n}_n
  \to W^{\oplus b_1}_1 \oplus \ldots \oplus W^{\oplus b_m}_m .
$$

Let us denote by $\hom_G(V,W)$ the G-linear maps between $V$ and $W$. Note that

$$
  \hom_G(V, V) = \bigoplus_{i=1}^n \bigoplus_{j=1}^m
  \hom_G(V_i, W_j)^{\oplus a_i b_j} .
$$

This holds also for $\hom_G$ replaced by $\hom$. In fact, this statement is analogous to
the fact that linear maps between finite dimensional vector spaces can be represented by
matrices.

Now suppose that for some $i$ the $V_i$ is not equivalent to any of the $W_j$. Then this
together with Schur's Lemma implies that $\hom(V,V)=0$ - contradiction. By symmetry this
implies that $n=m$ and $V_i=W_{\pi(i)}$ for some permutation $\pi$. Without loss of
generality $\pi=\mathrm{id}$.

Again by Schur's lemma we thus have $\hom(V_i,W_j)=0$ for $i\neq j$ and hence:

$$
  \hom_G(V, V) = \bigoplus_{i=1}^n
  \hom_G(V_i, W_i)^{\oplus a_i b_i} .
$$

Hence the identity on $V$ induces a G-isomorphism between $V_i^{a_i}$ and $W_i^{b_i}$. Since the
dimensions of $V_i$ and $W_i$ are the same (by equivalence) this implies $a_i=b_i$. QED.

** Class Functions as a Hilbert Space
:PROPERTIES:
:CUSTOM_ID: class-functions-hilbert-space
:END:
Recall that the class functions are constant on all conjugacy classes

$$
  \mathrm{Cl}(a) = \{g a g\inv; g\in G \} .
$$

Hence for a finite group the space of class functions is a $k$ dimensional vector space
where $k$ is the number of different conjugacy classes (the indicator functions of the
single conjugacy classes form a basis).

Using the following scalar product, the vector space turns into a Hilbert Space:

$$
  \langle \alpha, \beta \rangle =
  \frac{1}{\abs{G}} \sum_{g\in G} \alpha(g)^* \beta(g) .
$$

It turns out that the irreducible characters are an orthonormal basis of this Hilbert
Space. This should be shown in [[#exercise-a2-15][exercise A2.15]]. This exercise however bases the proof on a
more difficult result so it does not really help to understand this nice result. For a
direct proof have a look into [cite:@Fulton2004], Chapter 2.2. I recommend to read the
proof, it is really nice. You can also try to find it on your own based on the following
hints:

- The map

  $$
    p = \frac{1}{\abs{G}} \sum_{g\in G} g
  $$

  is a projection from $V$ to $V^G:=\{v\in V; \forall g: gv=v\}$.
- Hence

  $$
    \dim V^G = \chi_V(p) = \frac{1}{\abs{G}} \sum_{g\in G} \chi_V(g) .
  $$
- We have $\hom_G(V,W)=\hom(V,W)^G$.
- If $V$ and $W$ are irreducible by Schur's Lemma we have that $\dim(\hom_G(V,W))$ is
  either $1$ or $0$ depending on whether $V$ and $W$ are isomorphic or not.
- Finally use $\chi_{\hom(V,W)}(g)=\chi_{V^*}(g)\otimes\chi_W(g)=\chi_{V}(g)^*\otimes\chi_W(g)$ to
  deduce the claim.

As a corollary of the above we see that the number of distinct irreducible characters is
equal to the number of conjugacy classes.

* Exercises
** Exercise A2.11 (Characters)
:PROPERTIES:
:CUSTOM_ID: exercise-a2-11
:END:
Prove the following properties of characters on a /finite/ (and complex) matrix group:

1. $\chi(I)=n$,
2. $\abs{\chi(g)}\leq n$,
3. $\abs{\chi(g)} = n \Rightarrow g = e^{i\theta} I$,
4. Characters are constant on conjugacy classes,
5. $\chi(g^{-1}) = \chi(g)^*$ (complex conjugate),
6. $\chi(g)$ is an algebraic number.

*** Proof of (1)
This should be clear since the identity matrix has exactly $n$ ones on the diagonal.

*** Proof of (2)
Recall that the trace is just the sum of all eigenvalues, counted with multiplicity
(exactly $n$ numbers). Let $\lambda$ be one of the eigenvalues and consider a
corresponding eigenvector $v$. Then

$$
  g^a \ket{v} = \lambda^a \ket{v} .
$$

Each element of a finite group has finite order. Hence there is an integer $r$ such that
$g^r=e$ and thus

<<root-of-unity-property>>
$$ \lambda^r=1 $$

holds for any eigenvalue. In particular $|\lambda|=1$. Hence, by the triangle inequality
we get the claim. QED.

*** Proof of (3)
This follows from the [[root-of-unity-property][special form]] of the eigenvalues, together with the fact that the
triangle inequality is strict iff all summands are colinear.

*** Proof of (4)
We have to show $\chi(h^{-1}gh)=\chi(g)$. This follows from the cyclicity property of the trace:

$$
  \trace{ab} = \sum_{ij} a_{ij} b_{ji} = \sum_{ji} b_{ji} a_{ij} = \trace{ba} .
$$

QED.

*** Proof of (5)
Since we work on vector spaces of /complex/ numbers, the [[https://en.wikipedia.org/wiki/Characteristic_polynomial][characteristic polynomial]] can be
factored into /linear/ polynomials:

$$
  \prod_{i=1}^n (\lambda_i - g) .
$$

This assumes that the eigenvalues (including multiplicities) are $\lambda_i$. Multiplying
this by $g^{-n}$ shows that the eigenvalues of $g^{-1}$ are $\lambda_i^{-1}$ (including
multiplicities). From the [[root-of-unity-property][special form]] of the eigenvalues we get
$\lambda_i^{-1}=\lambda_i^*$ which implies the claim. QED.

*** Proof of (6)
Again by the [[root-of-unity-property][special form]] of the eigenvalues the character is just a sum of roots of
unity. The latter are algebraic. According to [[https://en.wikipedia.org/wiki/Algebraic_number#Field][wikipedia]] algebraic numbers form a field (in
fact, they are the algebraic closure of the rational numbers). Hence sums of algebraic
numbers are algebraic too. QED.

** Exercise A2.12 (Unitary matrix groups)
:PROPERTIES:
:CUSTOM_ID: exercise-a2-12
:END:
A unitary matrix group is comprised solely of unitary matrices. Show that every finite
matrix group is equivalent to a unitary matrix group. If a representation of a group
consists entirely of unitary matrices, we may refer to it as being a /unitary
representation/.

*** Example of a non-unitary matrix group
An example of a non-unitary matrix group is generated by

$$
  g = \begin{bmatrix} 1 & a \\ 0 & -1 \end{bmatrix} .
$$

Clearly $\langle g \rangle = \{I, g\}$, since $g^2=I$. Moreover $g$ is not unitary for any
$a\neq0$. On the other hand $g$ is diagonalizable (its eigenvalues are $\pm1$). Note that
the claim of the exercise implies diagonalizability for /any/ representation of a finite
group! In fact, equivalence to a unitary group [[equivalence-G-iso][means]] that there is a G-isomorphism $h$
such that $hgh\inv$ is unitary and hence diagonalizable. But if $hgh\inv$ is
diagonalizable the same is true for $g$.

On the other hand for $a\neq0$ the following is a generator for a faithful representation
of $\ZZ$ which is /not/ diagonalizable (up to a factor the matrix is already in [[https://en.wikipedia.org/wiki/Jordan_normal_form][Jordan
normal form]]):

$$
  g = \begin{bmatrix} 1 & a \\ 0 & 1 \end{bmatrix} .
$$

Thus a conjugation $g\mapsto hgh\inv$ won't make this into a unitary group. Hence /this/
representation is not equivalent to a unitary representation.

*** Proof
Let us define the positive semi-definite operator (identifying group elements with their
matrix representation)

$$
  p = \sum_{h\in G} h^\dagger h .
$$

This operator is invertible since $\bra{u}p\ket{u} > 0$ for any non-zero vector $u$. By
the functional calculus for hermitian matrices we can uniquely define a positive
semi-definite operator $\sqrt{p}$ whose square is $p$ (if $p$ is already diagonal just
take the square roots of each entry and else apply the spectral theorem first to make it
diagonal). The matrix $\sqrt{p}$ is invertible too.

Now define the mapping $\phi$ as the conjugation with $\sqrt{p}$:

$$
  \phi: g \mapsto \sqrt{p} g \sqrt{p}^{-1}.
$$

It is easy to see that this is an isomorphism of $G$ to some other matrix group
$G'$. Moreover this matrix group is unitary since every $g\in G$ acts as a permutation on
$G$ which implies:

$$
  \phi(g)^\dagger \phi(g) = \sqrt{p}^{-1} g^\dagger p g \sqrt{p}^{-1}
  = \sqrt{p}^{-1} \sum_{h\in G} (hg)^\dagger hg \sqrt{p}^{-1}
  = \sqrt{p}^{-1} p \sqrt{p}^{-1} = I .
$$

Since conjugation preserves the trace (exercise A2.11) we are done. QED.

** Exercise A2.13
Show that every irreducible Abelian matrix group is one dimensional.

*** Proof
Let $s$ by an /arbitrary/ element of the group. Since the group is abelian we have:

$$
  g s = s g
$$

for any element $g$. By [[*Schur's Lemma][Schur's Lemma]] we have $s=\alpha_s I$ for some complex number
$\alpha_s$. Since $s$ was arbitrary we have that any element is of this form. A group of
multiples of the identity can clearly only be irreducible if it is one dimensional. QED.

** TODO Exercise A2.14
Prove that if $\rho$ is an irreducible representation of $G$, then $|G|/d_\rho$ is an
integer.

** TODO Exercise A2.15
:PROPERTIES:
:CUSTOM_ID: exercise-a2-15
:END:
Using the Fundamental Theorem, prove that characters are orthogonal, that is:

$$
  \sum_{i=1}^r r_i (\chi_i^p)^* \chi_i^q = \abs{G} \delta_{pq} \quad \text{and} \quad
  \sum_{p=1}^r (\chi_i^p)^* \chi_j^p = \frac{\abs{G}}{r_i} \delta_{ij} ,
$$

where $p$, $q$, and $\delta_{pq}$ have the same meaning as in the theorem, and $\chi_i^p$
is the value the character of the $p$​th irreducible representation takes on the $i$​th
conjugacy class of $G$, and $r_i$ is the size of the $i$​th conjugacy class.

** TODO Exercise A2.16
$S_3$ is the group of permutations of three elements. Suppose we order these as mapping
=123= to: =123=; =231=; =312=; =213=; =132=, and =321=, respectively. Show that

there exist two one-dimensional irreducible representations of $S_3$, one of which is
trivial, and the other of which is =1=, =1=, =1=, =-1=, =−1=, =−1=, corresponding in order
to the six permutations given earlier. Also show that there exists a two-dimensional
irreducible representation, with the matrices

: TODO matrices here

Verify that the representations are orthogonal.

*** Solution

# TODO
#+begin_src python
  arep = [
      Matrix([[1, 0], [0, 1]]),
      Matrix([[-1, -sqrt(3)], [sqrt(3), -1]]) / 2,
      Matrix([[-1, sqrt(3)], [-sqrt(3), -1]]) / 2,
      Matrix([[-1, 0], [0, 1]]),
      Matrix([[1, sqrt(3)], [sqrt(3), -1]]) / 2,
      Matrix([[1, -sqrt(3)], [-sqrt(3), -1]]) / 2
  ]
#+end_src

** Exercise A2.17
Prove that the regular representation is faithful.

*** Proof
This is more or less obvious. In fact, the regular representation $\rho^R$ can be
/identified/ with the vector space $R=\CC^{\oplus G}$ made up of the following formal sums:

$$
  v = \sum_{h \in G} \lambda_h h ,
$$

where $\lambda_h\in\CC$ and $G$ is acts as a basis (so that the $\lambda_h$ are
unique). See also the entry for [[https://en.wikipedia.org/wiki/Free_module][free module]] on wikipedia.  With this definition $\rho^R$
is given by

$$
  \rho^R(g) v = \sum_{h \in G} \lambda_h (gh) .
$$

Clearly this is a homomorphism of groups. It is also an isomorphism since
$\rho^R(g)=\rho^R(e)$ implies $\rho^R(g)e=\rho^R(e)e$ which in turn implies $ge=e$, hence
$g=e$. QED.

** Exercise A2.18
Show that the character of the regular representation is zero except on the representation
of the identity element, for which $\chi^R(I)=\abs{G}$.

*** Proof
We have

$$
  \rho^R(g)_{ij} = \begin{cases} 1 & \text{if } g g_i=g_j \\ 0 & \text{else.} \end{cases}
$$

$g g_i=g_i$ is equivalent to $g=e$. Hence $\rho^R(g)$ has /any/ non-zero entries on
the diagonal iff $g=e$. QED.

** Exercise A2.19
Use Theorem A2.5 to show that the regular representation contains $d_{\rho^p}$ instances
of each irreducible representation $\rho^p$. Thus, if $R$ denotes the regular
representation, and $\hat{G}$ denotes the set of all inequivalent irreducible
representations, then

$$
  \chi_i^R = \sum_{\rho \in \hat{G}} d_\rho \chi_i^\rho .
$$

*** Proof
By Theorem A2.4 (the fundamental theorem) the irreducible representations are an
orthonormal basis of the Hilbert Space of class functions (see [[#class-functions-hilbert-space][here]] too). Hence

$$
  \chi^R = \sum_{\rho\in\hat{G}} c_\rho \chi^\rho
$$

for /some/ $c_\rho\in\CC$. Let us calclute the value of the coefficients:

$$
  c_\rho = \langle \chi^\rho, \chi^R \rangle = \abs{G}\inv \chi^\rho(e)^* \chi^R(e) = d_\rho .
$$

The second equality follows from exercise A2.18 and the third one from exercise
A2.11(1). QED.

** Exercise A2.20
The character of the regular representation is zero except for the conjugacy class
containing $e$ (which is $\{e\}$), the identity element in $G$ (see exercise A2.18). Show,
therefore, that

$$
  \sum_{\rho \in \hat{G}} d_\rho \chi^\rho(g) = \abs{G} \delta_{ge} .
$$

*** Proof
We have

$$
  \sum_{\rho \in \hat{G}} d_\rho \chi^\rho(g)
  = \chi^R(g) = \abs{G} \delta_{ge} .
$$

The first equality follows from exercise A2.19. The second one from exercise A2.18. QED.

** Exercise A2.21
Show that $\sum_{\rho\in\hat{G}}d_\rho^2=\abs{G}$.

*** Proof
We have

$$
  \sum_{\rho\in\hat{G}} d_\rho^2 = \sum_{\rho\in\hat{G}} d_\rho \chi^\rho(e) = \chi^R(e) = \abs{G} .
$$

The first equality follows from exercise A2.11(1), the second from A2.19 and the third
again from A2.11(1). QED.

* References
#+print_bibliography:
