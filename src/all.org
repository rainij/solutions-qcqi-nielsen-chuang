#+title:  Solutions for the bible of Quantum Computation and Quantum Information
#+author: Reinhard Stahn
#+startup: inlineimages nolatexpreview show3levels
#+include: ./inc/latex-macros.org
#+todo: TODO(t) WIP(w) | DONE(d)

#+TOC: headlines 2

* COMMENT TODOs [9/16]
- [X] Write Exercise x.y instead of exercise x.y in headings.
- [X] Remove the numbers from (at least some) headings in the HTML output.
- [X] How to tell the HTML exporter to recognize the latex macros (e.g. for \norm).
- [X] Remove toplevel Heading "quantum bible", Make Parts toplevel.
- [X] move latex_header to separate file
- [X] Use ~qiskit.circuit.Parameter~ ([[https://qiskit.org/documentation/stubs/qiskit.circuit.QuantumCircuit.assign_parameters.html][link]]) to draw some of the circuits.
- [X] Use ~print~ less often in code blocks to not pollute ipython when using ~%run quantum-bible.py~.
- [X] Don't use these "Inline" Appendices. Use ~:exports results~ and so on.
- [X] Setup some nice CSS.
- [ ] Already with just 60 exercises the mathjax on the website takes alot of time. Find a solution
  to this problem.
  - Possible solution: One might split this org file into several org files, e.g. by chapter.
  - Possible solution: Do as here [[http://sporadic.stanford.edu/bump/group/gr2_2.html][fold proofs]].
- [ ] Comment out "Search for circuits" - it might be distracting?
- [ ] Do not replace (most) results of code blocks. If a result is already there do not recompute if
  block was not changed (or similar criterion).
- [ ] Github pages build should use modern emacs (via docker) and not the one which coincidentally
  ships with =ubuntu-latest=. As of writing this, Ubuntu uses Emacs 27.1 (org-mode 9.3). I
  personally use a custom build of Emacs 29. This solves the following problems:
  - Properly support citations via =org-cite= (fortunately we only cite one thing at the moment 😄).
  - Older org modes do not put (svg) images into an =img= HTML-container - this makes them look "different".
- [ ] Should we have some "proof-environment"?
- [ ] I use type annotations only due to its in-IDE benefits. Might make sense to actually set up
  type checking - somehow.
- [ ] We would like to have chapter wise session. On the other hand we also need to share some stuff
  between chapters. Currently I made chapter 4 and chapter but this may be a problem since I
  potentially want to divide the file into several files (not sure though).

* Notation
:PROPERTIES:
:CUSTOM_ID: common-notation
:END:
For two hermitian operators we write:

$$ A \leq B $$

if $\langle\psi|B - A|\psi\rangle \geq 0$ for all $|\psi\rangle$. In the special case that one
operator is just a multiple of the Identity, e.g. $A=aI$, we write:

$$ a \leq B $$

We define the [[https://en.wikipedia.org/wiki/Kronecker_delta][Kronecker delta]] to be

$$
\delta_{ij} = \begin{cases}
  0 & \text{if } i \neq j, \\
  1 & \text{if } i = j. \end{cases}
$$

The /Fourier transform/ is denoted like that:

$$
  \FT \sum_{k=0}^{N-1} x_k |k\rangle = \frac{1}{\sqrt{N}} \sum_{k,j=0}^{N-1} x_k e^{\frac{2\pi\ii}{N}kj} |j\rangle .
$$

* Part I
** Chapter 2
:PROPERTIES:
:header-args:python: :session *chapter-2* :tangle yes :comments link :results silent :exports both
:END:
*** Setup
**** Python Libraries
#+begin_src python
  from itertools import product

  import sympy as sp
  from sympy import Matrix, sqrt
#+end_src

**** Bra-Ket
For convenience we define two functions which map bit-strings to the corresponding bra and ket vectors.

#+begin_src python
  def ket(bits: str) -> Matrix:
      """If bits is a string of '0' and '1' this returns |bits>."""
      vec = [0] * 2**len(bits)
      vec[int(bits, 2)] = 1
      return Matrix(vec)


  def bra(bits: str) -> Matrix:
      """If bits is a string of '0' and '1' this returns <bits|."""
      return ket(bits).H
#+end_src

**** The Trace and the Partial Trace
In the following we define the trace for arbitrary square matrices and the partial trace for square
matrices whose dimension is a power of two. Note that the concept of the partial trace only makes
sense if one can consider the matrix as element of some tensor product (i.e. the dimension is a
product $m_1\cdot m_2\cdot\ldots$). We further restrict to $m_i=2$ to keep the implementation and
the interface simple and since probably nothing else is needed in the context of the book.

#+begin_src python
  def trace(M: Matrix):  # TODO: what is the correct return type?
      """Returns the sum of the diagonal elements. Requires a square matrix."""
      dim = M.shape[0]
      assert dim == M.shape[1], "M must be square"
      result = 0
      for i in range(dim):
          result += M[i, i]
      return result


  def ptrace(M: Matrix, bit_positions: list[int] = None) -> Matrix:
      """Partial Trace. The Matrix must have dimension 2^n. The bit_positions describe which bits
      (from the right) get traced out."""
      dim = M.shape[0]
      assert dim == M.shape[1], "M must be square"
      assert dim.bit_count() == 1, "Dim of M must be 2^n for some n >= 0"
      bit_size = dim.bit_length() - 1
      if bit_positions is not None:
          assert len(bit_positions) > 0, "bit_positions must not be empty"
          assert all(0 <= pos <= bit_size for pos in bit_positions), "Invalid bit_positions"

      if bit_positions is None:  # shortcut
          return Matrix([[trace(M)]])
      if len(bit_positions) == 1 and dim == 2:  # corner case
          return Matrix([[trace(M)]])
      elif len(bit_positions) > 1:
          ps = bit_positions.copy()
          ps.sort()  # IMPORTANT!
          RM = M
          while len(ps) > 0:
              pos = ps.pop()
              RM = ptrace(RM, [pos])
          return RM

      rpos = bit_size - 1 - bit_positions[0]

      mat = [[0]*(dim//2) for _ in range(dim//2)]
      for i, j in product(range(dim//2), range(dim//2)):
          ibits = f"{i:b}".zfill(bit_size - 1)
          jbits = f"{j:b}".zfill(bit_size - 1)
          i0 = int(ibits[:rpos] + "0" + ibits[rpos:], 2)
          i1 = int(ibits[:rpos] + "1" + ibits[rpos:], 2)
          j0 = int(jbits[:rpos] + "0" + jbits[rpos:], 2)
          j1 = int(jbits[:rpos] + "1" + jbits[rpos:], 2)
          mat[i][j] = M[i0, j0] + M[i1, j1]

      return Matrix(mat)
#+end_src

Very simple unit tests:

#+begin_src python
  A = Matrix([[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15]])
  B = Matrix([[8*i + j for j in range(8)] for i in range(8)])

  # Results for bit_positions == [0], in this case it is easy to read out the results from the input
  # matrix. Essentially you only have to to view e.g. A as a Matrix of 2x2 matrices which you replace
  # by their traces.
  A0 = Matrix([[5, 9], [21, 25]])
  B0 = Matrix([[9, 13, 17, 21], [41, 45, 49, 53], [73, 77, 81, 85], [105, 109, 113, 117]])

  # To reduce the case of e.g. bit_positions == [1] to bit_positions == [0] use the fact that
  # permuting the bit pattern like so 'xyz' -> 'zyx' induces a Permutation on the basis vectors which
  # corresponds to a permutation matrix P1. After doing the partial trace we are left with 'zy' and
  # have to permute this back to 'yz' (Matrix P2). In other words we have the identity
  # P2*ptrace(P1*B*P1, [0])*P2 - ptrace(B, [i]). Use sympy.Permutation, sympy.PermutationMatrix, and
  # PermutationMatrix.as_explicit to automate most of the work.
  A1 = Matrix([[10, 12], [18, 20]])
  B1 = Matrix([[18, 20, 26, 28], [34, 36, 42, 44], [82, 84, 90, 92], [98, 100, 106, 108]])
  B2 = Matrix([[36, 38, 40, 42], [52, 54, 56, 58], [68, 70, 72, 74], [84, 86, 88, 90]])

  assert ptrace(A, [0]) == A0, "test ptrace(A, [0])"
  assert ptrace(A, [1]) == A1, "test ptrace(A, [0])"
  assert ptrace(B, [0]) == B0, "test ptrace(B, [0])"
  assert ptrace(B, [1]) == B1, "test ptrace(B, [1])"
  assert ptrace(B, [2]) == B2, "test ptrace(B, [2])"
  assert ptrace(B, [0, 2]) == ptrace(ptrace(B, [2]), [0]), "test ptrace(B, [0, 2])"
  assert ptrace(B, [2, 0]) == ptrace(ptrace(B, [2]), [0]), "test ptrace(B, [2, 0])"
  assert ptrace(B, [0, 1, 2]) == Matrix([[trace(B)]]), "test ptrace(B, [0, 1, 2])"
  assert ptrace(B, [2, 1, 0]) == Matrix([[trace(B)]]), "test ptrace(B, [2, 1, 0])"
#+end_src

*** Exercises
**** Exercise 2.71 (Criterion to decide if a state is mixed or pure)
Let $\rho$ be a density operator. Show that $\trace{\rho^2}\leq1$, with equality if and only if
$\rho$ is a pure state.

***** Proof
By the characterization of density operators (Theorem 2.5) there are $0<p_i\leq 1$ and orthonormal
$\{|\psi_i\rangle\}$ such that:

$$
  \rho = \sum_i p_i |\psi_i\rangle\langle\psi_i| .
$$

Hence:

$$
  \trace{\rho^2} = \trace{ \sum_i p_i^2 |\psi_i\rangle\langle\psi_i| } = \sum_i p_i^2 \leq \sum_i p_i = 1 ,
$$

which proves the first claim. Equality can clearly only hold if for all $i$: $p_i=1$. By the trace
condition this is only possible if there is only one summand in the sum making up $\rho$. This means
that $\rho$ is pure in that case. QED.

**** Exercise 2.72 (Bloch sphere for mixed states)
The Bloch sphere picture for pure states of a single qubit was introduced in Section 1.2. This
description has an important generalization to mixed states as follows.

1. Show that an arbitrary density matrix for a mixed state qubit may be written as

   $$
     \rho = \frac{I + \overrightarrow{r} \cdot \overrightarrow{\sigma} }{2}
   $$

  where $\overrightarrow{r}$ is a real three-dimensional vector such that
   $\norm{\overrightarrow{r}}\leq1$. This vector is known as the Bloch vector for the state
   $\rho$. Conversely any such $\rho$ is also a density operator.
2. What is the Bloch vector representation for the state $\rho=I/2$?
3. Show that a state $\rho$ is pure if and only if $\norm{\overrightarrow{r}}=1$.
4. Show that for pure states the description of the Bloch vector we have given coincides with that
   in Section 1.2.

***** Proof of 1, 3, and 4
The matrix representation of $\rho$ looks as follows:

$$
  \rho = \frac{1}{2} \begin{bmatrix} 1 + z & x - iy \\ x + iy & 1 - z \end{bmatrix}
  = \begin{bmatrix} p & \frac{1}{2}\zeta^* \\ \frac{1}{2}\zeta & q \end{bmatrix} .
$$

Let $r=\norm{\overrightarrow{r}}$. We see that the matrices $D$ which can be represented by $\rho$
are characterized by the above matrix together with the constraints:

$$
  p, q \geq 0,\; \zeta\in\CC \text{ with } p + q = 1 \text{ and } r = (p - q)^2 + |\zeta|^2 \leq 1 .
$$

Now let $|\psi\rangle=e^{i\gamma}(c|0\rangle+e^{i\varphi}s|1\rangle)$ be a pure state ($c=\cos(\theta/2)$ and $s=\sin(\theta/2)$). The
corresponding density matrix is:

$$
  \,|\psi\rangle\langle\psi| = \begin{bmatrix} c^2 & e^{-i\varphi}cs \\ e^{i\varphi}cs & s^2 \end{bmatrix} .
$$

Recall the following trigonometric identities: $\cos\theta=c^2-s^2$ and $\sin\theta=2cs$. This
implies that the above constraint is satisfied. Hence pure states are in $D$. In particular we have
$r=1$ for pure states.

On the other hand the same trigonometric identities also show that the constraint strengthened by
$r=1$ characterizes the pure states. Indeed, the correspondence between the two representations is
given by $x+iy=\zeta=e^{i\varphi}\sin\theta$ and $z=p-q=\cos\theta$. This shows claims 3 and 4 (for
the latter recall that the Bloch-Sphere is parameterized by
$(x,y,z)=(\sin\theta\cos\varphi,\;\sin\theta\sin\varphi,\;\cos\theta)$).

Clearly $D$ is a convex set, hence all density matrices are in $D$. This follows from the fact that
density operators are the (closed) convex hull of the pure states. This shows the original version
of claim 1 (we extended it a bit).

To show the rest of claim 1 it remains to prove that $D$ contains only density operators.

That $D$ contains only hermitian operators with trace=1 is clear. By exercise 4.5 we have
$(\overrightarrow{r} \cdot \overrightarrow{\sigma})^2=\norm{\overrightarrow{r}}^2I$. Since
$\overrightarrow{r} \cdot \overrightarrow{\sigma}$ is hermitian and not a multiple of $I$ we deduce
that it has the two eigenvalues $\pm\norm{\overrightarrow{r}}$. Hence (see [[#common-notation][section on notation]] for
the meaning):

$$
  0 \leq \frac{1 - \norm{\overrightarrow{r}}}{2} \leq \rho \leq  \frac{1 + \norm{\overrightarrow{r}}}{2} \leq 1 .
$$

In particular, $\rho$ is indeed a positive operator. Hence, $\rho$ is a density matrix. This shows
the rest of claim 1.

***** Solution to 2
$I/2$ is represented by $\overrightarrow{r}=(0,0,0)$. It corresponds to the ensemble $\{(1/2,|0\rangle),(1/2,|1\rangle)\}$.

**** Exercise 2.73
Let $\rho$ be a density operator. A minimal ensemble for $\rho$ is an ensemble
$\{(p_i, |\psi_i\rangle)\}$ containing a number of elements equal to the rank of $\rho$. Let
$|\psi\rangle$ be any state in the support of $\rho$ . (The /support/ of a Hermitian operator $A$
is the vector space spanned by the eigenvectors of $A$ with non-zero eigenvalues.) Show that there
is a minimal ensemble for $\rho$ that contains $|\psi\rangle$, and moreover that in any such
ensemble $|\psi\rangle$ must appear with probability

$$
  p = \frac{1}{\langle\psi|\rho^{-1}|\psi\rangle} ,
$$

where $\rho^{-1}$ is defined to be the inverse of $\rho$, when $\rho$ is considered as an operator
acting only on the support of $\rho$. (This definition removes the problem that $\rho$ may not have
an inverse.)

***** Proof
Consider the representation of $\rho$ by its eigenvectors (with non-zero eigenvalues):

$$
  \rho = \sum_{i=1}^n \lambda_i |i\rangle\langle i| .
$$

Since $|\psi\rangle$ is in the support of $\rho$ there are unique complex numbers $v_1,\ldots,v_n$
with:

$$
  \sum_{i=1}^n v_i \sqrt{\lambda_i} |i\rangle \in \RR |\psi\rangle \text{ and } \sum_{i=1}^n |v_i|^2 = 1 .
$$

Now extend these numbers to a unitary matrix $u\in\CC^{n\times n}$ such that $u_{ij}=v_j$ (formally
the existence follows from the Gram-Schmidt procedure). Let

$$
  \sqrt{p_i} |\psi_i\rangle := \sum_{i=1}^n u_{ij} \sqrt{\lambda_j} |j\rangle .
$$

By construction $|\psi\rangle=|\psi_1\rangle$. By Theorem 2.6 (Unitary Freedom in the ensemble for
density matrices) we found an ensemble containing $|\psi\rangle$ so the existence is
established. Conversely, the same Theorem states that any ensemble representing $\rho$ and
satisfying $|\psi_1\rangle=|\psi_1\rangle$ must satisfy the above constraint for a matrix $u$ whose
first row is $v$.

By the above contraint and the spectral theorem we have:

$$
  \sqrt{p_i p_j} \langle\psi_i|\rho^{-1}|\psi_j\rangle
  = \sum_{kl} u_{ik}^\dagger \sqrt{\lambda_k} \langle k| \rho^{-1} u_{jl} \sqrt{\lambda_l} |l\rangle
  = \sum_{k} u_{jk} u_{ki}^* \lambda_k \langle k|\rho^{-1}|k\rangle
  = \delta_{ij} .
$$

Setting $i=j=1$ proves the claim. QED.

*Remark:* The proof shows that each minimal ensemble $(\sqrt{p_i}|\psi_i\rangle)$ is an orthonormal
basis on the support of $\rho$ with respect to the inner product given by
$\langle\varphi|\rho^{-1}|\psi\rangle$.

**** Exercise 2.74
Suppose a composite of systems A and B is in the state $|a\rangle|b\rangle$, where $|a\rangle$ is a
pure state of system A, and $|b\rangle$ is a pure state of system B. Show that the reduced density
operator of system A alone is a pure state.

***** Proof
The joint state is indeed a /simple/ tensor product (i.e. a product state):

$$
  \,|a\rangle |b\rangle = |a\rangle \otimes |b\rangle .
$$

The corresponding density matrix is:

$$
  \rho = |a\rangle\langle a| \otimes |b\rangle\langle b| .
$$

The reduced density operator for A is obtained by taking the partial trace with respect to B:

$$
  \rho_A = \ptrace{B}{\rho} = |a\rangle\langle a|.
$$

This is indeed the pure state $|a\rangle$. QED.

**** Exercise 2.75
For each of the four Bell states, find the reduced density operator for each qubit.

***** Solution
The four Bell States are given by:

$$
  \,|\beta_{xy}\rangle = \frac{1}{\sqrt{2}} \left( |0y\rangle + (-1)^{x} |1\overline{y}\rangle \right) ,
$$

where $\overline{y}$ denotes the negation of $y$. Using $\trace{|i\rangle\langle j|}=\delta_{ij}$ we deduce:

$$
  \ptrace{2}{|\beta_{xy}\rangle} = \frac{1}{2} (|0\rangle\langle0| + |1\rangle\langle1|) = \frac{1}{2} I .
$$

and in the same way:

$$
  \ptrace{1}{|\beta_{xy}\rangle} = \frac{1}{2} (|y\rangle\langle y|
  \,+\, |\overline{y}\rangle\langle\overline{y}|) = \frac{1}{2} I .
$$

So in all 8 cases we get the same result: $I/2$.

*Remark:* We see that knowledge of all partial traces is not sufficient to reconstruct the original
state.

**** Exercise 2.76
Extend the proof of the Schmidt decomposition to the case where A and B may have state spaces of
different dimensionality.

***** Proof
Of course one may reuse the proof from the book by utilizing the general form of the singular value
decompostion for non-square matrices.

Alternatively: Assume wlog $\dim(H_A)\leq\dim(H_B)$. We already have a proof for the case of equal
dimensions hence assume $\dim(H_A)<\dim(H_B)$. Now we extend A by a direct sum with a Hilbert Space
$R$ such that:

$$
  \dim(H_A \oplus R) = \dim(H_B) .
$$

By the already proved special case of the theorem we get a Schmidt-Decomposition on $(H_A\oplus R)\otimes H_B$:

$$
  \,|\psi\rangle = \sum_i \lambda_i \, |i_A\rangle |i_B\rangle .
$$

We have to prove that $|i_A\rangle\in H_A$ for all $i$. Indeed, let $|r\rangle\in R$ and consider:


$$
  \langle i_A|r\rangle = \langle i_A, i_B | r, i_B \rangle = \sum_j \langle j_A, j_B | r, i_B \rangle
  = \langle \psi | r, i_B \rangle = 0 .
$$
This shows the claim. QED.

**** Exercise 2.77
Suppose ABC is a three component quantum system. Show by example that there are quantum states of
such systems which can not be written in the form

$$
  \,|\psi\rangle = \sum_i \lambda_i |i_A, i_B, i_C\rangle
$$

where $\lambda_i$ are real numbers, and $|i_A\rangle$, $|i_B\rangle$, $|i_C\rangle$ are orthonormal
vectors of the respective systems.

***** Proof
Suppose a Schmidt-like decomposition is possible for a state with respect to ABC. Then the reduced
density operators in A, B and C must have the same set of eigenvalues. Hence, to show that such a
decomposition is not possible for a given state it suffices to show that the sets of eigenvalue are
not all equal.

To spare us boring calculations lets introduce a nice function which takes a state vector of a
three-qubit system ABC as input (this is already the simplest case where we can find counter
examples). As output it reports the eigenvalues of the density matrix of each subsystem.

#+name: exercise-2-77-1
#+begin_src python
  def get_eigenvals_of_ABC(state_vector: Matrix):
      """Calculate eigenvals of subsystems of three-qubit system (for Exercise 2.77)."""
      density = state_vector * state_vector.H
      DA = ptrace(density, [1, 2])
      DB = ptrace(density, [0, 2])
      DC = ptrace(density, [0, 1])

      result = ""
      for S, D in [("A", DA), ("B", DB), ("C", DC)]:
          result += f"Eigenvalues in {S}: {D.eigenvals()}.\n"

      return result
#+end_src

The following code-snippit shows that

$$
  \frac{1}{\sqrt{3}} (|000\rangle + |010\rangle + |011\rangle)
$$

cannot be decomposed as required:

#+name: exercise-2-77-2
#+begin_src python :results replace
  get_eigenvals_of_ABC((ket('000') + ket('010') + ket('011')) / sqrt(3))
#+end_src

#+RESULTS: exercise-2-77-2
: Eigenvalues in A: {1/2 - sqrt(5)/6: 1, sqrt(5)/6 + 1/2: 1}.
: Eigenvalues in B: {1/2 - sqrt(5)/6: 1, sqrt(5)/6 + 1/2: 1}.
: Eigenvalues in C: {1: 1, 0: 1}.

**** Exercise 2.78
Prove that a state $|\psi\rangle$ of a composite system AB is a product state if and only if it has
Schmidt number 1. Prove that $|\psi\rangle$ is a product state if and only if $\rho^A$ (and thus
$\rho^B$) are pure states.

***** Proof
A product state is a state which can be represented by a /simple/ tensor product
$|\alpha\rangle\otimes|\beta\rangle$. But this is by definition the same as having Schmidt-Rank 1.

For the second part consider the Schmidt-Decomposition:

$$
  \, |\psi\rangle = \sum_{i=1}^r \lambda_i |i_A\rangle \otimes |i_B\rangle .
$$

Hence the reduced state on system A is (take the partial trace on B):

$$
  \rho^A = \sum_{i=1}^r \lambda_i^2 |i_A\rangle\langle i_A| .
$$

Since $\sum_i\lambda_i^2=1$ and $\lambda_i>0$ this can only be a pure state (a projection operator,
i.e. $\rho^2=\rho$) if $r=1$. This is the same as $|\psi\rangle$ being a product state. QED.

**** Exercise 2.79
Consider a composite system consisting of two qubits. Find the Schmidt decompositions of the states

$$
  \frac{|00\rangle + |11\rangle}{\sqrt{2}}; \quad
  \frac{|00\rangle + |01\rangle +  |10\rangle + |11\rangle}{2}; \quad \text{and} \quad
  \frac{|00\rangle + |01\rangle + |10\rangle}{\sqrt{3}} .
$$

***** Solution
The first state clearly is already represented as Schmidt-Decomposition.

The second term has Schmidt-Decomposition $|+\rangle\otimes|+\rangle$, where
$|+\rangle=(|0\rangle+|1\rangle)/\sqrt{2}$ is "the" positive eigenvector of the Pauli Operator =X=.

For the third one we have to calculate something. The proof of the existence of the
Schmidt-Decomposition gives a procedure to actually calculate it. First let us find the Matrix
$A\in\CC^{2\times2}$ such that:

$$
  \frac{|00\rangle + |01\rangle + |10\rangle}{\sqrt{3}} = \sum_{ij} A_{ij} |i\rangle \otimes |j\rangle .
$$

Clearly the following is the only matrix satisfying the above equation:

$$
  A = \frac{1}{\sqrt{3}} \begin{bmatrix} 1 & 1 \\ 1 & 0 \end{bmatrix} .
$$

We need to find the singular value decomposition of $A$. Since $A$ is hermitian this simplifies to
find the spectral decomposition $A=UDU^\dagger$.

One can use sympy to do this. The eigenvalues are:

$$
  \lambda_{\pm} = \frac{\sqrt{3}}{6} \left( 1 \pm \sqrt{5} \right) .
$$

"The" eigenvectors are:

$$
  \,|\pm_A\rangle = \frac{1}{\sqrt{10 \pm 2\sqrt{5}}} \left((1 \pm \sqrt{5})|0\rangle + 2|1\rangle \right) .
$$

With this we can write down the Schmidt-Decomposition:

$$
  \frac{|00\rangle + |01\rangle + |10\rangle}{\sqrt{3}}
  = \lambda_+ |+_A\rangle|+_A\rangle + \lambda_- |-_A\rangle|-_A\rangle .
$$

Note that the fact that the eigenvectors can be chosen with real entries simplifies things.

**** Exercise 2.80
Suppose $|\psi\rangle$ and $|\varphi\rangle$ are two pure states of a composite quantum system with
components A and B, with identical Schmidt coefficients. Show that there are unitary transformations
$U$ on system A and $V$ on system B such that $|\psi\rangle = (U \otimes V )|\varphi\rangle$.

***** Proof
That $|\psi\rangle$ and $|\varphi\rangle$ have the same Schmidt coefficients means that there are
positive numbers $\lambda_i$ such that

\begin{align*}
  \, |\psi\rangle &= \sum_{i=1}^r \lambda_i |i_{A,\psi}\rangle |i_{B,\psi}\rangle , \\
  \, |\varphi\rangle &= \sum_{i=1}^r \lambda_i |i_{A,\varphi}\rangle |i_{B,\varphi}\rangle ,
\end{align*}

for some orthonormal sets $(|i_{A,\psi}\rangle)$, $(|i_{A,\varphi}\rangle)$, $(|i_{B,\psi}\rangle)$,
$(|i_{B,\varphi}\rangle)$. By the latter fact it is easy to find a unitary $U$ which maps
$|i_{A,\varphi}\rangle$ to $|i_{A,\psi}\rangle$ and similarly a $V$ for the B-system. These two
unitary operators satisfy the claim.

**** Exercise 2.81 (Freedom in purifications)
Let $|AR_1\rangle$ and $|AR_2\rangle$ be two purifications of a state $\rho^A$ to a composite system
AR. Prove that there exists a unitary transformation $U_R$ acting on system R such that

$$
\,|AR_1\rangle = (I_A \otimes U_R ) |AR_2\rangle .
$$

***** Proof
Let

$$
  \rho^A = \sum_{i=1}^r \lambda_i^2 |i_A\rangle\langle i_A|
$$

be a Spectral-Decomposition of $\rho^A$ (in particular all the vectors involved form an orthonormal
set). Without loss of generality we may assume that $|AR_2\rangle$ adheres to the generic
construction from the book, that is

$$
\, |AR_2\rangle = \sum_{i=1}^r |i_A\rangle \otimes |i_R\rangle
$$

with an orthonormal set $(|i_R\rangle)$. A priori the Hilbert Space of $R$ could have dimension
smaller then $r$. But in that case we could simply augment $R$ by some additional dimensions.

Since $|AR_1\rangle$ and $|AR_2\rangle$ are purifications of the same state they have the same
Schmidt Numbers (the $\lambda_i$ from above). From Exercise 2.80 we deduce that there exist
unitary matrices $V_A$ and $V_R$ such that

$$
\,|AR_1\rangle = (V_A \otimes V_R ) |AR_2\rangle .
$$

To simplify notation let us write $V=V_A$. Slightly abusing notation, let us write
$\ptrace{R}{|\psi\rangle}$ when we mean $\ptrace{R}{|\psi\rangle\langle\psi|}$. We have

$$
  \rho^A = \ptrace{R}{|AR_1\rangle} = \ptrace{R}{V\otimes V_R \, |AR_2\rangle} = V^\dagger \rho^A V .
$$

This implies that $V$ leaves the eigenspaces of $\rho^A$ invariant (that is, an eigenvector of some
eigenvalue is mapped to a possibly different eigenvector of the same eigenvalue).

For the moment let us assume that all $\lambda_i$ are equal, that is $\lambda_i=1/r$. Let
$(v_{ij})\in\CC^{r\times r}$ be the matrix representation of $V$ on the eigenspace of $1/r$. We
have:

$$
\, |AR_1\rangle = V \otimes V_R \, |AR_2\rangle = \frac{1}{r} \sum_{ij} v_{ji} |j_A\rangle \otimes V_R|i_R\rangle
  = \frac{1}{r} \sum_{j} |j_A\rangle \otimes \left( \sum_i v_{ji} V_R|i_{R}\rangle \right) .
$$

Let $|j_{R'}\rangle=\sum_{i}v_{ji}V_R|i_{R}\rangle$. These vectors form an orthonormal set
since $(v_{ij})$ is a unitary matrix (and transposed unitary matrices are unitary too) and the
$(|i_R\rangle)$ are orthonormal. Hence there is a unitary matrix $U_R$ such that
$|j_{R'}\rangle=U|j_R\rangle$. This together with the previous equation implies the desired result:

$$
\, |AR_1\rangle = (I_A \otimes U_R) |AR_2\rangle .
$$

The general case follows by decomposing $|AR_1\rangle$ and $|AR_2\rangle$ into direct sums over the
eigenspaces of $\rho^A$ and repeating the above reasoning for each one. Note that in the above
reasoning for the special case the particular value of the trace was unimportant! QED.

**** Exercise 2.82
Suppose $\{p_i , |\psi_i\rangle\}$ is an ensemble of states generating a density matrix $\rho$
for a quantum system A. Introduce a system R with orthonormal basis $|i\rangle$.

1. Show that $\sum_i \sqrt{p_i} |\psi_i\rangle|i\rangle$ is a purification of $\rho$.
2. Suppose we measure R in the basis $(|i\rangle)$, obtaining outcome i. With what probability do we
   obtain the result $i$, and what is the corresponding state of system A?
3. Let $|AR\rangle$ be any purification of $\rho$ to the system AR. Show that there exists an
   orthonormal basis $|i\rangle$ in which R can be measured such that the corresponding
   post-measurement state for system A is $|\psi_i\rangle$ with probability $p_i$.

Remark (which is missing in the book): In sub-exercise 3 one may assume that the space $R$ is large
enough to hold all the $|i\rangle$ even if the purification does not need that many dimensions (two
ensembles always have at least $r$ (rank) members but might have more, see also Theorem 2.6).

***** Proof of 1
This was /essentially/ shown in the book right before Exercise 2.79! In the book it was /implicitly/
assumed that the $|\psi\rangle$ are orthonormal (by using the Schmidt-Decomposition of $\rho$). But
the proof did not use this fact. QED.

***** Proof of 2
Recall that:

$$
  \,|AR\rangle = \sum_i \sqrt{p_i} |\psi_i\rangle |i\rangle .
$$

The measurement of $i$ as viewed from the whole system AR is represented by
$I\otimes|i\rangle\langle i|$ (see Box 2.6). Hence the probability to measure $i$ is:

$$
  p(i) = \langle AR|I\otimes|i\rangle\langle i| AR\rangle = p_i .
$$

The post-measurement state is:

$$
  \frac{1}{p(i)} I\otimes|i\rangle\langle i| AR\rangle = |\psi\rangle|i\rangle .
$$

Restricted to A this is corresponds to $|\psi\rangle$ (note that this does not /directly/ follow
from Postulate 4 but it is easy to show that product state behave nice under decomposition into the
corresponding subsystems). QED.

*Although it is not asked for*, here is the state of R expressed as a density matrix (before measurement):

$$
  \rho^R = \ptrace{A}{|AR\rangle\langle AR|} = \sum_{ij} \sqrt{p_i p_j} \langle\psi_i|\psi_j\rangle |i\rangle\langle i| .
$$

It is nice to verify that the after measurement results restricted to R are consistent with the
above:

$$
  p(i) = p_i = \trace{|i\rangle\langle i| \rho^R} ,
$$

and

$$
\,  |i\rangle = \frac{1}{p_i} |i\rangle\langle i| \rho^R |i\rangle\langle i| .
$$

***** Proof of 3
Unfortunately there is a notation clash here. Let us rename the orthonormal set used in part 1 to
$(|i_0\rangle)$ and the corresponding purified vector to $|AR_0\rangle$. By exercise 2.81 (freedom
of purifications) there is a unitary operator $U_R$ such that:

$$ |AR\rangle = I\otimes U_R \; |AR_0\rangle $$

Hence we may use the basis $(|i\rangle=U_R|i_0\rangle)$ to achieve the desired goal.

But note a subtle issue here: A priori $U_R$ is not necessarily defined on each individual
$|i_0\rangle$. The reason is, that each density operator has ensembles with arbitrary many states
(of course they are all linearly dependent to some $r$ dimensional set due to Theorem 2.6). This
implies that R0 can be arbitrary large if one takes the construction in sub-exercise 1. On the
other hand one can just "add some dimensions" to R if necessary and extend $U_R$ unitarily. QED.

* Part II
** Chapter 4
:PROPERTIES:
:header-args:python: :session *global* :tangle yes :comments link :results silent :exports both
:END:
*** Setup
**** Setup Python Libraries
#+name: setup-chapter-4
#+begin_src python
  from functools import reduce
  from itertools import product
  from typing import Any

  import sympy as sp
  from sympy import cos, exp, I, Matrix, pi, sin, sqrt
  from sympy.physics.quantum import TensorProduct
  from sympy.combinatorics import Permutation as Perm

  import numpy as np
  import numpy.typing as npt

  from qiskit.circuit import QuantumCircuit, Parameter as Param
#+end_src

**** Pauli- and Rotation-Matrices
The Pauli matrices, and some related matrices:

#+name: paulis-and-friends
#+begin_src python
  # The Paulis:
  X = Matrix([[0, 1], [1, 0]])
  Y = Matrix([[0, -I], [I, 0]])
  Z = Matrix([[1, 0], [0, -1]])

  # Identity
  Id = Matrix([[1, 0], [0, 1]])
  # Hadamard Gate
  H = Matrix([[1, 1], [1, -1]]) / sqrt(2)
  # Phase Gate (sqrt(Z))
  S = Matrix([[1, 0], [0, I]])
  # pi/8 Gate
  T = Matrix([[1, 0], [0, exp(pi * I / 4)]])

  # Rotation Operators
  # - Rz: Phase Shift
  # - Rx: "Strange" Rotation
  # - Ry: Real Rotation
  theta = sp.symbols('theta')
  Rz = Matrix([[exp(-I*theta/2), 0], [0, exp(I*theta/2)]])
  Rx = Matrix([[cos(theta/2), -I*sin(theta/2)], [-I*sin(theta/2), cos(theta/2)]])
  Ry = Matrix([[cos(theta/2), -sin(theta/2)], [sin(theta/2), cos(theta/2)]])
#+end_src

The rotation operators correspond to a rotation of angle $\theta$ around the respective axis in the
*Bloch Sphere* (See Exercise 4.6).

#+caption: The Bloch Sphere
#+name: bloch-sphere.svg
#+attr_org: :width 350px
#+attr_html: :style width: 45%
#+attr_html: :title Smite-Meister, CC BY-SA 3.0 <https://creativecommons.org/licenses/by-sa/3.0>, via Wikimedia Commons. Minor Modifications.
[[https://commons.wikimedia.org/wiki/File:Bloch_sphere.svg][file:./images/bloch-sphere.svg]]

**** SWAP - a two-qubit Gate
The =SWAP= Gate takes two qubits and exchanges their state. It is a permutation on the basis vectors:

#+name: swap-gate
#+begin_src python
  SWAP = Matrix([
    [1, 0, 0, 0],
    [0, 0, 1, 0],
    [0, 1, 0, 0],
    [0, 0, 0, 1]
  ])
#+end_src

In particular it maps the product state $|\psi,\varphi\rangle$ to $|\varphi,\psi\rangle$.

**** Controlled Gates
For the definition of the controlled gates we introduce the projections $P_j$ corresponding to the
computational basis. Moreover we generalize the Tensor Product (Kronecker Product on Matrices) to
take more then two argumentes (sympy only allows two arguments, which is not convenient).

#+name: projection-operators
#+begin_src python
  # First define the projections onto the computational basis
  P0 = Matrix([[1, 0], [0, 0]])
  P1 = Matrix([[0, 0], [0, 1]])

  def tprod(A1, *As):
      """Generalize TensorProduct to one and more then two arguments."""
      P = A1
      for A in As:
          P = TensorProduct(P, A)
      return P
#+end_src

The most basic controlled gates are the controlled Pauli Gates on two qubits. The function ~make_CU~
generalizes this construction to arbitrary single-qubit gates on arbitrary many wires:

#+name: controlled-pauli-gates
#+begin_src python
  # controlled X (NOT), Y, and Z gates
  CX = tprod(P0, Id) + tprod(P1, X)
  CY = tprod(P0, Id) + tprod(P1, Y)
  CZ = tprod(P0, Id) + tprod(P1, Z)


  def make_CU(num_wires: int, control: int, target: int, U: Matrix) -> Matrix:
      """Returns a controlled U Gate. U must be single qubit gate. Wires are
      numbered 0 to num_wires - 1."""
      assert 0 <= control < num_wires, "control out of range"
      assert 0 <= target < num_wires, "target out of range"
      assert control != target, "target must differ from control"
      assert U.rows == U.cols == 2, "U must be single-qubit gate"

      t0 = [Id]*num_wires
      t1 = [Id]*num_wires

      t0[control] = P0
      t1[control] = P1
      t1[target] = U

      return tprod(*t0) + tprod(*t1)
#+end_src

There are a few straightforward ways to generalize the above defined simple controlled gates.

- One can allow for multiple controls ($C^nU$ gates). One instance is the /Toffoli Gate/ aka $CCX$
  aka $C^2X$.
- Normally, e.g. $C^3X$ is "activated" by the bit pattern =111=. One can generalize this to let a
  different bit pattern, like =101=, activate it.
- One can also allow for $U$ to be a multi-qubit gate (multiple targets). In general this requires
  to specify how to wire the targets into $U$ (in which order) but for some examples like the
  /Fredkin Gate/ (aka =CSWAP=) this is an irrelevant question since the =SWAP= gate is symmetric in
  its inputs.

#+name: other-controlled-gates
#+begin_src python
  # Toffoli Gate aka CCX
  Toff = tprod(P0, P0, Id) + tprod(P0, P1, Id) + tprod(P1, P0, Id) + tprod(P1, P1, X)

  # Fredkin Gate aka CSWAP
  Fred = tprod(P0, Id, Id) + tprod(P1, SWAP)
#+end_src

Since we need them sometimes, in the following we define a factory for controlled gates with multiple controls.

#+name: make-CnU-gates
#+begin_src python
  def make_CnU(num_wires: int, controls: list[int], target: int, U: Matrix) -> Matrix:
      """Generalization of make_CU to several controls."""
      assert all([0 <= c < num_wires for c in controls]), "controls out of range"
      assert 0 <= target < num_wires, "target out of range"
      assert all([c != target for c in controls]), "target must differ from controls"
      assert U.rows == U.cols == 2, "U must be single-qubit gate"

      P = [P0, P1]

      CnU = None
      ts = []
      for bitlist in product(*[[0, 1]]*len(controls)):
          t = [Id]*num_wires

          for i, bit in enumerate(bitlist):
              t[controls[i]] = P[bit]

          ts.append(t)
      ts[-1][target] = U

      tensors = [tprod(*t) for t in ts]
      CnU = None
      for tensor in tensors:
          CnU = tensor if CnU is None else CnU + tensor

      return CnU
#+end_src

Some very simple Unit Tests:

#+name: unit-tests-for-controlled-gates
#+begin_src python
  assert make_CU(2, 0, 1, X) == CX, "Expected CX Gate (1)"
  assert make_CU(3, 1, 2, X) == tprod(Id, CX), "Expected CX Gate (2)"

  assert make_CnU(3, [0, 1], 2, X) == Toff, "Expected Toffoli Gate (1)"
  assert make_CnU(4, [1, 2], 3, X) == tprod(Id, Toff), "Expected Toffoli Gate (2)"
#+end_src

**** Two-Level Gates
Two-Level gates are gates which act non-trivially only on two base vectors (computational
base). They are a direct generalization of /fully controlled/ single-qubit gates, whose two base
vectors must additionally satisfy the property that the bit-representation of their index must be
equal up to a single bit-flip.

In the following we provide a utility function to quickly generate a two-level matrix. It is
designed to work well together with the procedure to decompose general matrices into two-level
matrices outlined in chapter 4.5.1 of the book.

#+name: make-two-level-gates
#+begin_src python
  def make_twolevel(dim: int, indices: list[int], row: list) -> Matrix:
      """Make a two level unitary matrix essentially by giving an unnormalized row.

      Let i,j=indices, a,b=row, n=norm((a,b)). The resulting unitary matrix U satisfies
      (U_{ii},U_{ij}=(a,b)/n if i<j, else (U_{ij},U_{ii}=(a,b)/n. The other is derived from
      conjugation, like that (a,b) -> (-b*,a*).
      """
      assert len(indices) == len(row) == 2, "Expected only two indices/rows."
      assert all([0 <= i < dim for i in indices]), "Indices out of range."
      i, j = indices
      assert i != j, "Indices must not be equal."
      i1, j1 = sorted([i, j])

      U = [[1 if i == j else 0 for j in range(dim)] for i in range(dim)]

      norm = sqrt(row[0]*row[0].conjugate() + row[1]*row[1].conjugate())
      r0, r1 = row[0]/norm, row[1]/norm

      U[i][i1], U[i][j1] = r0, r1
      U[j][i1], U[j][j1] = -r1.conjugate(), r0.conjugate()

      return Matrix(U)


  def make_onelevel(dim: int, index: int, factor) -> Matrix:
    """Make a diagonal matrix with `factor` at position `index`."""
    U = [[1 if i == j else 0 for j in range(dim)] for i in range(dim)]
    U[index][index] = factor
    return Matrix(U)
#+end_src

The following tests also illustrate how the function works. Take the first test as an example. The
first index, which is 1 in test 1, determines in which row we put ~[4,3]~. The columns are specified
by the /sorted/ indices: 0 and 1. Then the corresponding "conjugate row" is inserted and finally we
normalize.

#+name: test-two-level-gates
#+begin_src python
  assert make_twolevel(4, [1,0], [3, 4]) == Matrix([
      [-4, 3, 0, 0],
      [ 3, 4, 0, 0],
      [ 0, 0, 5, 0],
      [ 0, 0, 0, 5]]) / 5, "test: make_twolevel 1"
  assert make_twolevel(4, [2,1], [3, 4*I]) == Matrix([
      [5,   0,   0, 0],
      [0, 4*I,   3, 0],
      [0,   3, 4*I, 0],
      [0,   0,   0, 5]]) / 5, "test: make_twolevel 2"
#+end_src

**** The Search for Circuits
In the following we document some /very basic/ approaches to find circuits consisting of
(relatively) simple gates to construct more complex gates.

The simplest non-trivial test case is to find the construction of $C^2U$ by a circuit consisting
only of controlled $X$, $V$, and $V^\dagger$, where $V$ is unitary with $V^2=U$. That is, we want to
find the construction from Figure 4.8 by exhausive search.

Possible Approaches (checkbox means that it is tried out within this document):
- [X] via sympy directly on matrices
- [X] via numpy (on matrices)
- [ ] via sympy but replacing matrices by permutations (in the spirit of the solution to exercise 4.27).
- [ ] outside python to avoid slow loops

***** Approach 1: via Sympy - Don't do this!
Here I document the approach via Sympy. This is not really a feasable approach since Matrix
Multiplication in Sympy is *extremely* slow. Of course this is not entirely unexpected since sympy
is not meant to be used in a brute force environment.

In fact, finding the circuit of Figure 4.8 via brute force is out of reach for this approach. It
can't be done within "reasonable" time limits. Going through all combinations of *just two gates*
(just 25=5*5 cases for the five admissible gates) already takes one second. For three gates the
number raises to almost nine seconds. So several minutes are to be expected in case of five gates. I
count this as "unreasonable" since this is still a very small problem.

*Conclusion:* Do not use sympy to calculate lots of matrix products.

****** The search routine
Just for completeness here is the code:

#+name: search-for-circuits-approach-via-sympy
#+begin_src python
  def make_all_CU(num_wires: int, U: Matrix, name: str, pred=None) -> list[Any]:
      """Generate all CU gates, whose control/target wires satisfy an optional predicate."""
      if pred is None:
          pred = (lambda c, t: True)

      # All possible combinations of (control, target).
      all_cts = list(product(range(num_wires), range(num_wires)))
      all_cts = [(c, t) for (c, t) in all_cts if c != t and pred(c, t)]

      gates = []
      for c, t in all_cts:
          gate = make_CU(num_wires, c, t, U)
          gates.append(dict(  # The output is a list of dicts
              name=name,
              ct=(c, t),
              gate=gate,
          ))

      return gates


  def sp_search_circuits(n: int, admissible_gates: list[Matrix], Wanted_Gate: Matrix) -> str:
      """Find all circuits with n gates implementing Wanted_Gate."""
      solutions = []
      for gates in product(*([admissible_gates]*n)):
          gs = [g["gate"] for g in gates]
          prod = reduce((lambda x, y: x*y), gs)
          if sp.simplify(prod) == Wanted_Gate:  # wanted gate should already be simplified
              solutions.append(" * ".join([f"{g['name']}{g['ct']}" for g in gates]))
      return solutions
#+end_src

****** Testing the search routine
Here we try it out. You can use ipython magic function ~%time~ to measure how slow this approach is.

#+name: search-for-circuits-approach-via-sympy-tests
#+begin_src python
  V = Matrix([[1 - I, 1 + I], [1 + I, 1 - I]]) / 2
  assert sp.simplify(V*V) == X, "Exercise 28: V must be sqrt(X)."


  def make_pred_CX(num_wires):
      def pred_CX(c, t):
          return c < t and t < num_wires - 1
      return pred_CX


  def make_pred_CV(num_wires: int):
      def pred_CV(c, t):
          return c < t and t == num_wires - 1
      return pred_CV


  adm_CX = make_all_CU(3, X, "CX", make_pred_CX(3))
  adm_CV = make_all_CU(3, V, "CV", make_pred_CV(3))
  adm_CVh = make_all_CU(3, V.H, "CVh", make_pred_CV(3))

  admissible_gates = adm_CX + adm_CV + adm_CVh

  CX01 = make_CU(3, 0, 1, X)
  CX02 = make_CU(3, 0, 2, X)
  CV02 = make_CU(3, 0, 2, V)
  assert sp_search_circuits(1, admissible_gates, CX01) == ['CX(0, 1)'], "sp_search_circuits: CX01"
  assert sp_search_circuits(1, admissible_gates, CV02) == ['CV(0, 2)'], "sp_search_circuits: CV02"
  # We comment this out since it takes about a second:
  # result = sorted(['CX(0, 1) * CV(0, 2)', 'CV(0, 2) * CX(0, 1)'])
  # assert sorted(sp_search_circuits(2, admissible_gates, CX01 * CV02)) == result, "sp_search_circuits: CX01 * CV02"
#+end_src

***** Approach 2: via Numpy
*IMPORTANT:* Complex numbers in numpy are always implemented via floats. To avoid the typical
floating point arithmetic issues we assume that all numbers are either integrals or more generally
multiples of some ~2**(-n)~. In that case floating point arithmetic is exact (up to overflow).

****** Reimplement some basic auxiliary functions for numpy
First we have to reimplement some functions we already use at the sympy side:

#+name: numpy-make-controlled-gates
#+begin_src python
  def np_kron(A1: npt.ArrayLike, *As: list[npt.ArrayLike]) -> np.ndarray:
      """Generalize TensorProduct to one and more then two arguments."""
      P = A1
      for A in As:
          P = np.kron(P, A)
      return P


  def np_make_CU(num_wires: int, control: int, target: int, U: np.ndarray) -> np.ndarray:
      """Returns a controlled U Gate. U must be single qubit gate. Wires are
      numbered 0 to num_wires - 1."""
      assert 0 <= control < num_wires, "control out of range"
      assert 0 <= target < num_wires, "target out of range"
      assert control != target, "target must differ from control"
      assert U.shape == (2, 2), "U must be single-qubit gate"

      t0 = [np_Id]*num_wires
      t1 = [np_Id]*num_wires

      t0[control] = np_P0
      t1[control] = np_P1
      t1[target] = U

      return np_kron(*t0) + np_kron(*t1)


  def np_make_CnU(num_wires: int, controls: list[int], target: int, U: np.ndarray) -> np.ndarray:
      """Generalization of make_CU to several controls."""
      assert all([0 <= c < num_wires for c in controls]), "controls out of range"
      assert 0 <= target < num_wires, "target out of range"
      assert all([c != target for c in controls]), "target must differ from controls"
      assert U.shape == (2, 2), "U must be single-qubit gate"

      P = [np_P0, np_P1]

      CnU = None
      ts = []
      for bitlist in product(*[[0, 1]]*len(controls)):
          t = [np_Id]*num_wires

          for i, bit in enumerate(bitlist):
              t[controls[i]] = P[bit]

          ts.append(t)
      ts[-1][target] = U

      tensors = [np_kron(*t) for t in ts]
      CnU = None
      for tensor in tensors:
          CnU = tensor if CnU is None else CnU + tensor

      return CnU
#+end_src

****** Implementation of the search routine
Now we can implement the search routine:

#+begin_src python
  def np_make_all_CU(num_wires: int, U: Matrix, name: str, pred=None) -> list[Any]:
      if pred is None:
          pred = (lambda c, t: True)

      pairs = list(product(range(num_wires), range(num_wires)))
      pairs = [(c, t) for (c, t) in pairs if c != t and pred(c, t)]

      gates = []
      for c, t in pairs:
          gate = np_make_CU(num_wires, c, t, U)
          gates.append(dict(
              name=name,
              ct=(c, t),
              gate=gate,
          ))

      return gates


  def np_make_all_C2U(num_wires: int, U: np.ndarray, name: str, pred=None) -> list[Any]:
      if pred is None:
          pred = (lambda c, t: True)

      triples = list(product(*([range(num_wires)]*3)))
      triples = [(c0, c1, t) for (c0, c1, t) in triples if c0 < c1 and c0 != t and c1 != t and pred((c0, c1), t)]

      gates = []
      for c0, c1, t in triples:
          gate = np_make_CnU(num_wires, [c0, c1], t, U)
          gates.append(dict(
              name=name,
              ct=((c0, c1), t),
              gate=gate,
          ))

      return gates


  def np_search_circuit(n: int, admissible_gates: list[np.ndarray], Wanted_Gate: np.ndarray) -> str:
      """Find all solutions to exercise 4.28 with n gates."""
      solutions = []
      for gates in product(*([admissible_gates]*n)):
          gs = [g["gate"] for g in gates]
          prod = reduce((lambda x, y: x @ y), gs)
          if np.alltrue(prod == Wanted_Gate):
              solutions.append(" @ ".join([f"{g['name']}{g['ct']}" for g in gates]))
      return solutions


  def make_pred_CX(num_wires):
      def pred_CX(c, t):
          return c < t and t < num_wires - 1
      return pred_CX


  def make_pred_CV(num_wires: int):
      def pred_CV(c, t):
          return c < t and t == num_wires - 1
      return pred_CV


  def make_pred_CCX(num_wires: int):
      def pred_CCX(c, t):
          return c[0] < t and c[1] < t and t < num_wires - 1
      return pred_CCX
#+end_src

****** Pauli Matrices (and friends) for numpy
Now let us redefine the Pauli Matrices within numpy:

#+name: numpy-paul-matrices
#+begin_src python
  np_X = np.array([[0, 1], [1, 0]])
  np_Y = np.array([[0, -1j], [1j, 0]])
  np_Z = np.array([[1, 0], [0, -1]])

  np_Id = np.eye(2)
  np_P0 = np.array([[1, 0], [0, 0]])
  np_P1 = np.array([[0, 0], [0, 1]])

  # Half-integral-numbers should be OK too since floats are binary
  np_V = np.array([[1 - 1j, 1 + 1j], [1 + 1j, 1 - 1j]]) / 2
  np_Vt = np_V.conj().T
  assert np.alltrue(np_V @ np_V == np_X), "np_V must be sqrt(np_X)."
#+end_src

****** Basic Unit Tests
Very simple unit tests:

#+name: numpy-unit-tests-for-search-circuit
#+begin_src python
  np_adm_CX = np_make_all_CU(3, np_X, "CX", make_pred_CX(3))
  np_adm_CV = np_make_all_CU(3, np_V, "CV", make_pred_CV(3))
  np_adm_CVh = np_make_all_CU(3, np_Vt, "CVh", make_pred_CV(3))

  np_admissible_gates = np_adm_CX + np_adm_CV + np_adm_CVh

  # For convenience:
  def shorten_admissible_gates(admissible_gates):
      return [dict(name=ag["name"], ct=ag["ct"]) for ag in admissible_gates]


  np_CX01 = np_make_CU(3, 0, 1, np_X)
  np_CX02 = np_make_CU(3, 0, 2, np_X)
  np_CV02 = np_make_CU(3, 0, 2, np_V)
  np_CVt02 = np_make_CU(3, 0, 2, np_Vt)
  assert np_search_circuit(1, np_admissible_gates, np_CX01) == ['CX(0, 1)'], "np_search_circuit: CX01"
  assert sorted(np_search_circuit(1, np_admissible_gates, np_CV02)) == ['CV(0, 2)'], "np_search_circuit: CV02"
  result = sorted(['CX(0, 1) @ CV(0, 2)', 'CV(0, 2) @ CX(0, 1)'])
  assert sorted(np_search_circuit(2, np_admissible_gates, np_CX01 @ np_CV02)) == result, "np_search_circuit: CX01 @ CV02"
#+end_src

****** Find all minimal implementations of the Toffoli Gate
Finally we can actually search for all realizations of the Toffoli Gate (=CCX=):

#+name: numpy-search-toffoli
#+begin_src python
  np_Toff = np.array(Toff)

  # we deactivate the code since it takes around 10 seconds to execute
  if False:
      np_search_circuit(5, np_admissible_gates, np_Toff)
  # Produces among 19 others the solution from the book:
  # 'CV(0, 2) @ CX(0, 1) @ CVt(1, 2) @ CX(0, 1) @ CV(1, 2)',
#+end_src

We obtain 20 solutions using exactly 5 gates to represent the Toffoli (with less gates it is not possible):

#+begin_example
CX(0, 1) @ CV(0, 2) @ CVh(1, 2) @ CX(0, 1) @ CV(1, 2)
CX(0, 1) @ CV(1, 2) @ CX(0, 1) @ CVh(0, 2) @ CVh(1, 2)
CX(0, 1) @ CV(1, 2) @ CX(0, 1) @ CVh(1, 2) @ CVh(0, 2)
CX(0, 1) @ CV(1, 2) @ CVh(0, 2) @ CX(0, 1) @ CVh(1, 2)
CX(0, 1) @ CVh(0, 2) @ CV(1, 2) @ CX(0, 1) @ CVh(1, 2)
CX(0, 1) @ CVh(1, 2) @ CX(0, 1) @ CV(0, 2) @ CV(1, 2)
CX(0, 1) @ CVh(1, 2) @ CX(0, 1) @ CV(1, 2) @ CV(0, 2)
CX(0, 1) @ CVh(1, 2) @ CV(0, 2) @ CX(0, 1) @ CV(1, 2)
CV(0, 2) @ CX(0, 1) @ CVh(1, 2) @ CX(0, 1) @ CV(1, 2)
CV(0, 2) @ CV(1, 2) @ CX(0, 1) @ CVh(1, 2) @ CX(0, 1)
CV(1, 2) @ CX(0, 1) @ CV(0, 2) @ CVh(1, 2) @ CX(0, 1)
CV(1, 2) @ CX(0, 1) @ CVh(1, 2) @ CX(0, 1) @ CV(0, 2)
CV(1, 2) @ CX(0, 1) @ CVh(1, 2) @ CV(0, 2) @ CX(0, 1)
CV(1, 2) @ CV(0, 2) @ CX(0, 1) @ CVh(1, 2) @ CX(0, 1)
CVh(0, 2) @ CX(0, 1) @ CV(1, 2) @ CX(0, 1) @ CVh(1, 2)
CVh(0, 2) @ CVh(1, 2) @ CX(0, 1) @ CV(1, 2) @ CX(0, 1)
CVh(1, 2) @ CX(0, 1) @ CV(1, 2) @ CX(0, 1) @ CVh(0, 2)
CVh(1, 2) @ CX(0, 1) @ CV(1, 2) @ CVh(0, 2) @ CX(0, 1)
CVh(1, 2) @ CX(0, 1) @ CVh(0, 2) @ CV(1, 2) @ CX(0, 1)
CVh(1, 2) @ CVh(0, 2) @ CX(0, 1) @ CV(1, 2) @ CX(0, 1)
#+end_example

*** Exercises
**** Exercise 4.1
In Exercise 2.11, which you should do now if you haven’t already done it, you computed the
eigenvectors of the Pauli matrices. Find the points on the Bloch sphere which correspond to the
normalized eigenvectors of the different Pauli matrices.

***** Solution
The eigenvalues are $\pm1$ for all Pauli matrices. The eigenvectors (tip: ~Z.eigenvects()~) are:

| Pauli | Eigenvector for $+1$                     | Eigenvector for $-1$                      |
|-------+------------------------------------------+-------------------------------------------|
| Z     | $\vert0\rangle$                          | $\vert1\rangle$                           |
| X     | $2^{-1/2}(\vert0\rangle+\vert1\rangle)$  | $2^{-1/2}(\vert0\rangle-\vert1\rangle)$   |
| Y     | $2^{-1/2}(i\vert0\rangle-\vert1\rangle)$ | $2^{-1/2}(-\vert0\rangle+i\vert1\rangle)$  |

Recall the correspondence between the state vector and the parameterization of the Bloch Sphere:

\begin{align*}
  ​|\psi\rangle &= \cos\left(\theta /2\right) |0 \rangle \, + \, e^{i\varphi}  \sin\left(\theta /2\right) |1\rangle
  \quad \text{ for } 0 \leq \theta \leq \pi \text{ and } 0 \leq \varphi \leq 2\pi \\
  &=: c |0\rangle + e^{i\varphi} s |1\rangle
\end{align*}

and (using $\sin\theta=2sc$, $\cos\theta=c^2-s^2$)

\begin{align*}
  (x, y, z) &= (\sin\theta \cos\varphi,\; \sin\theta \sin\varphi,\; \cos\theta) \\
  &= (2sc\cdot\cos\varphi,\; 2sc\cdot\sin\varphi,\; c^2 - s^2) .
\end{align*}

From this it is not hard to see that the $+1$ eigenvectors of =X=, =Y=, =Z= correspond to $\hat{x}$,
$\hat{y}$, $\hat{z}$. The $-1$ eigenvectors correspond to $-\hat{x}$, $-\hat{y}$, $-\hat{z}$.

**** Exercise 4.2
Let $x$ be a real number and $A$ a matrix such that $A^2 = I$. Show that

\begin{align*}
% \label{eq:exercise-4.2-1}
\exp(ixA) = \cos(x)I + i\sin(x)A
\end{align*}

Use this result to verify Equations (4.4) through (4.6).

***** Solution
The equation follows directly from the polynomial series of $\exp$, $\sin$, and $\cos$.

**** Exercise 4.3
Show that, up to a global phase, the π/8 gate satisfies $T = R_z(\pi/4)$.

***** Proof
It is easy to see that $T = \exp(i\pi/8) \cdot R_z(\pi/4)$. We let ~sympy~ do the job:

#+name: exercise-4.3-1
#+begin_src python :results replace
  rz = Rz.subs(theta, pi/4)
  exp(I*pi/8) * rz - T  # should be zero
#+end_src

#+RESULTS: exercise-4.3-1
: Matrix([[0, 0], [0, 0]])

QED.

**** Exercise 4.4
Express the Hadamard gate $H$ as a product of $R_x$ and $R_z$ rotations and $e^{i\varphi}$ for some
$\varphi$.

***** Solution
Clearly a mere product of two factors can't produce the Hadamard gate. Hence we try to
find $\alpha,\beta,\gamma$ such that $R_z(\alpha)\cdot R_x(\gamma) \cdot R_z(\beta)$ is the Hadamard
up to the phase factor. Due to the sqrt of 2 factor appearing in $H$ we deduce that $\gamma=\pm\pi/2$
is a good bet. Knowing what comes we choose $\gamma=\pi/2$.

#+name: exercise-4.4-1
#+begin_src python
  a, b = sp.symbols('\\alpha \\beta')

  ra = Rz.subs(theta, a)
  rb = Rz.subs(theta, b)
  rx = Rx.subs(theta, pi/2)

  h0 = ra * rx * rb
  simp = sp.simplify(sqrt(2)*h0)
#+end_src

A short calculation leads to (use the code above to do it):

#+name: exercise-4.4-2
#+begin_src python :results value latex replace :exports none
  latex_formula = sp.latex(simp)
  #sp.preview(simp, viewer='file', filename='output.png', euler=False,
  #           dvioptions=['-D', '200', '-T', 'tight', '-bg', 'Transparent', '-fg', 'rgb 0.2 0.6 1.0'])
  #"output.png"

  latex_formula
#+end_src

#+RESULTS: exercise-4.4-2
#+begin_export latex
\left[\begin{matrix}e^{\frac{i \left(- \alpha - \beta\right)}{2}} & - i e^{- \frac{i \left(\alpha - \beta\right)}{2}}\\- i e^{\frac{i \left(\alpha - \beta\right)}{2}} & e^{\frac{i \left(\alpha + \beta\right)}{2}}\end{matrix}\right]
#+end_export

# RHS is result above
$$
R_z(\alpha)\cdot R_x(\pi/2) \cdot R_z(\beta) = \frac{1}{\sqrt{2}} \cdot
\left[\begin{matrix}e^{0.5 i \left(- \alpha - \beta\right)} & - 1.0 i e^{- 0.5 i \left(\alpha - \beta\right)}\\- 1.0 i e^{0.5 i \left(\alpha - \beta\right)} & e^{0.5 i \left(\alpha + \beta\right)}\end{matrix}\right]
$$

Hence setting $\alpha = \beta = \pi/2$ and $\phi = \pi/2$ we get

$$
H = e^{i\pi/2} \cdot R_z(\pi/2)\cdot R_x(\pi/2) \cdot R_z(\pi/2)
$$

**** Exercise 4.5
Prove that $(\hat{n}\cdot\sigma)^2 = I$, and use this to verify Equation (4.8).

***** Solution
This is easy to see from the following calculation:

#+name: exercise-4.5-1
#+begin_src python :results replace :exports both
  nx, ny, nz = sp.symbols('n_x n_y n_z')
  r = nx*X + ny*Y + nz*Z

  sp.simplify(r*r)
#+end_src

#+RESULTS: exercise-4.5-1
: Matrix([[n_x**2 + n_y**2 + n_z**2, 0], [0, n_x**2 + n_y**2 + n_z**2]])

By assumption we have $n_x^2 + n_y^2 + n_z^2 = 1$, which implies the claim.

Alternatively one can avoid calculating with matrices by using the well known (anti) commutator
relations between the Pauli Operators like $XY=iZ=-YX$. This shows that in the expanded form of
$(\hat{n}\cdot\sigma)^2$ only the squares of the Pauli Operators survive. Now use $X^2=Y^2=Z^2=I$ to
obtain the claim.

**** Exercise 4.6 (Bloch sphere interpretation of rotations)
Show that the rotation operators $R_{\hat{n}}(\theta)$ corresponds to a rotation of angle $\theta$
around the axis given by $\hat{n}$.

In other words: If we identify Qubits which just differ by phase, and identify each Qubit with its
(unique) Bloch vector, then the action of the quantum rotation is isomorphic to the ordinary
rotation with said axis and angle within the Bloch Sphere.
***** Proof
We divide the proof into several steps.

Let $|\psi\rangle = \cos\left(\theta /2\right) |0 \rangle \, + \, e^{i\varphi} \sin\left(\theta
/2\right) |1\rangle$ and recall the parameterization $p = (\sin\theta \cos\varphi,\;
\sin\theta \sin\varphi,\; \cos\theta)$
of the sphere.

****** (A) The claim is true for the special case $\hat{n} = (0, 0, 1)$.

PROOF: The standard basis $(|0\rangle, |1\rangle)$ diagonalizes =Z=. Hence, =Z= trivially acts on
$\varphi$ which corresponds to a rotation around the z-axis. QED.

****** (B) The claim is true for the special case $\hat{n} = (0, 1, 0)$.

PROOF: It is sufficient to prove this for infinitesimal small angles. More precisely, we consider
$\delta \to 0$ and use $\approx$ for equality up to $O(\delta^2)$.

Let $r_y(\delta)$ be the rotation of angle $\delta$ around y-axis. Let $\theta' = \theta + a\delta$ and $\varphi'=\varphi+b\delta$
be the coordinates of $r_y(\delta)p$. We want to calculate $a, b$. We have:

\begin{align*}
r_y(\delta)p &\approx (\sin(\theta)\cos(\varphi) + \delta\cos(\theta),\;
  a \sin(\theta)\sin(\varphi),\;
  a \cos(\theta) - \delta\sin(\theta)\cos(\varphi)) \\
  &\approx (\sin\theta' \cos\varphi',\; \sin\theta' \sin\varphi',\; \cos\theta')
\end{align*}

It is advisable to first calculate $a$ from the third components and then $b$ from the second:

$$
  a = \cos(\varphi),\quad b = - \frac{\cos(\theta)\sin(\varphi)}{\sin(\theta)}
$$

Next we abbreviate $c=\cos(\theta/2)$, $s=\sin(\theta/2)$ and similarly $c', s'$ with $\theta'$ in place of $\theta$.

$$
  R_y(\delta) |\psi\rangle \approx (c - \frac{\delta}{2} e^{i\varphi} s) |0\rangle + (\frac{\delta}{2} c + e^{i\varphi}s) |1\rangle
$$

It is to be shown that this equals (up to $O(\delta^2)$)

$$
  e^{i\delta f} (c'|0\rangle + e^{i\varphi'}s'|1\rangle)
$$

for some real $x$. A calculation yields that this is indeed true for $f=-s\sin(\varphi)/2c$. QED.

****** (C) The claim is true for the special case $\hat{n} = (1, 0, 0)$.

PROOF: Observe that:

$$
  R_x(\theta) = R_y(\pi/2) R_z(\theta) R_y(-\pi/2)
$$

Moreover, recall that a similar formula holds for the rotations within the Bloch Sphere:

$$
  r_x(\theta) = r_y(\pi/2) r_z(\theta) r_y(-\pi/2)
$$

This together with (A) and (B) implies the claim. QED.

****** Intermezzo
Let $\hat{n} = (x, y, z)$, and $a = x + iy$. Then

$$
  N := \hat{n}\cdot(X, Y, Z) = \left(\begin{matrix} z & \overline{a} \\ a & -z \end{matrix}\right)
$$

It remains to show the claim for $N$.

****** (D) There exist $\alpha,\beta$ such that:

$$
  R_{\hat{n}}(\theta) = R_x(\alpha) R_y(\beta) \cdot R_z(\theta) \cdot R_y(-\beta) R_x(-\alpha)
$$

PROOF: The expression on the right simplifies to

\begin{bmatrix}
  \cos(\alpha)\cos(\beta) & \sin(\beta) + i \sin(\alpha)\cos(\beta) \\
  \sin(\beta) - i \sin(\alpha)\cos(\beta) & -\cos(\alpha)\cos(\beta)
\end{bmatrix}

It is not hard to see that $\alpha,\beta$ can be chosen such that this equals $N$. The concrete
values would be needed to determine the axis of rotation. However, we determine it another way. QED.

****** (E) $R_{\hat{n}}(\alpha)$ corresponds to a rotation of angle $\alpha$ around /some/ axis
(which is independent of the angle).

PROOF: This is a direct consequence of (D), together with (B) and (C). QED.

****** (F) The angle in (E) is indeed $\hat{n}$.

PROOF: We have to show that the positive eigenvector $v_+$ of $R_{\hat{n}(\alpha)}$ corresponds to
$\hat{n}$ on the Bloch sphere. Therefore let us calculate the eigenvalues:

#+name: exercise-4.6
#+begin_src python :results replace
  x, y, z = sp.symbols('x y z')
  N = Matrix([[z, x - I*y], [x + I*y, -z]])
  ev = N.eigenvects()

  # Keep in mind that x^2 + y^2 + z^2 = 1
  output=""
  for i in [0, 1]:
      output += f"eigenvalue = {ev[i][0]}\neigenvector = {ev[i][2]}"
      if i==0: output += "\n\n"
  output
#+end_src

#+RESULTS: exercise-4.6
: eigenvalue = -sqrt(x**2 + y**2 + z**2)
: eigenvector = [Matrix([
: [z/(x + I*y) - sqrt(x**2 + y**2 + z**2)/(x + I*y)],
: [                                               1]])]
:
: eigenvalue = sqrt(x**2 + y**2 + z**2)
: eigenvector = [Matrix([
: [z/(x + I*y) + sqrt(x**2 + y**2 + z**2)/(x + I*y)],
: [                                               1]])]

We see that the normalized eigenvectors for $\pm 1$ are:

$$
  v_{\pm} = \frac{1}{\sqrt{2}} \left(
    \pm \sqrt{1 \pm z}\cdot|0\rangle + \frac{x + iy}{\sqrt{1 \pm z}} \cdot |1\rangle \right)
$$

Let $\theta,\varphi$ such that

$$
  \hat{n} =: (\sin\theta \cos\varphi,\; \sin\theta \sin\varphi,\; \cos\theta)
$$

Let us abbreviate $c=\cos(\theta/2)$, $s=\sin(\theta/2)$. By the usual trigonometric identities we have:

$$
  \hat{n} = (2sc\cos(\varphi), 2sc\sin(\varphi), c^2 - s^2)
$$

Plugging this into the above formula for $v_+$ we see that indeed

$$ |\psi\rangle = c |0\rangle + e^{i\varphi}s |1\rangle $$

which proofs the claim. QED.

****** Conclusion
(F) proves the claim QED[exercise 4.6].

**** Exercise 4.7
Show that $XYX = - Y$ and use this to prove that $X R_y(\theta)X = R_y(-\theta)$.

*Solution:* Follows from $(XY)X = iZX = i^2Y$.
**** Exercise 4.8
An arbitrary single qubit unitary operator can be written in the form

$$ U = \exp(i\alpha) R_{\hat{n}} (\theta) $$

for some real numbers $\alpha$ and $\theta$, and a real three-dimensional unit vector $\hat{n}$.

1. Prove this fact.
2. Find values for the Hadamard gate $H$.
3. Find values for the phase gate $S = \sqrt{Z}$.

***** Proof of 1
:PROPERTIES:
:CUSTOM_ID: exercise-4-8-part-1
:END:
PROOF: Clearly every unitary Matrix has the form:

$$
  U = e^{i\gamma} \begin{pmatrix} e & -\overline{f} \\ f & \overline{e} \end{pmatrix}
  \text{ where } |e|^2 + |f|^2 = 1,
$$

since the columns have to be orthogonal. In the following we show that the rotation operators are
*characterized* as those unitary operators which look like the RHS without the phase factor.

We have:

$$
R_{\hat{n}}(\theta) = e^{-i\theta N/2} = \left(\begin{matrix}
  \cos(\theta/2) - iz \sin(\theta/2) & -i\overline{a} \sin(\theta/2) \\
  -ia \sin(\theta/2) & \cos(\theta/2) + iz \sin(\theta/2) \end{matrix}\right)
$$

where $\hat{n} = (x, y, z)$ and $a = x + iy$. It is sufficient to show that the First column of the
rotation opterator can be made equal to $(e, f)$, since the second column of $U$ is fixed
by unitarity - up to a phase factor (this is where the $\alpha$ kicks in).

Abbreviating $\zeta = \cos(\theta/2) - iz \sin(\theta/2)$ and decomposing $a = e^{i\varphi}|a|$ we
see that the first columnt of the rotation is:

$$ (\zeta, -i e^{i \varphi} \sqrt{1 - |\zeta|^2}) $$

Clearly $\zeta$ can be chosen to be any complex number with modulus at most $1$. Once this is fixed,
the second component can be made any number with modulus $\sqrt{1-|\zeta|^2}$. Hence the system

\begin{align*}
  \alpha &= \gamma \\
  \zeta &= e \\
  -i e^{i\varphi} &= f/|f| \text{ if } f \neq 0
\end{align*}

has a (unique) solution, which proves the claim. QED.

***** Part 2
We follow the proof of Part 1 and first represent $H$ in this special form:

$$
  H = \frac{1}{\sqrt{2}} \begin{pmatrix} 1 & 1 \\ 1 & -1 \end{pmatrix}
    = \frac{i}{\sqrt{2}} \begin{pmatrix} -i & -i \\ -i & i \end{pmatrix}
$$

Hence $\zeta=-i/\sqrt{2}$ and $e^{i\varphi}=1$. This in turn leads to $x=z=1/\sqrt{2}$, $z=0$ and
$\theta=\pi$. In other words:

$$
  H = i R_{(\hat{x}+\hat{z})/\sqrt{2}}(\pi) = \frac{1}{\sqrt{2}} \left( X + Z \right).
$$

***** Part 3
Recall $Z = i R_z(\pi)$, hence:

$$ S = e^{i\pi/4} R_z(\pi/2). $$

**** Exercise 4.9
Explain why any single qubit unitary operator may be written in the form (4.12).

*Solution:* This essentially follows from the first lines of the proof of part 1 in [[#exercise-4-8-part-1][exercise 4.8]]
(representation of $U$).

**** Exercise 4.10 (=X=-=Y= decomposition of rotations)
Give a decomposition analogous to Theorem 4.1 but using $R_x$ instead of $R_z$.

***** Solution
By Theorem 4.1 we find the following representation of $HUH$:

$$
  HUH = e^{i\alpha} R_z(\beta)\cdot R_y(\gamma)\cdot R_z(\delta)
$$

Conjugating this again with $H$ we get:

$$
  U = e^{i\alpha} R_x(\beta)\cdot R_y(-\gamma)\cdot R_x(\delta)
$$

QED.

**** Exercise 4.11
Suppose $\hat{m}$ and $\hat{n}$ are non-parallel real unit vectors in three dimensions. Use Theorem 4.1 to show that
an arbitrary single qubit unitary $U$ may be written

$$
  U = e^{i\alpha} R_{\hat{n}}(\beta) R_{\hat{m}}(\gamma) R_{\hat{n}}(\delta)
$$

for appropriate choices of α, β, γ and δ.

# No idea how to prove it directly from Theorem 4.1.

***** Proof
Since we consider only products of Gates we may identify Gates resp. Qubits which are equivalent up
to a phase factor. That is we work on the quotient space $\CC^2/\CC$ for the Qubits and
$\CC^{2\times2}/\CC$ for the Gates.

We have to proof that:

$$
  U \equiv R_{\hat{n}}(\beta) R_{\hat{m}}(\gamma) R_{\hat{n}}(\delta)
$$

In exercise 4.8 we proved that $U\equiv R_{\hat{k}}(\varepsilon)$ for some axis and angle. Let us
denote by $r$ the (ordinary) rotations in the Bloch Sphere. By exercise 4.6 we know that the quantum
roations are isomorphic to the corresponding ordinary rotations. That is, we have to show:

$$
  r_{\hat{k}}(\varepsilon) = r_{\hat{n}}(\beta) r_{\hat{m}}(\gamma) r_{\hat{n}}(\delta) .
$$

On the other hand this is a well known fact about the group of rotations (real orthogonal matrices
with determinant equal to 1) in three dimensions. We prove it here anyway:

The above equation is equivalent to

$$
   r_{\hat{n}}(-\beta) = r_{\hat{m}}(\gamma) r_{\hat{n}}(\delta) r_{\hat{k}}(-\varepsilon) .
$$

Since $\beta$ is a free parameter it suffices to show that the RHS maps $\hat{n}$ to itself, for
appropriate choices of $\gamma$ and $\delta$. Therefore let $\hat{t} = r_{\hat{k}}(-\varepsilon)\hat{n}$ and consider:

$$
  \hat{n} = r_{\hat{m}}(\gamma) r_{\hat{n}}(\delta) \hat{t} .
$$

Consider the Meridian $M_1$ around $\hat{n}$ which contains $\hat{t}$ and the Meridian $M_2$ around
$\hat{m}$ which contains $\hat{n}$. Since the two axes are not parallel the two Meridians have two
intersection points $a$ and $b$ (they can be equal in the trivial case $\hat{t}=\hat{n}$). Clearly
we can choose $\delta$ in such a way that $\hat{t}$ moves to one of the intersection points, say
$a$. Now, by definition of $M_2$ we can choose $\gamma$ in sich a way that $a$ moves to $\hat{n}$. QED.

**** Exercise 4.12
Give A, B, C, and α (in Corollary 4.2) for the Hadamard gate.

***** Solution
First let us find the parameters in

$$
  H = e^{i\alpha} R_z(\beta) R_y(\gamma) R_z(\delta)
$$

The RHS is given explicitly in (4.12) from where it is immediat that $\gamma=\pi/2$. The other three
parameters satisfy a linear system of equations, which can be solved easily: $\alpha=\pi/2$,
$\beta=0$, and $\delta=\pi$.

Hence:

\begin{align*}
  A &= R_z(\beta) R_y(\gamma/2) = R_y(\pi/4) = \frac{1}{2}
    \begin{pmatrix}
      \sqrt{\sqrt{2} + 2} & - \sqrt{2 - \sqrt{2}} \\
      \sqrt{2 - \sqrt{2}} & \sqrt{\sqrt{2} + 2}
    \end{pmatrix} \\
  B &= R_y(-\gamma/2) R_z(-(\delta + \beta)/2) = R_y(-\pi/4) R_z(-\pi/2) = \frac{1}{2}
    \begin{pmatrix}
      e^{\frac{i\pi}{4}} \sqrt{\sqrt{2} + 2} & e^{-\frac{i\pi}{4}} \sqrt{2 - \sqrt{2}} \\
      - e^{\frac{i\pi}{4}} \sqrt{2 - \sqrt{2}} & e^{-\frac{i\pi}{4}} \sqrt{\sqrt{2} + 2}
    \end{pmatrix} \\
  C &= R_z((\delta - \beta)/2) = R_z(\pi/2) =
    \begin{pmatrix}
      e^{- \frac{i \pi}{4}} & 0 \\
      0 & e^{\frac{i \pi}{4}}
    \end{pmatrix}
\end{align*}
**** Exercise 4.13 (Circuit identities)
It is useful to be able to simplify circuits by inspection, using well-known identities. Prove the
following three identities:

$$ X = HZH,\quad Z = HXH,\quad Y = - HYH $$

***** Proof
The first two identities follow from the fact that $H$ is (unitary and) self-adjoint and contains
eigenvectors of =X= as columns (and rows). The third identity follows from

$$ H = \frac{1}{\sqrt{2}} \left( X + Z \right). $$

and the commutator properties of the Paulis, e.g. $XY=iZ$ and its cyclic variations. Of course the
first two identities could also be proved like that.
**** Exercise 4.14
Use the previous exercise to show that $HTH=R_x(\pi/4)$, up to a global phase.

***** Proof
This follows from $T\equiv R_z(\pi/4)$ (up to phase factor) and $HZH=X$.
**** Exercise 4.15 (Composition of single qubit operations)
The Bloch representation gives a nice way to visualize the effect of composing two rotations.

1. Prove that if a rotation through an angle β1 about the axis n̂1 is followed by a
rotation through an angle β2 about an axis n̂2 , then the overall rotation is through an angle β12
about an axis n̂12 given by

\begin{align*}
  c_{12} &= c_1 c_2 - s_1 s_2 \; \hat{n}_1 \cdot \hat{n}_2 \\
  s_{12} \hat{n}_{12} &= s_1 c_2 \; \hat{n}_1 + c_1 s_2 \; \hat{n}_2 + s_1 s_2 \; \hat{n}_2 \times \hat{n}_1 ,
\end{align*}

where $c_i=\cos(\beta_i/2)$, $s_i=\sin(\beta_i/2)$, $c_{12}=\cos(\beta_{12}/2)$, and $s_{12}=\sin(\beta_{12}/2)$.

2. Show that if β1 = β2 and n̂1 = ẑ these equations simplify to

\begin{align*}
  c_{12} &= c_2 − s_2 \; \hat{z} \cdot \hat{n}_2 \\
  s_{12} \hat{n}_12 &= sc \; (\hat{z} + \hat{n}_2) + s_2 \; \hat{n}_2 \times \hat{z} ,
\end{align*}

where $c=c_1$ and $s=s_1$.

*Remark:* /It seems/ (if we did no mistake) that there is a typo in the original formula for
$s_{12}\hat{n}_{12}$. We corrected this (hopefully).

***** Proof
We only proof the first assertion since the second one follows trivially from the first.

We use the previously established fact that the 3D-rotations are isomorphic to the Pauli rotation
operators (exercise 4.6). Along that way we essentially establish the relation between Quaternions
and 3D rotations (and Pauli rotations).

For a vector $\hat{n}$ let us define $N_{\hat{n}}=-i(n_1X+n_2Y+n_3Z)$. The composition of the two
rotations is given by:

$$
  (c_{12} + s_{12} N_{\hat{n}_{12}}) = (c_2 + s_2 N_{\hat{n}_2}) \cdot (c_1 + s_1 N_{\hat{n}_1}) .
$$

To spare us from the tedious work to expand the RHS by hand we use sympy for that. We are only
interested in algebraic operations and in particular we don't want to see any cumbersome matrix
expression. To help sympy we use the fact that the Quaterions can be modelled by the Pauli
Matrices. Just use the Identity matrix as the unit (the real number 1) and $-iX$, $-iY$, $-iZ$ as
the three imaginary units. Keep in mind that we only use the Quaterions as a trick to tell sympy
that we are not interested in Matrices. Essentially we still use the Pauli Rotations to prove the
claim.

#+name: exercise-4.15
#+begin_src python :results replace
  from sympy import Quaternion

  x1, y1, z1 = sp.symbols('x1 y1 z1')
  x2, y2, z2 = sp.symbols('x2 y2 z2')
  c1, c2, s1, s2 = sp.symbols('c1 c2 s1 s2')

  N1 = Quaternion(0, x1, y1, z1)
  N2 = Quaternion(0, x2, y2, z2)

  R1 = c1 + s1*N1
  R2 = c2 + s2*N2

  R2 * R1
#+end_src

#+RESULTS: exercise-4.15
: (c1*c2 - s1*s2*x1*x2 - s1*s2*y1*y2 - s1*s2*z1*z2) + (c1*s2*x2 + c2*s1*x1 - s1*s2*y1*z2 + s1*s2*y2*z1)*i + (c1*s2*y2 + c2*s1*y1 + s1*s2*x1*z2 - s1*s2*x2*z1)*j + (c1*s2*z2 + c2*s1*z1 - s1*s2*x1*y2 + s1*s2*x2*y1)*k

Rearranging the result for better readability:

#+begin_example
(c1*c2 - s1*s2*x1*x2 - s1*s2*y1*y2 - s1*s2*z1*z2)
+ (c1*s2*x2 + c2*s1*x1 - s1*s2*y1*z2 + s1*s2*y2*z1)*i
+ (c1*s2*y2 + c2*s1*y1 + s1*s2*x1*z2 - s1*s2*x2*z1)*j
+ (c1*s2*z2 + c2*s1*z1 - s1*s2*x1*y2 + s1*s2*x2*y1)*k
#+end_example

From here we can directly read out the claim! QED.

**** Exercise 4.16 (Matrix representation of multi-qubit gates)
What is the 4×4 unitary matrix for the following circuits

#+RESULTS: exercise-4.16-circuit
#+begin_example

q_0: ─────
     ┌───┐
q_1: ┤ H ├
     └───┘

     ┌───┐
q_0: ┤ H ├
     └───┘
q_1: ─────

#+end_example

#+name: exercise-4.16-circuit
#+begin_src python :results replace :exports results
  qc1 = QuantumCircuit(2)
  qc1.h(1)

  qc2 = QuantumCircuit(2)
  qc2.h(0)

  str(qc1.draw('text')) + "\n\n" + str(qc2.draw('text'))
#+end_src

***** Solution
According the convention of the book, these two circuits are represented by $I\otimes H$,
$H\otimes I$ (in that order). We note here that Qiskit uses the reverse order. The Kronecker Product
yields the matrices (since the basis vectors are ordered in a canonical way: 00, 01, 10, 11):

$$
  I\otimes H = \frac{1}{\sqrt{2}}
  \,\begin{bmatrix}
    1 &  1 & 0 &  0 \\
    1 & -1 & 0 &  0 \\
    0 &  0 & 1 &  1 \\
    0 &  0 & 1 & -1
  \,\end{bmatrix}
$$

$$
  H\otimes I = \frac{1}{\sqrt{2}}
  \,\begin{bmatrix}
    1 & 0 &  1 &  0 \\
    0 & 1 &  0 &  1 \\
    1 & 0 & -1 &  0 \\
    0 & 1 &  0 & -1
  \,\end{bmatrix}
$$

**** Exercise 4.17 (Building =CNOT= from controlled-=Z= gates)
Construct a =CNOT= (=CX=) gate from a =CZ= using two Hadamard Gates.

***** Solution
The general form of a CU-gate is ($P_j$ being projections):

$$
  CU = P_1 \otimes I + P_2 \otimes U
$$

Hence by $HZH=X$:

$$
  CX = I\otimes H \cdot CZ \cdot I\otimes H
$$

**** Exercise 4.18
Show that swapping the two qubits leaves =CZ= invariant. That is, these two circuits are equal:

#+begin_example
q_0: ──■──
     ┌─┴─┐
q_1: ┤ Z ├
     └───┘

     ┌───┐
q_0: ┤ Z ├
     └─┬─┘
q_1: ──■──
#+end_example

For this reason, the =CZ= is often denoted in a symmetric form:

#+RESULTS: exercise-4.18-circuit-1
:
: q_0: ─■─
:       │
: q_1: ─■─
:

#+name: exercise-4.18-circuit-1
#+begin_src python :results replace :exports results
  qc = QuantumCircuit(2)
  qc.cz(0, 1)

  qc.draw('text')
#+end_src

***** Proof
This follows from

$$
  CZ = P_1 \otimes I + P_2 \otimes Z = I \otimes P_1 + Z \otimes P_2 .
$$

**** Exercise 4.19 (=CNOT= action on density matrices)
The gate is a simple permutation whose action on a density matrix ρ is to rearrange the elements in
the matrix. Write out this action explicitly in the computational basis.

***** Solution
The density matrix for two qubits in the computational basis looks as follows:

$$
  \rho = \sum_{i,j=0}^1 p_{ij} |ij\rangle .
$$

=CX= maps $|0j\rangle$ to itself, and it swaps $|10\rangle$ with $|11\rangle$. Hence, as a mapping
on the density matrix it acts as follows on the density matrix:

$$
  p_{0i} \mapsto p_{0i},\quad p_{10} \mapsto p_{11},\quad p_{11} \mapsto p_{10} .
$$

**** Exercise 4.20 (=CNOT= basis transformations)
Show that the following two circuits are equal:

#+RESULTS: exercise-4.20-circuit-1
#+begin_example
     ┌───┐     ┌───┐
q_0: ┤ H ├──■──┤ H ├
     ├───┤┌─┴─┐├───┤
q_1: ┤ H ├┤ X ├┤ H ├
     └───┘└───┘└───┘

     ┌───┐
q_0: ┤ X ├
     └─┬─┘
q_1: ──■──

#+end_example


Moreover the effect of the =CX= gate on the eigenbasis of =X= is as follows:

$$
  \,|\pm+\rangle \mapsto |\pm+\rangle,\quad |\pm-\rangle \mapsto |\mp-\rangle
$$

In other words: With respect to the eigenbasis of =X= the =CX= gate acts again like a =CX= gate but with
the control and target qubit switched.

#+name: exercise-4.20-circuit-1
#+begin_src python :results replace :exports results
  qc1 = QuantumCircuit(2)
  qc1.h(0)
  qc1.h(1)
  qc1.cx(0, 1)
  qc1.h(0)
  qc1.h(1)

  qc2 = QuantumCircuit(2)
  qc2.cx(1, 0)

  str(qc1.draw('text')) + "\n\n" + str(qc2.draw('text'))
#+end_src

***** Proof
The statement after "Moreover" is direct consequence of the first statement. Therefore we only prove
the first one.

We have to show that $H\otimes H \cdot CX \cdot H\otimes H$ is the =CX= gate with the qubits reversed.

First, let us recall the projections on the eigenbasis of =X=:

\begin{align*}
  P_+ &= |+\rangle \otimes \langle+| = \begin{bmatrix} 1 & 1 \\ 1 & 1 \end{bmatrix}, \\
  P_- &= |-\rangle \otimes \langle-| = \begin{bmatrix} 1 & -1 \\ -1 & 1 \end{bmatrix}.
\end{align*}

Consider

$$
  H\otimes H \cdot CX \cdot H\otimes H = P_+ \otimes I + P_- \otimes Z .
$$

We have to show that, after swapping the two qubits the RHS equals =CX=. In fact:

$$
  I \otimes P_+ + Z \otimes P_- = \frac{1}{2}
      \,\begin{bmatrix}
         1 &  1 &  0 &  0 \\
         1 &  1 &  0 &  0 \\
         0 &  0 &  1 &  1 \\
         0 &  0 &  1 &  1
      \,\end{bmatrix}
    \,+ \frac{1}{2}
      \,\begin{bmatrix}
         1 & -1 &  0 &  0 \\
        -1 &  1 &  0 &  0 \\
         0 &  0 & -1 &  1 \\
         0 &  0 &  1 & -1
      \,\end{bmatrix}
    =
      \,\begin{bmatrix}
        1 & 0 & 0 & 0 \\
        0 & 1 & 0 & 0 \\
        0 & 0 & 0 & 1 \\
        0 & 0 & 1 & 0
      \,\end{bmatrix} = C(X) .
$$

**** Exercise 4.21
Verify that Figure 4.8 implements the $C^2(U)$ operation.

***** Solution
The easiest solution might be to just try out all four possibilities to plugin the computational
basis into the first two wires.

Another approach is to just calculate the corresponding algebraic expression:

\begin{align*}
        &(P_0 \otimes I \otimes I + P_1 \otimes I \otimes V) \\
  \cdot &(P_0 \otimes I \otimes I + P_1 \otimes X \otimes I) \\
  \cdot &(I \otimes P_0 \otimes I + I \otimes P_1 \otimes V^\dagger) \\
  \cdot &(P_0 \otimes I \otimes I + P_1 \otimes X \otimes I) \\
  \cdot &(I \otimes P_0 \otimes I + I \otimes P_1 \otimes V)
\end{align*}

Using $XP_0X=P_1$ and $XP_1X=P_0$ we get, that this is:

$$
  P_0 \otimes P_0 \otimes I + P_1 \otimes P_0 \otimes I + P_0 \otimes P_1 \otimes I + P_1 \otimes P_1 \otimes V^2 .
$$

Which is indeed $C^2(U)$.

**** Exercise 4.22
Prove that a $C^2(U)$ gate (for any single qubit unitary $U$) can be constructed using at most eight
one-qubit gates, and six $C(X)$.

***** Proof
If we combine the construction of $C^2(U)$ from figure 4.8 (the $U=V^2$ thing) with the construction
of $C(U)$ from figure 4.6 (the $AXBXC=U$ thing), we immediately see that we can construct a circuit
with six =CX= and ten one-qubit gates (two of the three phase gates cancel each other). However, we
can reduce the number of one qubit gates by two, since two pairs can actually be merged into a
single one-qubit operator.

**** Exercise 4.23
Construct a $C^1(U)$ gate for $U=R_x(\theta)$ and $U=R_y(\theta)$, using only =CNOT= and single qubit
gates. Can you reduce the number of single qubit gates needed in the construction from three to two?

***** Solution
For the y-rotation this is easy:

$$
  C^1(R_y(\theta)) = C(X) \cdot R_{y,2}(-\theta/2) \cdot C(X) \cdot R_{y,2}(\theta/2) .
$$

#+RESULTS: exercise-4.22-circuit-1
:
: q_0: ─────────────■────────────────■──
:      ┌─────────┐┌─┴─┐┌──────────┐┌─┴─┐
: q_1: ┤ Ry(θ/2) ├┤ X ├┤ Ry(-θ/2) ├┤ X ├
:      └─────────┘└───┘└──────────┘└───┘

We get the same result if we use the proof of Corollary 4.2. For the x-rotation we first deduce from
exercise 4.6 (interpretation as 3D rotations):

$$
  R_x(\theta) = R_z(-\pi/2) \cdot R_y(\theta) \cdot R_z(\pi/2) .
$$

Now the proof of Corollary 4.2 shows:

$$
  C^1(R_x(\theta)) = R_{z,2}(-\pi/2) C(X) \cdot R_{y,2}(-\theta/2) \cdot C(X) \cdot R_{z,2}(-\pi/2) R_{y,2}(\theta/2) .
$$

#+RESULTS: exercise-4.22-circuit-2
:
: q_0: ─────────────────────────■────────────────■──────────────
:      ┌─────────┐┌──────────┐┌─┴─┐┌──────────┐┌─┴─┐┌──────────┐
: q_1: ┤ Ry(θ/2) ├┤ Rz(-π/2) ├┤ X ├┤ Ry(-θ/2) ├┤ X ├┤ Rz(-π/2) ├
:      └─────────┘└──────────┘└───┘└──────────┘└───┘└──────────┘

# The code for the circuit plots:

#+name: exercise-4.22-prepare
#+begin_src python :exports none
  params = (Param('θ/2'), Param('-θ/2'), Param('-π/2'))

  qc1 = QuantumCircuit(2)
  qc1.ry(params[0], 1)
  qc1.cx(0, 1)
  qc1.ry(params[1], 1)
  qc1.cx(0, 1)

  qc2 = QuantumCircuit(2)
  qc2.ry(params[0], 1)
  qc2.rz(params[2], 1)
  qc2.cx(0, 1)
  qc2.ry(params[1], 1)
  qc2.cx(0, 1)
  qc2.rz(params[2], 1)
#+end_src

#+name: exercise-4.22-circuit-1
#+begin_src python :results replace :exports results
  str(qc1.draw('text'))
#+end_src

#+name: exercise-4.22-circuit-2
#+begin_src python :results replace :exports results
  str(qc2.draw('text'))
#+end_src

**** Exercise 4.24
Verify that Figure 4.9 implements the Toffoli gate.

***** Proof
Preliminaries: Recall that $T=e^{i\pi/8}R_z(\pi/4)$ and $XZX=-Z$. It suffices to prove the claim for
states of the form $|ij\rangle\otimes|\psi\rangle$ (the basis states in the first two wires), by
linearity.

The first wire always acts as $T$. This does nothing to $|0\rangle$ and applies a phase shift to $|1\rangle$.

Now we consider the first two wires (the upper wires) states of the form $|01\rangle$ (that is, the
control qubit is turned off). Then, the second wire acts as $ST^\dagger T^\dagger=I$. Hence
$|01\rangle$ is mapped to itself. Now consider $|1i\rangle$. The second wire now acts as

$$
  SX T\dagger XT\dagger = e^{-i\pi/4} S XR_z(\pi/4)XR_z(\pi/4) = e^{-i\pi/4} S .
$$

Hence $|1i\rangle$ is mapped to $|1\rangle\otimes S|i\rangle$. We summarize: The first two wires act as:

$$
  \,|ij\rangle \mapsto \begin{cases}
      i|11\rangle  & \text{if } i=j=1 \\
      \,|ij\rangle & \text{else.}
  \,\end{cases}
$$

Now consider the third wire. It is not hard to see that if one of the first two qubits is
$|0\rangle$, then all operators cancel each other (equalize to $I$) due to $X^2=-1$ and $T^\dagger T=I$.

So the only interesting case is if the first to qubits are both on (equal state 1). In that case we
have to show that the operator in the third row is equal to $-iX$. We have:

$$
  T X T^\dagger X = R_z(\pi/4) X R_z(-\pi/4) X = R_z(\pi/2) .
$$

Hence the operator in the third row is:

$$
  H R_z(\pi/2) R_z(\pi/2) H = R_x(\pi) = -iX.
$$

QED.

**** TODO Exercise 4.25 (Fredkin gate construction) [3/4]
Recall that the Fredkin (controlled-swap) gate performs the transform:

\begin{bmatrix}
  1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
  0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\
  0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\
  0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\
  0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\
  0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\
  0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\
  0 & 0 & 0 & 0 & 0 & 0 & 0 & 1
\end{bmatrix}


1. [X] Give a quantum circuit which uses three Toffoli gates to construct the Fredkin gate (Hint: think
   of the swap gate construction – you can control each gate, one at a time).
2. [X] Show that the first and last Toffoli gates can be replaced by gates.
3. [X] Now replace the middle Toffoli gate with the circuit in Figure 4.8 to obtain a Fredkin gate
   construction using only six two-qubit gates.
4. [ ] Can you come up with an even simpler construction, with only five two-qubit gates?

***** Solution to 1
Taking the swap-gate construction from Figure 1.7 we may deduce that the following circuit might do
what we want:

#+RESULTS: exercise-4-25-circuit-1
:
: q_0: ──■────■────■──
:        │  ┌─┴─┐  │
: q_1: ──■──┤ X ├──■──
:      ┌─┴─┐└─┬─┘┌─┴─┐
: q_2: ┤ X ├──■──┤ X ├
:      └───┘     └───┘

In fact, a short calculation yields the desired result.

#+name: exercise-4-25-1
#+begin_src python
  T01 = make_CnU(3, [0, 1], 2, X)
  T02 = make_CnU(3, [0, 2], 1, X)

  assert T01 * T02 * T01 == Fred, "Exercise 4.25, Solution to 1."
#+end_src

#+name: exercise-4-25-circuit-1
#+begin_src python :results replace :exports results
  qc1 = QuantumCircuit(3)
  qc1.ccx(0, 1, 2)
  qc1.ccx(0, 2, 1)
  qc1.ccx(0, 1, 2)

  qc1.draw('text')
#+end_src

***** Solution to 2
The following circuit equals the Fredkin Gate too:

#+RESULTS: exercise-4-25-circuit-2
:
: q_0: ───────■───────
:           ┌─┴─┐
: q_1: ──■──┤ X ├──■──
:      ┌─┴─┐└─┬─┘┌─┴─┐
: q_2: ┤ X ├──■──┤ X ├
:      └───┘     └───┘

In fact:

#+name: exercise-4.25-2
#+begin_src python
  C12 = make_CU(3, 1, 2, X)

  assert C12 * T02 * C12 == Fred, "Exercise 4.25, Solution to 2."
#+end_src

#+name: exercise-4-25-circuit-2
#+begin_src python :results replace :exports results
  qc2 = QuantumCircuit(3)
  qc2.cx(1, 2)
  qc2.ccx(0, 2, 1)
  qc2.cx(1, 2)

  qc2.draw('text')
#+end_src

***** Solution to 3
Apriori this new circuit uses 8 = 6 + 2 two-qubit gates. However the first two of these can be
merged into one (together with the Hadamard in between). Observe that the a similar fact is true for
the last two two-qubit gates of the construction from Figure 4.9. Hence we only need 6 such gates.

***** Solution to 4
So far I have no solution. My first guess was to use the construction from Firgure 4.8 (the thing
with $V^2=X$). With the same trick as in Solution 3 (merging adjacent gates) one gets a solution
with 6 two-qubit gates. I tried to move around gates at the right end (via commutator relations)
hoping the find an equivalent circuit with on gate less - so far without success.

**** Exercise 4.26
Show that the circuit

#+RESULTS: exercise-4-26-circuit-1
:
: q_0: ─────────────────────────────■───────────────────────────────
:                                   │
: q_1: ─────────────■───────────────┼────────────────■──────────────
:      ┌─────────┐┌─┴─┐┌─────────┐┌─┴─┐┌──────────┐┌─┴─┐┌──────────┐
: q_2: ┤ Ry(π/?) ├┤ X ├┤ Ry(π/?) ├┤ X ├┤ Ry(-π/?) ├┤ X ├┤ Ry(-π/?) ├
:      └─────────┘└───┘└─────────┘└───┘└──────────┘└───┘└──────────┘

differs from a Toffoli gate only by relative phases $e^{i\theta(c_1,c_2,t)}$.

#+name: exercise-4-26-circuit-1
#+begin_src python :results replace :exports results
  qc = QuantumCircuit(3)
  params = (Param('π/?'), Param('-π/?'))
  qc.ry(params[0], 2)
  qc.cx(1, 2)
  qc.ry(params[0], 2)
  qc.cx(0, 2)
  qc.ry(params[1], 2)
  qc.cx(1, 2)
  qc.ry(params[1], 2)

  qc.draw('text')
#+end_src

***** Proof
The following code saves us from the tedious calculations. It shows that $?=4$ (everywhere) is a
possible choice and that

$$
  \theta(c_1, c_2, t) = \begin{cases}
      \pi  & \text{if } c_1=1,  \text{ and } c_2=t=0 \\
      0 & \text{else.}
  \,\end{cases}
$$

#+name: exercise-4-8-get-circuit
#+begin_src python
  def get_circuit(n: int):
      """The n is the divisor missing in the Figure of Exercise 4.26 (the '?')."""
      R = tprod(Id, Id, Ry.subs(theta, pi / n))
      Ri = tprod(Id, Id, Ry.subs(theta, -pi / n))

      CX12 = make_CU(3, 1, 2, X)
      CX02 = make_CU(3, 0, 2, X)

      return sp.simplify(R * CX12 * R * CX02 * Ri * CX12 * Ri)


  C = get_circuit(4)
  Phase = tprod(Id, Id, Id) - 2*tprod(P1, P0, P0)  # Multiplies |100> by -1

  assert Phase * C == Toff, "Exercise 4.26: Circuit should be Toffoli up to Phase Factor"
#+end_src

**** Exercise 4.27
Using just =CNOT= and Toffoli gates, construct a quantum circuit to perform the transformation

\begin{bmatrix}
  1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
  0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
  0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\
  0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\
  0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\
  0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\
  0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\
  0 & 0 & 0 & 0 & 0 & 0 & 1 & 0
\end{bmatrix}

This kind of partial cyclic permutation operation will be useful later, in Chapter 7.

***** Solution
Since the exercise already speaks about permutations lets dive into the permutation group
formalism. This works since all involved matrices (=CNOT=, Toffoli, and the matrix from the exercise
text) are all /permutation matrices/. These form a group which is isomorphic to a group of
permuations. The procedure below also works analogously if we would directly use the matrix
representations but I think it is nice to think it throught in a different formalism.

Keep in mind that the isomorphism reverses the order of multiplication, that is: if Matrices $A$ and
$B$ correspond to permutations $a$ and $b$ then $AB$ corresponds to $ba$ (meaning apply $b$ first
and then $a$). This is not just a sympy quirk but a normal convention in the mathematics of
permutations. Maybe the rationale is that the action of a permutation is sometimes written in
superscript notation: $x^{ba}=(x^b)^a$ where $x$ is some set which gets permutated (see also
[[https://en.wikipedia.org/wiki/Group_action#Right_group_action][right-group-action]] on wikipedia, which does not use superscript notation though).

Recall the Matrix representation for the =CNOT= gate with control at 0 and target at 1 (on three
wires):

$$
  C_{01}(X) = \begin{bmatrix}
      1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
      0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\
      0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\
      0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\
      0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\
      0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
      0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\
      0 & 0 & 0 & 0 & 0 & 1 & 0 & 0
    \,\end{bmatrix}
$$

If we enumerate the basis vectors from $0$ (for $|000\rangle$) to $7$ (for $|111\rangle$), then this
corresponds to the permuation $(4\;6)(5\;7)$ (in [[https://en.wikipedia.org/wiki/Permutation#Cycle_notation][cycle-notation]]). The other variations of =CX= (with
different control/target) can be found by noting that permuting the three wires induces a
permutation on the basis vectors which in turn translates to an action on the permutation group
itself. See the code block below for the results (or use ~make_CU~ to make life easier).

The "standard" Toffoli Gate is the one with target at 2:

$$
  T_2 = \begin{bmatrix}
      1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
      0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\
      0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\
      0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\
      0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\
      0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\
      0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 \\
      0 & 0 & 0 & 0 & 0 & 0 & 1 & 0
  \,\end{bmatrix} ,
$$

which corresponds to the permuation $(6\;7)$. The other three Toffolis (with different targets) are
listed in the code block below.

#+name: exercise-4-27-1
#+begin_src python
  # cxij means: control i, target j
  cx01 = Perm(4, 6)(5, 7)
  cx02 = Perm(4, 5)(6, 7)
  cx12 = Perm(2, 3)(6, 7)
  cx10 = Perm(2, 6)(3, 7)
  cx20 = Perm(1, 5)(3, 7)
  cx21 = Perm(1, 3)(5, 7)

  # ti means: target at qubit i
  t0 = Perm(3, 7)
  t1 = Perm(5, 7)
  t2 = Perm(6, 7)
#+end_src

The following code defines an exhaustive search for solutions with a fixed number of gates.

#+name: exercise-4-27-2
#+begin_src python
  perms = [cx01, cx02, cx12, cx10, cx20, cx21, t0, t1, t2]
  names = ["cx01", "cx02", "cx12", "cx10", "cx20", "cx21", "t0", "t1", "t2"]
  indices = list(range(len(perms)))

  def search_ex4_27(n: int):
      """Find all solutions to exercise 4.27 with n gates."""
      for idxs in product(*([indices]*n)):
          ps = [perms[i] for i in idxs]
          prod = reduce((lambda x, y: x*y), ps)
          if prod == Perm(1, 2, 3, 4, 5, 6, 7):
              print(" * ".join([names[i] for i in idxs]))
#+end_src

Trying out some values of $n$ we see that $n=5$ is the minimal value which yields a solution. There
are six solutions in fact but they are similar in the sense that the last three permutations (gates)
actually commute. The solutions are:

#+begin_example
t0 * cx21 * cx02 * cx12 * t2
t0 * cx21 * cx02 * t2 * cx12
t0 * cx21 * cx12 * cx02 * t2
t0 * cx21 * cx12 * t2 * cx02
t0 * cx21 * t2 * cx02 * cx12
t0 * cx21 * t2 * cx12 * cx02
#+end_example

One benefit of the "reversed" multiplication of the permutations is that it is the same ordering
like in typical drawings of circuits. Let us just draw the third one:

#+RESULTS: exercise-4-27-circuit
:      ┌───┐
: q_0: ┤ X ├────────────■────■──
:      └─┬─┘┌───┐       │    │
: q_1: ──■──┤ X ├──■────┼────■──
:        │  └─┬─┘┌─┴─┐┌─┴─┐┌─┴─┐
: q_2: ──■────■──┤ X ├┤ X ├┤ X ├
:                └───┘└───┘└───┘

#+name: exercise-4-27-circuit
#+begin_src python :results replace :exports results
  qc = QuantumCircuit(3)
  qc.ccx(1, 2, 0)
  qc.cx(2, 1)
  qc.cx(1, 2)
  qc.cx(0, 2)
  qc.ccx(0, 1, 2)

  qc.draw('text')
#+end_src

**** Exercise 4.28
*Original Formulation:* For $U=V^2$ with $V$ unitary, construct a $C^5(U)$ gate analogous to that in
Figure 4.10, but using no work qubits. You may use controlled-$V$ and controlled-$V^\dagger$ gates.

*Remark:* In my opinion the formulation of the exercise is bad. The way I understand it there is
indeed no solution. Some sources in the internet claim that some slight variation of the circuit in
Figure 8 (for n=3 add a wire above the others, and let this wire be an additional control of the two
=CX= and the rightmost =CV=) solves the problem (see reference in the solution). But in fact, I also
found this solution but since it involves a $C^{n-1}V$ gate to construct $C^nU$ I rejected it as an
invalid solution. To get rid of all these control qubits on $V$ one would again take further roots
of $V$ which seems to be not very usefull for a real implementations. So at best it is a *pseudo
solution* (in my opinion).

*Alternate Version:* Let $n\geq3$, $V$ unitary and $U=V^2$. Prove that it is impossible to obtain a
construction of $C^n(U)$ on $n+1$ wires from $X$, $V$, $V^\dagger$, $U$, $C(X)$, $C(V)$,
$C(V^\dagger)$, and $C(U)$ alone which works for arbitrary $U$ (for $n=2$ it is possible as Figure
4.8 shows).

***** Proof (of the alternate version)
The idea for the proof is surprisingly simple - watch out for the determinant of the circuit! The
credits for the idea go to [[https://cs.stackexchange.com/q/138853][this stackoverflow answer]]. The overall discussion contains also a
reference to the pseudo-solution mentioned in the remark above.

Consider $n+1$ wires and recall that with all controls being on the first $n$ wires we have:

$$
  C^n(U) = \mathrm{diag}(I,I,\ldots,I,U) \text{ with } 2^n - 1 \text{ copies of }
  I=\begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}.
$$

That is, $C^n(U)$ is a diagonal matrix up to a tiny 2 by 2 sub-matrix $U$ in the lower right
corner. This follows from the ordering of the basis vectors (counting in binary, like 000, 001, 010,
..., 111). Hence:

$$
  \det(C^n(U)) = \det(U).
$$

Note that this formula also holds if the controls are elsewhere. This follows from the fact that the
determinant is invariant with respect to a change of basis.

Now consider the more general case of $C^m(W)$ (for a unitary $W$) with $m\leq n$ on $n+1$
wires. Assume for the moment that $W$ sits on the last wire and the controls being immediately
before. Again by the ordering of the basis vectors we see that:

$$
  C^m(W) = \mathrm{diag}(W_m, W_m,\ldots, W_m) \text{ with } 2^{n-m} \text{ copies of } W_m,
$$

where $W_m$ looks like in the special case $m=n$ above. Since the determinant of $W_m$ is $\det(W)$, we deduce:

$$
  \det(C^m(W)) = \det(W)^{2^{n-m}} .
$$

Again this still holds if the controls and the target are elsewhere on the $n$ wires.

Now suppose the construction was possible:

$$
  C^n(U) = \prod_i G_i,
$$

where each $G_i$ is one of the allowed gates. By well known properties of the determinant we have:

$$
  \det(U) = \prod_i \det(G_i) .
$$

The analysis above, together with $n-m\geq 2$, shows that $\det(G_i)=\det(W)^{4k}$ for some $k$ and
$W$ one of $V$, $V^\dagger$, $U$ or $X$. Since $\det(X)=-1$ we have:

$$
  \det(U) = \left(\det(V)^{k_V} \cdot \det(V^\dagger)^{k_{V^\dagger}} \cdot \det(U)^{k_U}\right)^4.
$$

This can't be satisfied for /arbitrary/ $U$. To be specific consider $U=X$. In that case the LHS is
$-1$ and the RHS is $+1$ because $\det(V),\det(V^\dagger)\in\{+i,-i\}$. QED.

**** TODO Exercise 4.29
Find a circuit containing $O(n^2)$ Toffoli, =CNOT= and single qubit gates which implements a
$C^n(X)$ gate (for $n>3$), using no work qubits.

*TODO:* In the light of the discussion of Exercise 4.28 this seems to be not possible - at least how
I interpret the exercise. Maybe one can find a different interpretation, state the exercise less
vague, and give a solution.

**** TODO Exercise 4.30
Suppose $U$ is a single qubit unitary operation. Find a circuit containing $O(n^2)$ Toffoli, =CNOT= and single
qubit gates which implements a $C^n(U)$ gate (for $n>3$), using no work qubits.

*TODO:* In the light of the discussion of Exercise 4.28 this seems to be not possible - at least how
I interpret the exercise. Maybe one can find a different interpretation, state the exercise less
vague, and give a solution.

**** Exercise 4.31 (More circuit identities)
Let subscripts denote which qubit an operator acts on, and let $C$ be a =CNOT= with qubit 1 the
control qubit and qubit 2 the target qubit. Prove the following identities:

\begin{align}
  C X_1 C &= X_1 X_2 \\
  C Y_1 C &= Y_1 X_2 \\
  C Z_1 C &= Z_1 \\
  C X_2 C &= X_2 \\
  C Y_2 C &= Z_1 Y_2 \\
  C Z_2 C &= Z_1 Z_2 \\
  R_{z,1}(\theta) C &= C R_{z,1}(\theta) \\
  R_{x,2}(\theta) C &= C R_{x,2}(\theta)
\end{align}

***** Proofs
Preparations: Let $N$ stand for =X=, =Y=, or =Z=. Recall that $P_0$ and $P_1$ are the projections
onto the computational basis, and that:

\begin{align*}
  C = P_0 \otimes I + P_1 \otimes X \\
  N_1 = N \otimes I,\quad N_2 = I \otimes N
\end{align*}

In particular: $X_1 X_2=X\otimes X$.

Identity (1) follows by considering only states of the form $|0j\rangle$, $|1j\rangle$, noting that
$X_1$ swaps the computational basis.

Identitiy (2) follows similarly if one observes that $Y_1$ acts like $X_1$ up to different phases,
which do not play a role here.

Identity (3) follows from the fact that $Z_1$ commutes with $P_0$ and $P_1$ (and hence with $C$),
and that $C^2=I$.

Identity (4) follows similarly from the fact that $X_2$ also commutes with $C$.

Identity (5) follows from $YX=-iZ=-XY$, and $P_0P_1=P_1P_0=0$, and $X^2=I$, and $Z=P_0-P_1$.

Identity (6) follows the same way as (5).

Identity (7) follows from the fact that =Z=, and hence $R_z$, commutes with $P_0$ and $P_1$.

Identitiy (8) follows from the fact =X=, and hence $R_x$, commutes with =X=.

**** Exercise 4.32
Suppose $\rho$ is the density matrix describing a two qubit system.
Suppose we perform a projective measurement in the computational basis of the
second qubit. Let $P_0=|0\rangle\langle0|$ and $P_1=|1\rangle\langle1|$ be the projectors onto the $|0\rangle$ and
$|1\rangle$ states of the second qubit, respectively. Let $\rho'$ be the density matrix which
would be assigned to the system after the measurement by an observer who did
not learn the measurement result. Show that

$$
  \rho' = P_0 \rho P_0 + P_1 \rho P_1 .
$$

Also show that the reduced density matrix for the first qubit is not affected by
the measurement, that is, $\ptrace{2}{\rho}=\ptrace{2}{\rho'}$.

***** Proof
First of all observe that the formulation of the exercise clearly identifies $P_i$ with
$I_1\otimes P_i$. We keep this identification in the following.

If the interpret the measurement postulate "the right way" we see that it immediately implies that
a measurement with respect to $P$ leaves the system in the post measurement state

$$
  \left\{ \left(\trace{P_0\rho}, P_0 \rho P_0\right),
          \left(\trace{P_1\rho}, P_1 \rho P_1\right) \right\} ,
$$

which is an /ensemble/. I suppose it only "collapses" into one of its members if "some classical
information flows". I suppose that "an observer who did not learn the measurement result" means that
this flow of information did not happen, hence the state of the system is still in the ensemble. The
corresponding density operator is:

$$
  P_0 \rho P_0 + P_1 \rho P_1 = \rho' .
$$

This proves the first claim. To prove the second claim we may assume wlog that
$\rho=\alpha\otimes\beta$ - by linearity of the trace. Indeed:

$$
  \sum_i \ptrace{2}{P_i\,\rho\,P_i}
  = \sum_i \ptrace{2}{I\otimes P_i \, \alpha\otimes\beta \, I\otimes P_i}
  = \alpha \sum_i \trace{P_i \beta P_i} = \alpha = \ptrace{2}{\rho} ,
$$

which concludes the solution of the exercise. QED.

**** Exercise 4.33 (Measurement in the Bell basis)
The measurement model we have specified for the quantum circuit model is that measurements are
performed only in the computational basis. However, often we want to perform a measurement in some
other basis, defined by a complete set of orthonormal states. To perform this measurement, simply
unitarily transform from the basis we wish to perform the measurement in to the computational basis,
then measure. For example, show that the circuit

#+name: exercise-4.33-bell-measurement
#+begin_src python :results replace :exports results
  qc = QuantumCircuit(2, 2)
  qc.cx(0, 1)
  qc.h(0)
  qc.barrier(range(2)) # just to make the drawing nicer
  qc.measure(range(2), range(2))

  str(qc.draw('text'))
#+end_src

#+RESULTS: exercise-4.33-bell-measurement
:           ┌───┐ ░ ┌─┐
: q_0: ──■──┤ H ├─░─┤M├───
:      ┌─┴─┐└───┘ ░ └╥┘┌─┐
: q_1: ┤ X ├──────░──╫─┤M├
:      └───┘      ░  ║ └╥┘
: c: 2/══════════════╩══╩═
:                    0  1


performs a measurement in the basis of the Bell states. More precisely, show that
this circuit results in a measurement being performed with corresponding
POVM elements the four projectors onto the Bell states. What are the
corresponding measurement operators?

***** Proof
Let $x,y\in\{0,1\}$. Observe

$$
  CX \cdot H\otimes I \; |xy\rangle
  = \frac{1}{\sqrt{2}} (|0y\rangle + (-1)^x |1\overline{y})
  = |\beta_{xy}\rangle .
$$

Hence the circuit first maps $|\beta_{xy}\rangle$ to $|xy\rangle$ and then measures in the
computational basis. This already shows that the circuit indeed "measures in the Bell Basis" in some
sense.

The measurement operators can be read directly from the circuit:

$$
  Q_{ij} = P_{ij} \cdot H\otimes I \cdot CX =: P_{ij} \cdot U ,
$$

where the $P_{ij}$ are the standard projections (for the measurement in the computational basis
after the barrier). Observe that these are no projections ($U$ and hence the $P_{ij}U$ map the Bell
Basis to the standard basis as implied by the introductory calculations). This is in line with the
observation that two times applying the circuit results in a potentially different outcome.

The corresponding POVMs are indeed the projections on the Bell Basis:

$$
  Q_{ij}^\dagger Q_{ij} = U^\dagger P_{ij} U ,
$$

since $U$ maps the Bell Basis to the standard basis. QED.

**** Exercise 4.34 (Measuring an operator)
Suppose we have a single qubit operator $U$ with eigenvalues $\pm1$, so that $U$ is both Hermitian and
unitary, so it can be regarded both as an observable and a quantum gate. Suppose we wish to measure
the observable $U$. That is, we desire to obtain a measurement result indicating one of the two
eigenvalues, and leaving a post-measurement state which is the corresponding eigenvector. How can
this be implemented by a quantum circuit?  Show that the following circuit implements a measurement
of $U$:

#+name: exercise-4.34-measure-observable
#+begin_src python :results replace :exports results
  qc = QuantumCircuit(2, 1)
  qc.h(0)
  qc.cx(0, 1)  # this is CX but we hack it to CU below
  qc.h(0)
  qc.barrier(range(2)) # just to make the drawing nicer
  qc.measure(range(1), range(1))

  str(qc.draw('text'))\
      .replace('X', 'U')\
      .replace('q_0', '|0>')\
      .replace('q_1', '|ψ>')
#+end_src

#+RESULTS: exercise-4.34-measure-observable
:      ┌───┐     ┌───┐ ░ ┌─┐
: |0>: ┤ H ├──■──┤ H ├─░─┤M├
:      └───┘┌─┴─┐└───┘ ░ └╥┘
: |ψ>: ─────┤ U ├──────░──╫─
:           └───┘      ░  ║
: c: 1/═══════════════════╩═
:                         0

***** Proof
Observe that the projections on the eigenvalues of $U$ are given by:

$$
  Q_{\pm} = \frac{1}{2} (I \pm U) .
$$

This and a short calculation shows that the result of the circuit at the position of the barrier
(before measurement) is:

$$
  H_1 \cdot C(U) \cdot H_1 \; |0\psi\rangle
  = |0\rangle \otimes Q_+ |\psi\rangle + |1\rangle \otimes Q_- |\psi\rangle .
$$

Now we see that finally applying the measurement in the first qubit "reveals" the corresponding
projection of $|\psi\rangle$ in the second wire. QED.

**** Exercise 4.35 (Measurement commutes with controls)
A consequence of the principle of deferred measurement is that measurements commute with quantum
gates when the qubit being measured is a control qubit. That is, applying $C(U)$ first and then
measure the first qubit is the same as first measuring (first qubit) and then applying $U$
conditionally on the second qubit depending on the measurement outcome.

***** Proof
Let us consider a generic state $|\psi\rangle=\sum_{ij}\alpha_{ij}|ij\rangle$.

*Case 1 (Measure first):* Directly after measuring, the state of the system is an ensemble (of the
possible measurement outcomes):

$$
  \{ (p_0, |\psi_0\rangle), (p_1, |\psi_1\rangle) \} ,
$$

where

$$
  p_i = \sqrt{|\alpha_{i0}|^2 + |\alpha_{i1}|^2}, \quad
  \,|\psi_i\rangle = \frac{1}{p_i} (\alpha_{i0} |i0\rangle + \alpha_{i1} |i1\rangle) .
$$

The conditional application of $U$ leaves the system in state

$$
  \{ (p_0, |\psi_0\rangle), (p_1, I\otimes U \; |\psi_1\rangle) \} .
$$

*Case 2 (CU first):* After applying the controlled $U$ the state is:

$$
  C(U) |\psi\rangle = \sum_j (\alpha_{0j} |0j\rangle + \alpha_{1j} |1\rangle \otimes U|j\rangle) .
$$

Measuring this, leaves us in the same final state as in case 1:

$$
  \{ (p_0, |\psi_0\rangle), (p_1, I\otimes U \; |\psi_1\rangle) \} .
$$

QED.

**** Exercise 4.36
Construct a quantum circuit to add two two-bit numbers $x$ and $y$ modulo 4. That is, the circuit
should perform the transformation $|x,y\rangle\rightarrow|x,x+y\mod4\rangle$.

***** Solution
To find a possible solution let us write the operation in a slightly more explicit bit-wise form:

$$
  \, |x_0,x_1,y_0,y_1\rangle \mapsto |x_0,x_1,x_0\oplus y_0, x_1\oplus c \oplus y_1\rangle ,
$$

where $c=x_0\cdot y_0$ is the carry-bit. Recall that $C(X)$ implements binary addition
modulo 2. Hence the following circuit, which is inspired by the above equation, does what we want:

#+RESULTS: exercise-4.36-solution
:
: q_0: ──■────■───────
:        │    │
: q_1: ──┼────┼────■──
:        │  ┌─┴─┐  │
: q_2: ──■──┤ X ├──┼──
:      ┌─┴─┐└───┘┌─┴─┐
: q_3: ┤ X ├─────┤ X ├
:      └───┘     └───┘

#+name: exercise-4.36-solution
#+begin_src python :results replace :exports results
  qc = QuantumCircuit(4)
  qc.ccx(0, 2, 3)
  qc.cx(0, 2)
  qc.cx(1, 3)

  str(qc.draw('text'))
#+end_src

**** Exercise 4.37
Provide a decomposition of the transform

$$
\frac{1}{2}
\,\begin{bmatrix}
  1 & 1 & 1 & 1 \\
  1 & i & -1 & - i \\
  1 & -1 & 1 & -1 \\
  1 & - i & -1 & i
\,\end{bmatrix}
$$

into a product of two-level unitaries. This is a special case of the quantum Fourier transform,
which we study in more detail in the next chapter.

***** Solution
We semi-automate the task with sympy. First we have to set up the matrix:

#+name: exercise-4.37-1
#+begin_src python
  F = Matrix([[I**(x*y) for x in range(4)] for y in range(4)]) / 2
#+end_src

Using the the utility function src_python{make_twolevel} it is relatively easy to follow the
procedure from the book (note that in general we also had to use src_python{make_onelevel}, but here
we don't need it)):

#+name: exercise-4.37-2
#+begin_src python
  U1 = sp.simplify(make_twolevel(4, [1,0], [1, -1]))
  U2 = sp.simplify(make_twolevel(4, [2,0], [1, -sqrt(2)]))
  U3 = sp.simplify(make_twolevel(4, [3,0], [1, -sqrt(3)]))
  U4 = sp.simplify(make_twolevel(4, [2,1], [sqrt(3) * (3 + I), -3 * (1 - I)]))
  U5 = sp.simplify(make_twolevel(4, [3,1], [I, -sqrt(2)]))

  F0 = make_CU(2, 0, 1, Matrix([[1, I], [-1, I]]) / sqrt(2))
  assert sp.simplify(U5*U4*U3*U2*U1*F) == F0
#+end_src

From this we can easily readout the decomposition:

$$
\left[\begin{matrix}\frac{\sqrt{2}}{2} & \frac{\sqrt{2}}{2} & 0 & 0\\\frac{\sqrt{2}}{2} & - \frac{\sqrt{2}}{2} & 0 & 0\\0 & 0 & 1 & 0\\0 & 0 & 0 & 1\end{matrix}\right] \cdot \left[\begin{matrix}\frac{\sqrt{6}}{3} & 0 & \frac{\sqrt{3}}{3} & 0\\0 & 1 & 0 & 0\\\frac{\sqrt{3}}{3} & 0 & - \frac{\sqrt{6}}{3} & 0\\0 & 0 & 0 & 1\end{matrix}\right] \cdot \left[\begin{matrix}\frac{\sqrt{3}}{2} & 0 & 0 & \frac{1}{2}\\0 & 1 & 0 & 0\\0 & 0 & 1 & 0\\\frac{1}{2} & 0 & 0 & - \frac{\sqrt{3}}{2}\end{matrix}\right] \cdot \left[\begin{matrix}1 & 0 & 0 & 0\\0 & - \frac{\sqrt{3} i \left(1 + i\right)}{4} & \frac{3}{4} - \frac{i}{4} & 0\\0 & \frac{3}{4} + \frac{i}{4} & - \frac{\sqrt{3} \cdot \left(1 + i\right)}{4} & 0\\0 & 0 & 0 & 1\end{matrix}\right] \cdot \left[\begin{matrix}1 & 0 & 0 & 0\\0 & \frac{\sqrt{6}}{3} & 0 & - \frac{\sqrt{3} i}{3}\\0 & 0 & 1 & 0\\0 & \frac{\sqrt{3} i}{3} & 0 & - \frac{\sqrt{6}}{3}\end{matrix}\right] \cdot \left[\begin{matrix}1 & 0 & 0 & 0\\0 & 1 & 0 & 0\\0 & 0 & \frac{\sqrt{2}}{2} & \frac{\sqrt{2} i}{2}\\0 & 0 & - \frac{\sqrt{2}}{2} & \frac{\sqrt{2} i}{2}\end{matrix}\right]
$$


The following code was used to produce the above latex expression:

#+name: exercise-4.37-3
#+begin_src python
  def get_latex_for_exercise_4_37():
      Vs = [U1.H, U2.H, U3.H, U4.H, U5.H, F0]
      return " \\cdot ".join([sp.latex(V) for V in Vs])
#+end_src

**** Exercise 4.38
Prove that there exists a $d\times d$ unitary matrix $U$ which cannot be decomposed as a product of
fewer than $d-1$ two-level unitary matrices.

***** Proof
For each unitary matrix $U$ let us define an equivalence relation $\sim_U$ on $\{0,\ldots,d-1\}$
as follows. First of all define:

$$
  i \sim^0_U j :\Leftrightarrow \langle i|U|j\rangle \neq 0
$$

Now let $\sim_U$ be the reflexive and transitive closure $\mathrm{closure}(\sim^0_U)$ of
$\sim^0_U$. We remark that we actually only care about $i,j$ with $i\neq j$. But it is
convenient to have an /equivalence/ relation, hence we require reflexivity.

Let us call equivalence classes with at least two elements /non-trivial/. In a sense, the
non-trivial equivalence classes correspond to those subspaces, spanned by base vectors, on which the
matrix acts /non-trivially/. Note that this is a /slightly/ stricter notion then in the book. Merely
multiplying a base vector with a complex number of modulus one does not count. Instead we require
some "interaction" /between/ the basis vectors.

Note that two-Level matrices have at most one non-trivial equivalence class $A$, and this $A$ has
/exactly/ two elements.

Let us define the /score/ of an equivalence relation $\sim$ by:

$$
  \mathrm{score}(\sim) = \sum_A (|A| - 1),
$$

where $A$ ranges over all (non-trivial) equivalence classes of $\sim$. Observe that the score of a
two-level matrix is at most $1$. Let us write $\mathrm{score}(U):=\mathrm{score}(\sim_U)$. The score
has the following easy to prove properties (we only sketch their proofs)

- monotonicity :: $\sim_1\;\subset\;\sim_2\quad\Rightarrow\quad\mathrm{score}(\sim_1)\leq\mathrm{score}(\sim_2)$
- sub-additivity :: $\mathrm{score}(\mathrm{closure}(\sim_1\cup\sim_2))\leq\mathrm{score}(\sim_1)+\mathrm{score}(\sim_2)$.

The key to prove monotonicity is to observe that the equivalence classes of $\sim_1$ are subsets of
equivalence classes of $\sim_2$. Note that the claim would even be true without the $-1$
"punishment" for each equivalence class.

For sub-additivity first observe that the equivalence classes of the combined relation is
"essentially" the set of the "old" equivalence classes. In the extreme case where this is "realy"
true equality holds. In general, there can be old equivalence classes which overlap. This means that
we have to merge them. This "merger" of two old equivalence classes decreases the score by $m-1$,
where $m$ is the number of common elements of the two old equivalence classes. Of course the merging
has to be repeated until the equivalence classes are disjoint.

To say something about $\sim_{UV}$ recall:

$$
  \langle i|UV|j\rangle = \sum_k \langle i|U|k\rangle\langle k|V|j\rangle .
$$

This implies that

$$
  \sim^0_{UV} \; \subseteq \; \sim_U \circ \sim_V \; \subseteq \; \mathrm{closure}(\sim_U \cup \sim_V)
  \; =: \; \sim_{U,V} .
$$

In particular $\sim_{UV}\;\subseteq\;\sim_{U,V}$ (note the comma between $U$ and $V$ in the
RHS). Hence, by monotonicity and sub-additivity:

$$
  \mathrm{score}(UV) \leq \mathrm{score}(\sim_{U,V}) \leq \mathrm{score}(U) + \mathrm{score}(V) .
$$

In particular the score of a matrix which can be decomposed into $k$ two-level matrices is at most
$k$. On the other hand there are matrices whose score is $d-1$ (the maximal possible value). Take
for example the cyclic permuation which maps $|i\rangle$ to $|i+1\mod d\rangle$. Such a matrix
cannot be expressend by fewer than $d-1$ matrices. QED.

**** Exercise 4.39
Find a quantum circuit using single qubit operations and =CNOT=​s to implement the transformation

\begin{bmatrix}
  1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
  0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\
  0 & 0 & a & 0 & 0 & 0 & 0 & c \\
  0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\
  0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\
  0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\
  0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\
  0 & 0 & b & 0 & 0 & 0 & 0 & d
\end{bmatrix}

where $\tilde{U}=\begin{bmatrix}a&c\\b&d\end{bmatrix}$ is an arbitrary $2\times2$ unitary matrix.

***** Solution
Let us call the matrix $M$. Clearly $M$ represents a two-level operation at $s=010$, $t=111$. The
following gray code connects the two bit-patterns:

| $g_1$ | 010 |
| $g_2$ | 011 |
| $g_3$ | 111 |

Let $P$ be the permutation matrix corresponding to the permuation $(7)(2,3)$ in cycle notation (it
swaps $|g_1\rangle$ and $|g_2\rangle$). It can be implemented by a controlled =X=. $PMP$ is a
controlled $\tilde{U}$ gate with target $0$ and controls at all remaining wires. Hence the following
circuit implements $M$:

#+name: exercise-4.39-1
#+begin_src python :results replace :exports results
  qcU = QuantumCircuit(1, name="Ũ")
  ccu = qcU.to_gate().control(2)

  qc = QuantumCircuit(3)
  qc.ccx(0, 1, 2, '10')  # note: qiskit uses different bit-order
  qc.append(ccu, [1, 2, 0])
  qc.ccx(0, 1, 2, '10')

  str(qc.draw('text'))
#+end_src

#+RESULTS: exercise-4.39-1
:           ┌───┐
: q_0: ──o──┤ Ũ ├──o──
:        │  └─┬─┘  │
: q_1: ──■────■────■──
:      ┌─┴─┐  │  ┌─┴─┐
: q_2: ┤ X ├──■──┤ X ├
:      └───┘     └───┘

Figure 4.9 shows how to implement the controlled =X= from fundamental gates (take also into account
the "trick" from Figure 4.11). Use Figure 4.8 and Figure 4.6 to implement the controlled
$\tilde{U}$.

**** Exercise 4.40
For arbitrary $\alpha$ and $\beta$ show that

$$
  \norm{R_{\hat{n}}(\alpha) - R_{\hat{n}}(\alpha + \beta)} = |1 - \exp(i\beta/2)| .
$$

and use this to justify (4.76).

***** Proof
This directly follows from the fact that the /spectral radius/ of a normal operator is equal to its
operator norm (for non-normal operators it might be strictly smaller). For diagonal matrices this is
easy to see. For the general case, recall that normal operators are those operators which can be
diagonalized by unitary operators.

Let us return to the particular exercise. By the spectral theorem, and the fact that the rotation
operators are unitary we have:

$$
  \norm{R_{\hat{n}}(\alpha) - R_{\hat{n}}(\alpha + \beta)}
  = \norm{ R_{\hat{n}}(\alpha) (I-R_{\hat{n}}(\beta)) }
  = \norm{I-R_{\hat{n}}(\beta)} .
$$

Again by the spectral theorem the eigenvalues of $I-R_{\hat{n}}(\beta)$ are $1-\exp(\mp i\beta/2)$
(because the eigenvalues of $\hat{n}\cdot(X,Y,Z)$ are $\pm1$). Hence the spectral radius is
$|1-\exp(i\beta/2)|$. Putting everything together we proved the claim.

Formula (4.76) follows directly from this and $R_{\hat{n}}(\theta)^n=R_{\hat{n}}(n\theta)$ (again
spectral theorem) for an appropriate choice of $n$ (so that $\alpha$ and $n\theta$ are close
enough (as elements of the unit circle)). QED.

**** Exercise 4.41
This and the next two exercises develop a construction showing that the Hadamard, phase, controlled-
and Toffoli gates are universal. Show that this circuit

#+RESULTS: exercise-4.41
:      ┌───┐               ┌───┐┌─┐
: |0>: ┤ H ├──■─────────■──┤ H ├┤M├───
:      ├───┤  │         │  ├───┤└╥┘┌─┐
: |0>: ┤ H ├──■─────────■──┤ H ├─╫─┤M├
:      └───┘┌─┴─┐┌───┐┌─┴─┐└───┘ ║ └╥┘
: |ψ>: ─────┤ X ├┤ S ├┤ X ├──────╫──╫─
:           └───┘└───┘└───┘      ║  ║
: c: 2/══════════════════════════╩══╩═
:                                0  1

applies the operation $R_z(\theta)$ to the third (target) qubit if the measurement outcomes are both
$0$, where $\cos\theta=3/5$, and otherwise applies =Z= to the target qubit. Show that the
probability of both measurement outcomes being $0$ is $5/8$, and explain how repeated use of this
circuit and $Z=S^2$ gates may be used to apply a $R_z(\theta)$ gate with probability approaching
$1$.

#+name: exercise-4.41
#+begin_src python :results replace :exports results
  qc = QuantumCircuit(3, 2)
  qc.h(0)
  qc.h(1)
  qc.ccx(0, 1, 2)
  qc.s(2)
  qc.ccx(0, 1, 2)
  qc.h(1)
  qc.h(0)
  qc.measure(range(2), range(2))

  str(qc.draw('text')) \
    .replace('q_0', '|0>') \
    .replace('q_1', '|0>') \
    .replace('q_2', '|ψ>')
#+end_src

***** Proof
The initial state is $|00\psi\rangle$, however let us consider the more general situation where the
initial state is $|ab\psi\rangle$ for $a,b\in\{0,1\}$. Observe that

$$
  H\otimes H |ab\rangle = \frac{1}{2} \sum_{ij} (-1)^{ai+bj} |ij\rangle .
$$

It is easy to calculate the state /directly/ after the second =CCX=. It is:

$$
\, |\zeta_0\rangle = \frac{1}{2} \sum_{ij} \, (-1)^{ai+bj} \, |ij\rangle \, X^{ij} S X^{ij} \, |\psi\rangle .
$$

Before applying the last two Hadamard gates it comes in handy to represent this in a slightly
different way:

$$
\, |\zeta_0\rangle = \frac{1}{2} \sum_{ij} \, (-1)^{ai+bj} \, |ij\rangle \, S \, |\psi\rangle
   \, + \, \frac{1}{2} \, (-1)^{a+b} \, |11\rangle \, (XSX - S) \, |\psi\rangle .
$$

Applying the last two Hadamards leads to

\begin{align*}
\, |\zeta\rangle &= H\otimes H\otimes I |\zeta_0\rangle
  = |ab\rangle |\psi\rangle + \frac{1}{4} \sum_{ij} (-1)^{i+j+a+b} |ij\rangle \, (XSX-S) \, |\psi\rangle \\
  &= |ab\rangle \left( \frac{3}{4}S+\frac{1}{4}XSX \right)|\psi\rangle
  \,+\, \underbrace{\left(\sum_{ij\neq ab} \frac{1}{4} (-1)^{i+j+a+b} |ij\rangle \right)}_{=:A|ab\rangle}
  \, (XSX-S) \, |\psi\rangle .
\end{align*}

Note that the thus defined linear operator $A$ is /not/ unitary but invertible. It has the nice
property that $\norm{A|ab\rangle}=\sqrt{3}/4$ (independent of $a,b$) and that $A|ab\rangle$ is
orthogonal to $|ab\rangle$. On the other hand these properties do not generalize to arbitrary
states.

Clearly

$$
  XSX - S = (i-1) Z .
$$

The other operator which is applied to the first occurrence of $|\psi\rangle$ is a bit more tricky
to make sense of. We make use of the functional calculus for =Z= (more specifically: we use the
Pauli-Rotation formalism). First of all recall that $S=e^{i\pi/4}R_z(\pi/2)$ and
$R_z(-\pi)=iZ$. Using this, with $XZX=-Z$ we get:

\begin{align*}
  \frac{3}{4}S+\frac{1}{4}XSX &= \frac{1}{4} e^{i\pi/4} (3R_z(\pi/2) + R_z(-\pi/2))
  = \frac{1}{4} e^{i\pi/4} R_z(\pi/2) \cdot (3 + R_z(-\pi)) \\
  &= \frac{\sqrt{10}}{4} e^{i\pi/4} R_z(\pi/2) \cdot
    \underbrace{\left(\frac{3}{\sqrt{10}} + \frac{i}{\sqrt{10}} Z \right)}_{=:R_z(\theta_0)} .
\end{align*}

Observe that $\sin\theta_0=2\sin(\theta_0/2)\cos(\theta_0/2)=-3/5$. Let
$\theta=\theta_0+\pi/2$. Hence $\cos(\theta)=3/5$ and

$$
  \frac{3}{4}S+\frac{1}{4}XSX = \frac{\sqrt{10}}{4} e^{i\pi/4} R_z(\theta) .
$$

Let us summarize what we found out. The final state of the qubits is:

$$
\,  |\zeta\rangle = |ab\rangle \, \frac{\sqrt{10}}{4} e^{i\pi/4} R_z(\theta) |\psi\rangle
      \,+\, A|ab\rangle (i-1) Z |\psi\rangle
$$

*Conclusion:* If the initial state is $|ab\rangle|\psi\rangle$ then we measure $|ab\rangle$ with
probability $5/8$. In that case the final state of the "payload" is $R_z(\theta)|\psi\rangle$ (up to
a global phase). Otherwise the payload ends up in state $Z|\psi\rangle$ (up to a global phase). The
angle satisfies $\cos\theta=3/5$. This proves the first part of the exercise.

Let us sketch a possibility to improve the probability of success. One can introduce two more
ancillary qubits (initialized to $|0\rangle$) and put another such circuit on them (connected to the
"main" qubit as the first one). To cancel the =Z= from the first circuit, in case it "fails", one
can use three =CCZ= gates (for the three "failing" measurement outcomes). To prevent a double
rotation (if both circuits succeed) one can put a controls on the $S$ gate (or simpler: put a
controlled $S^3$ next to it) of the second circuit making it dependent on success of the first
one. My the principle of deferred measurement all measurements can be done at the end of the
circuit. To improve the probability even further, just repeat the procedure.

**** Exercise 4.42 (Irrationality of $\theta$)
Suppose $\cos\theta=3/5$. We give a proof by contradiction that $\theta$ is an irrational multiple
of $2\pi$.

1. Using the fact that $e^{i\theta}=(3+4i)/5$, show that if $\theta$ is rational, then there must
   exist a positive integer $m$ such that $(3+4i)^m=5m$.
2. Show that $(3 + 4i)^m=3+4i\mod5$ for all $m>0$, and conclude that no $m$ such that $(3+4i)^m=5^m$
   can exist.

***** Proof
The exercise essentially contains the solution. If $\theta$ was rational, then there would be
integers $k,m$ such that $\theta=2k\pi/m$. Hence

$$
  (3 + 4i)^m = 5^m \cdot e^{2k\pi i} = 5^m .
$$

On the other hand

$$
  (3+4i)^2 = -7 + 24i \equiv 3 + 4i \mod 5 .
$$

Clearly the same is true for higher powers. Hence $(3+4i)^m$ cannot be real - which contradicts a
previous statement. Hence $\theta$ can not be rational. QED.

**** Exercise 4.43
Use the results of the previous two exercises to show that the Hadamard, phase, controlled-~NOT~ and
Toffoli gates are universal for quantum computation.

***** Proof
We already know that if we add the $T$ gate then we have a universal set of gates. Hence it suffices
to be able to approximate the $T$ gate. Note that the $T$ gate is $R_z(\pi/4)$ up to a global
phase. Exercises 4.41 and 4.42 show that /any/ $R_z(\theta)$ can be approximated arbitrarily
well. QED.

Of course, contrary to the construction from the main-text, /this/ construction with the Toffoli
gate needs some ancillary qubits. So we proved a /weaker/ kind of universality then what is proved
for the "original" set of universal gates!

**** Exercise 4.44
Show that the three qubit gate

$$ G = C^2(iR_x(\pi\alpha)) $$

is universal for quantum computation whenever $\alpha$ is irrational.

***** Proof
We show universality for the situation where one has access to a reservoir of ancillary qubits in
state $|0\rangle$ or $|1\rangle$.

By irrationality of $\alpha$ one can approximate $C^2(R_x(\theta))$ for any angle $\theta$ (we drop
the factor $i$ because we ignore the global phase here and in the following). By the use of
ancillary qubits in state $|1\rangle$ one can thus implement $R_x(\theta)$ for any $\theta$.

Moreover the Toffoli =CCX= can be implemented. By the use of ancillary qubits in state $|1\rangle$
it is easy to implement =CX= and =X= from it.

To proof universality it suffices to implement $R_z(\theta)$ for arbitrary $\theta$. To see this,
first recall that according to exercise 4.11 any single qubit gate has the form
$R_z(\beta)R_x(\gamma)R_z(\delta)$ (up to a global phase). On the other hand, the book shows that
single qubit gates together with =CX= is a universal set.

Let $|\pm\rangle$ be eigenstates of =X= corresponding to the eigenvalues $\pm1$. By the spectral
theorem we have:

$$
  C(R_x(\theta)) |k-\rangle =
  \,\begin{cases}
    \, |0-\rangle & \text{for } k=0 \\
    e^{i\theta/2} \, |1-\rangle & \text{for } k=1
  \,\end{cases}
  = (e^{i\theta/4} R_z(\theta/2) |k\rangle) \otimes |-\rangle .
$$

That is, if we had access to an ancillary qubit in state $|-\rangle$ we could implement all
$R_z(\theta)$ gates. To see that, in a sense, we have access to such a qubit, consider:

$$
  C = R_x(\pi/2)_1 \cdot C(X) \cdot R_x(\pi/2)_1 .
$$

As usual the index $1$ means that we apply the rotation gate to the first qubit. Observe that

$$
  C |00\rangle = \frac{1}{\sqrt{2}} (|0\rangle|-\rangle - i|1\rangle|+\rangle) .
$$

That is, the circuit $C$, feeded with the initial state $|00\rangle$ and measured at the first qubit
produces $|-\rangle$ with a probability of $1/2$ (in that case $0$ is the measurement outcome). One
can make the probability as close to one as needed by running sufficiently many of these circuits,
but with the same "output" qubit. Of course, we have to prevent "multiple successes". To accomplish
this, we add additional controls to the $C(X)$ gate making it dependent on the measurement outcomes
of the "previous" runs of $C$. Of course measurements can be deferred to the end.

For the argument above it is of course sufficient to be able to generate $|-\rangle$ with /merely/
high probability. This proves the claim. QED.

**** Exercise 4.45
Suppose $U$ is a unitary transform implemented by an n qubit quantum circuit constructed from $H$,
$S$, and Toffoli gates. Show that $U$ is of the form $2^{-k/2}M$, for some integer $k$, where $M$ is
a $2^n\times2^n$ matrix with only complex integer entries. Repeat this exercise with the Toffoli gate
replaced by the π/8 gate.

***** Proof
Observe that except for the Hadamard gate all mentioned gates have complex integer coefficients (and
Kronecker products of these gates with the identity obviously does not change this
property). Moreover we have

$$
  H = 2^{-1/2} \tilde{H} ,
$$

for a matrix $\tilde{H}$ with (real - but this does not matter) integer coefficients. Hence we can
choose $k$ to be the number of Hadamard gates and $M$ to be the product of the matrices where $H$ is
replaced by $\tilde{H}$.

Now consider the $T$ gate. Observe that

$$
  T = \frac{1}{\sqrt{2}} \begin{bmatrix} \sqrt{2} & 0 \\ 0 & i+1 \end{bmatrix} .
$$

By a similar reasoning as above (technically by mathematical induction) we can easily show that any
gate composed of the mentioned base gates has the form

$$
  2^{-k/2} (M_1 + \sqrt{2} M_2) ,
$$

where $M_1$ and $M_2$ have only complex integer coefficients and $k$ is the number of $T$ gates
involved. QED.

**** Exercise 4.46 (Exponential complexity growth of quantum systems)
Let $\rho$ be a density matrix describing the state of $n$ qubits. Show that describing $\rho$
requires $4n-1$ independent real numbers.

***** Proof
We know that $\rho\in\CC^{2n\times2n}$. Hence, a priori we need $2\cdot4^n$ real numbers to describe
it. Since $\rho$ is (positive) hermitian, the diagonal entries are real and the off-diagonal entries
above the diagonl determine the off-diagonal entries below the diagonal completely. Hence we are
left with $4^n$ reals. This again reduces by one to $4^n-1$ by the trace condition.

**** Exercise 4.47
For $H=\sum_k^LH_k$, prove that $e^{-iHt}=\prod_ke^{-iH_kt}$ for all $t$ if $[H_j,H_k]=0$, for all
$j$, $k$.

***** Proof
First of all let us observe that it is sufficient to prove the statement for the special case $L=2$
since the general case directly follows from it. Let us restate a "cleaned up" version of the
statement:

Let $A$, $B$ two /commuting/ bounded operators (on the same Hilbert Space). Then
$e^{A+B}=e^Ae^B$. We will prove this statement.

The proof has two key ingredients. The first one is the *Binomial Formula*

$$
  (A + B)^k = \sum_{i=0}^k \binom{k}{i} A^{k-i} B^i .
$$

This formula can be easily proved by mathematical induction on $k$. The commutativity of $A$ and $B$
is needed in the proof and in fact it allows us to take the standard proof, where $A$ and $B$ are
real (or complex) numbers, as a template.

The second ingredient is the *Cauchy Product Formula*:

$$
  \left( \sum_{i=0}^\infty a_i \right) \cdot \left( \sum_{i=0}^\infty b_j \right)
  = \sum_{k=0}^\infty \sum_{i=0}^k a_{k-i} b_i .
$$

This formula holds under rather general conditions. One sufficient condition is that the two series
on the left are both absolutely convergent series (in a space of bounded operators over a Hilbert
Space). In fact, no commutativity is required and even associativity is unnecessary (the results
holds in abstract Banach Algebras).

Now let us come back to our problem. From the binomial formula we deduce:

$$
  e^{A+B} = \sum_{k=0}^\infty \frac{1}{k!} (A+B)^k
  = \sum_{k=0}^\infty \frac{1}{k!} \sum_{i=0}^k \binom{k}{i} A^{k-i} B^i
  = \sum_{k=0}^\infty \sum_{i=0}^k \frac{1}{(k-i)!} A^{k-i} \cdot \frac{1}{i!} B^i .
$$

The RHS has the form of the RHS of the Cauchy Product formula. Hence

$$
  e^{A+B} = e^A e^B
$$

as desired. QED.

**** Exercise 4.48
Show that the restriction of $H_k$ to involve at most $c$ particles implies that in the sum (4.97):

$$
  H = \sum_{k=1}^L H_k .
$$

$L$ is upper bounded by a polynomial in $n$.

***** Proof
I suppose that $n$ is the number of qubits. We assume that any particle is described by at most $m$
qubits. This implies that each Hamiltonian involves at most $mc$ qubits.

Moreover we assume that there are only a finite number $K$ of /types/ of interactions. As an example
consider a special case of the (quantum) Ising Model (aka [[https://en.wikipedia.org/wiki/Quantum_Heisenberg_model][Heisenberg Model]]) with periodic boundary
conditions:

$$
  H = -\frac{J}{2} \sum_{i=0}^n X_i X_{i+1} - h \sum_{j=1}^n Z_j .
$$

Here we have $c=2$, $m=1$ and $K=2$. More generally the two particle interaction could also involve
$Y_iY_{i+1}$ and $Z_iZ_{i+1}$ contributions, in which case we had $K=4$.

In the extreme case that each combination of $c$ particles gets a Hamiltonian of each type we get
the maximum value for $L$. So we get the upper bound

$$
  K \binom{n/m}{c} = O(Km^{-c} n^c)
$$

/if/ each particle needs /exactly/ $m$ qubits. In general at least some particles could need less
qubits. So the save upper bound is:

$$
  L \leq K \binom{n}{c} = O(K n^c) .
$$

Note that not each type of Hamiltonian needs to act on all $c$ particles. In that case the
inequality is already strict, since then the given binomial coefficient overestimates the possible
combinations. QED.

**** Exercise 4.49 (Baker–Campbell–Hausdorff formula)
Let $A$ and $B$ be bounded operators (on a Hilbert Space). Prove that

$$
  e^{(A+B)t} = e^{At} e^{Bt} e^{-\frac{1}{2} [A,B] t^2} + O(t^3)
$$

near $t=0$ and also prove these equations:

\begin{align}
  e^{(A + B)t} &= e^{At} e^{Bt} + O(t^2) , \\
  e^{(A + B)t} &= e^{Bt/2} e^{At} e^{Bt/2} + O(t^3) .
\end{align}

*Remarks:*
- I cleaned up the formulation a little bit, but it is essentially the same exercise.
- According to [[https://en.wikipedia.org/wiki/Baker%E2%80%93Campbell%E2%80%93Hausdorff_formula][wikipedia]] the above formula is a variant called the /Zassenhaus/ formula. In fact,
  BCH deals with the related but slightly different problem of finding the solution $C$ of
  $e^{Ct}=e^{At}e^{Bt}$.

***** Proofs
Let us first prove formula (1) - because it is the simplest. In fact, it directly follows from first
order approximating all involved exponential series:

$$
  e^{(A+B)t} = I + (A+B)t + O(t^2) = e^{At} e^{Bt} + O(t^2) .
$$

*Remark:* From this we easily obtain the Trotter Formula (Theorem 4.3) by replacing
$t\,\leftarrow\,t/n$ and taking the $n$​-th power. We even get a uniform error estimate $O(1/n)$ if
$t$ is restricted to a fixed interval $[0,t_0]$. Of course the original proof shows the same
(including the error estimate), but it contains an error: It is not true that
$\binom{n}{k}/n^k=(1+O(1/n))/k!$. Set $k=n$ to see this.

The other two formulas are also showed by comparing power series. This rather boring task can be
done by =sympy=. Hence let us define three symbols. Two non-commuting symbols for the operators and
a commuting symbol for the time:

#+name: exercise-4.49-1
#+begin_src python
  A, B = sp.symbols('A B', commutative=False)
  t = sp.symbols('t', commutative=True)  # commutes with A and B
#+end_src

For a warm up let us return to formula (1):

#+name: exercise-4.49-2
#+begin_src python :results replace
  E1 = exp((A+B)*t) - exp(A*t)*exp(B*t)
  E1.series(t, 0, 3)
#+end_src

#+RESULTS: exercise-4.49-2
: t**2*(-A*B/2 + B*A/2) + O(t**3)

This of course shows the claim again. But it is slightly more precise. The $t^2$ term as the
coefficient $-[A,B]/2$. In a sense this already proves the BCH formula (since the exponential's
leading term is $I$). But let us check it anyway. We increase the order of the series expansion to
$4$ since we are curious what the first non-vanishing term looks like:

#+name: exercise-4.49-3
#+begin_src python :results replace
  E2 = exp((A+B)*t) - exp(A*t)*exp(B*t)*exp(-(A*B-B*A)*t**2/2)
  E2.series(t, 0, 4)
#+end_src

#+RESULTS: exercise-4.49-3
: t**3*(-A*B*A/3 - A*B**2/3 + A**2*B/6 + 2*B*A*B/3 + B*A**2/6 - B**2*A/3) + O(t**4)

Now let us check formula (2):

#+name: exercise-4.49-4
#+begin_src python :results replace
  E3 = exp((A+B)*t) - exp(B*t/2)*exp(A*t)*exp(B*t/2)
  E3.series(t, 0, 4)
#+end_src

#+RESULTS: exercise-4.49-4
: t**3*(A*B*A/6 + A*B**2/24 - A**2*B/12 - B*A*B/12 - B*A**2/12 + B**2*A/24) + O(t**4)

Comparing this with the third order term of the BCH formula it looks like this formula has a
slightly better error estimate (the coefficients are smaller). But this is speculation at this
point!

QED.

**** Exercise 4.50
Let $H=\sum_{k=1}^L H_k$, and define

$$
  U_{t} = \left[ e^{-iH_1 t} e^{-iH_2 t} \ldots e^{-iH_L t}  \right]
    \left[ e^{-iH_L t} e^{-iH_{L-1} t} \ldots e^{-iH_1 t}  \right] .
$$

1. Prove that $U_{t}=e^{-2iHt}+O(t^3)$ near $t=0$.
2. Use the results in Box 4.1 to prove that there exists an $\alpha>0$ such that
   $$
     \norm{U^m_t - e^{-2miHt}} \leq m\alpha |t|^3 ,
   $$
   for all positive integers $m$.

***** Proof
The first part is a direct consequence of one of the formulas proved in Exercise 4.49:

$$
  e^{(A + B)t} = e^{Bt/2} e^{At} e^{Bt/2} + O(t^3) .
$$

The rest of the proof is just mathematical induction on $L$. The base case $L=0$ is trivial (holds
even with a zero-error). The induction step uses the above formula.

The case $m=1$ of the second part is /essentially/ a reformulation of the first part. In fact the
first part shows that there is a $t_0>0$ such that the inequality holds for all
$t\in[-t_0,t_0]$. But for $t>t_0$ we can use that the LHS is bounded by $2$. Hence the inequality
also holds in that range after possibly adjusting $\alpha$. The general case follows from the case
$m=1$ because all involved operators are unitary and hence the error estimates just add up according
to Box 4.1. QED.

**** Exercise 4.51
Construct a quantum circuit to simulate the Hamiltonian

$$
  \mathcal{H} = X_1 \otimes Y_2 \otimes Z_3 .
$$

performing the unitary transform $e^{-i\Delta t\mathcal{H}}$ for any $\Delta t$.

***** Solution
Let

$$
  H = \frac{1}{\sqrt{2}} \begin{bmatrix} 1 & 1 \\ 1 & -1 \end{bmatrix}, \quad
  K = \frac{1}{\sqrt{2}} \begin{bmatrix} i & -1 \\ -1 & i \end{bmatrix}.
$$

The first matrix is the Hadamard gate. Recall $HXH=Z$. The second matrix is chosen so that
$K^\dagger YK=Z$. To construct it we just calculated the eigenvectors of =Y= and used them as
columns in $K$. Hence

$$
  \mathcal{H} = H\otimes K^\dagger\otimes I \cdot Z_1\otimes Z_2\otimes Z_3 \cdot H\otimes K\otimes I .
$$

Observe that $K=iR_x(\pi/2)$. Note that the factor $i$ in the rotation operator representation of
$K$ and $K^\dagger$ cancels out when diagonalizing: $R_x(\pi/2)YR_x(-\pi/2)=Z$. Hence

$$
  \mathcal{H} = H\otimes R_x(\pi/2)\otimes I \cdot Z_1\otimes Z_2\otimes Z_3 \cdot H\otimes R_x(-\pi/2)\otimes I ,
$$

and thus:

$$
  e^{-i\mathcal{H} \Delta t} =
  H\otimes R_x(\pi/2)\otimes I \cdot
  e^{-i Z_1\otimes Z_2\otimes Z_3 \Delta t}
  \cdot H\otimes R_x(-\pi/2)\otimes I .
$$

From the book we already know how to construct the operator in the middle (Figure 4.19). The
complete circuit is:

#+RESULTS: exercise-4.51
:         ┌───┐                                                ┌───┐
: q_0: ───┤ H ├──────■───────────────────────────────────■─────┤ H ├────
:      ┌──┴───┴───┐  │                                   │  ┌──┴───┴───┐
: q_1: ┤ Rx(+π/2) ├──┼────■─────────────────────────■────┼──┤ Rx(-π/2) ├
:      └──────────┘  │    │                         │    │  └──────────┘
: q_2: ──────────────┼────┼────■───────────────■────┼────┼──────────────
:                  ┌─┴─┐┌─┴─┐┌─┴─┐┌─────────┐┌─┴─┐┌─┴─┐┌─┴─┐
: |0>: ────────────┤ X ├┤ X ├┤ X ├┤ Rz(2Δt) ├┤ X ├┤ X ├┤ X ├────────────
:                  └───┘└───┘└───┘└─────────┘└───┘└───┘└───┘

#+name: exercise-4.51
#+begin_src python :results replace :exports results
  params = (Param('+π/2'), Param('-π/2'), Param('2Δt'))

  qc = QuantumCircuit(4)

  qc.h(0)
  qc.rx(params[0], 1)

  qc.cx(0, 3)
  qc.cx(1, 3)
  qc.cx(2, 3)

  qc.rz(params[2], 3)

  qc.cx(2, 3)
  qc.cx(1, 3)
  qc.cx(0, 3)

  qc.rx(params[1], 1)
  qc.h(0)

  str(qc.draw('text')).replace('q_3', '|0>')
#+end_src

** WIP Chapter 5
:PROPERTIES:
:header-args:python: :session *global* :tangle yes :comments link :results silent :exports both
:END:
*** Setup
These are the operators $R_k$ appearing in the implementation of the Fourier Transform:

#+name: chapter-5-Rk
#+begin_src python
  k = sp.symbols('k', integer=True)
  Rk = sp.simplify(exp(2*pi*I*2**(-k-1)) * Rz.subs(theta, 2*pi*2**(-k)))
#+end_src

*** Exercises
**** Exercise 5.1
Give a direct proof that the linear transformation defined by Equation (5.2):

$$
  y_k = \frac{1}{\sqrt{N}} \sum_{j=0}^{N-1} x_j e^{\frac{2\pi\ii}{N}jk}
$$

is unitary.

***** Proof
An operator is unitary iff it maps one (arbitrarily chosen) orthonormal basis to an orthonormal
basis. In other words, it suffices to show that

$$
  \langle m| \FT^\dagger \FT |n\rangle = \delta_{mn} .
$$

Let us abbreviate $a=e^{2\pi\ii/N}$. For $n\neq m$, using the formula for /geometric series/, we have:

$$
  \langle m| \FT^\dagger \FT |n\rangle = \frac{1}{N} \sum_{kj} a^{nj-mk} \langle k|j\rangle
  = \frac{1}{N} \sum_{k} a^{(n-m)k}
  = \frac{a^{(n-m)N}-1}{a^{n-m}-1}
  = 0 .
$$

On the other hand, for $n=m$ the summation over $k$ in the above equality chain clearly equals
$1$. QED.

**** Exercise 5.2
Explicitly compute the Fourier transform of the $n$ qubit state $|00\ldots0\rangle$.

***** Solution
We have

$$
  \FT |00\ldots0\rangle = \frac{1}{2 ^{n/2}} \sum_{k=0}^{2^n-1} e^{\frac{2\pi\ii}{2^n}k} |k\rangle ,
$$

where we identify the (non-negative) integers $k$ with their (standard) binary representation (as
usual).

**** Exercise 5.3 (Classical fast Fourier transform)
Suppose we wish to perform a Fourier transform of a vector containing $2^n$ complex numbers on a
classical computer. Verify that the straightforward method for performing the Fourier transform,
based upon direct evaluation of Equation (5.1) requires $\Theta(2^{2n})$ elementary arithmetic
operations. Find a method for reducing this to $\Theta(n2^n)$ operations, based upon Equation
(5.4) (the product formula for the Quantum Fourier Transform).

***** Proof
First we consider the standard formula:

$$
  y_k = \frac{1}{2^{n/2}} \sum_{j=0}^{2^n-1} x_j e^{\frac{2\pi\ii}{2^n}jk}
$$

The following five "rather" elementary operations on real ($x$), complex ($z_{i}$), and integers
($n$) arguments are sufficient to compute the above expression:

$$
  (z_1,z_2)\mapsto z_1 + z_2 ;\quad (z_1,z_2)\mapsto z_1\cdot z_2;
  \quad x\mapsto \sqrt{x} ;\quad x\mapsto e^{2\pi\ii x} ;\quad
  n\mapsto 2^{-n} .
$$

The exercise does not specify what an "elementary" operation is. But I think it is necessary to have
at least an informal characterization of what we mean by "elementary". We call an operation
/elementary/ if it can be implemented with the help of constantly many instructions from the
instruction set of a modern computer processor (take a normal laptop as example).

To be a little bit more specific, we model a "modern computer" by the instruction set of [[https://webassembly.github.io/spec/core/syntax/instructions.html][webassembly]]
(WASM). This makes sense since webassembly aims to be compatible with a wide range of concrete
architectures.

Note that an operation consisting of constantly many elementary operations is itself
elementary. In the following we give a /justification/ why the above functions are elementary.

The first three operations are usually "elementary enough" to be directly available on (classical)
hardware - at least for (real) single or double precision floating point numbers. The corresponding
/instructions/ are called =add=, =mul= and =sqrt= in WASM. What exactly these instructions do
(adding two numbers and returning the result, or replacing one number by its sum with another one)
is not relevant for us. What matters, is that this shows that the first three operations are indeed
easy to compute on modern hardware.

The fourth operation can be implemented by the cosine and sine function, exploiting the well known
formula $e^{i\theta}=\cos\theta+\ii\sin\theta$. Some architectures have =sin= and =cos= as
instructions. This is not the case for WASM. Instead a WASM programmer has to use a library. But
since cosine and sine are just unavoidable here and ubiquitous anyway, let us cheat here a bit and
declare those functions to be elementary.

The fifth operation is a /little bit/ tricky too. A simple implementation would require $n-1$
multiplications. A well-known trick, utilizing $a^{2k}=(a^k)^2$ and $a^{2k+1}=a\cdot(a^k)^2$,
reduces this to $\Theta(\log(n))$ multiplications. Quite fast but an elementary operation should
need a constant number of instructions. Fortunately there is an even simpler way. First calculate
$2^n$ by taking $1$ and applying a left shift with $n$ (=shl= in WASM). In many programming
languages this is written ~1<<n~ and it is typically crucial to work with /integer/ types instead of
floats (since bit-shifts have no meaningful semantics on floats). Then convert to a float
(=f64.reinterpret.i64=) and obtain $2^{-n}=1/2^n$ (=div=).

Actually counting the number of operations is rather trivial. Clearly

$$
  y_k = \frac{1}{2^{n/2}} \sum_{j=0}^{2^n-1} x_j e^{\frac{2\pi\ii}{2^n}jk}
$$

needs $\Theta(2^n)$ of the above basic operations. We have to do this for $k\in\{0,1,\ldots,2^n-1\}$
resulting in a total of $\Theta(2^{2n})$ operations.

Now let us turn to the fast Fourier transform. The product formula involves the following function

$$
  (k,j)\mapsto e_k(j) := e^{2\pi\ii \cdot 0.j_{n-k+1}\ldots j_n} .
$$

Note

$$
  0.j_{n-k+1}\ldots j_n = j 2^{-k} \mod 1 = \mathrm{trunc}(j 2^{-k}).
$$

Since the truncation operation (=trunc=) is a valid WASM instruction, we see that $e_k(j)$ is
comprised of constantly many elementary operations and thus is elementary itself.

Given a vector of complex numbers $x$, let us write $|x\rangle=\sum_jx_j|j\rangle$. In the
following, the basic idea is to reduce a /call/ to the Fourier transform $\FT_n$ on $n$ bits to two
calls of the Fourier transform $\FT_{n-1}$ on $n-1$ bits - recursively. By the product formula,
writing $j=2j'+j_n$, we have

\begin{align*}
  \, |y\rangle &:= \FT_n |x\rangle
  = 2^{-n/2} \sum_{j=0}^{2^n-1} x_j \bigotimes_{k=1}^n (|0\rangle + e_k(j)|1\rangle) \\
  &= 2^{-n/2} \sum_{j=0}^{2^n-1} x_j (|0\rangle + (-1)^{j_n}|1\rangle)
     \bigotimes_{k=1}^{n-1} (|0\rangle + e^{2\pi\ii j_n 2^{-k-1}} e_k(j')|1\rangle) \\
  &= \frac{1}{\sqrt{2}} \sum_{j_n=0}^1 (|0\rangle + (-1)^{j_n}|1\rangle)
     \underbrace{
       2^{-(n-1)/2} \sum_{j'=0}^{2^{n-1}-1} x_{2j'+j_n} (|0\rangle + e^{2\pi\ii j_n 2^{-k-1}} e_k(j')|1\rangle)
     }_{=:|z^{(j_n)}\rangle} .
\end{align*}

Let us denote the $2^{n-1}$ dimensional vectors $(x_{2j'+j_n})_{j'}$ by $x^{(j_n)}$. Let
$|y^{(j_n)}\rangle=\FT_{n-1}|x^{(j_n)}\rangle$. Then we have

$$
  \,|z^{(0)}\rangle = |y^{(0)}\rangle = \sum_{j'=0}^{2^{n-1}-1} y^{(0)}_{j'}|j'\rangle
  \text{ and } |z^{(1)}\rangle = \sum_{j'=0}^{2^{n-1}-1} e^{2\pi\ii j'2^{-n}} y^{(0)}_{j'} |j'\rangle .
$$

The first equality follows directly from the product formula. The second one also follows from the
product formula - note that the bit pattern of $|j'\rangle$ dictates which of the factors
$e^{2\pi\ii\,j_n2^{-k-1}}$ appear in the coefficients. Lets go on with the calculation:

\begin{align*}
  \,|y\rangle &= \frac{1}{\sqrt{2}} \sum_{j_n=0}^1 (|0\rangle + (-1)^{j_n}|1\rangle) |z^{(j_n)}\rangle \\
  &= \frac{1}{\sqrt{2}} \sum_{j=0}^{2^n-1} (|0\rangle + (-1)^{j_n}|1\rangle) z^{(j_n)}_{j'} |j'\rangle \\
  &= \sum_{j'=0}^{2^{n-1}-1} \underbrace{\frac{1}{\sqrt{2}}(z^{(0)}_{j'} + z^{(1)}_{j'})}_{y_{j'}} |0j'\rangle +
     \sum_{j'=0}^{2^{n-1}-1} \underbrace{\frac{1}{\sqrt{2}}(z^{(0)}_{j'} - z^{(1)}_{j'})}_{y_{2^{n-1}+j'}} |1j'\rangle .
\end{align*}


Let us briefly summarize the algorithm for calculating the coefficients of $|y\rangle$ which can be
extracted from the above calculations:

1. Calculate $|y^{(j_n)}\rangle=\FT_{n-1}|x^{(j_n)}\rangle$ - recursively as long as $n>1$,
2. Calculate $|z^{(j_n)}\rangle$ from $|y^{(j_n)}\rangle$ as above,
3. Calculate $|y\rangle$ from $|z^{(j_n)}\rangle$ as above,

where $j_n\in\{0,1\}$. Let $c_n$ be the number of elementary operations required by this
algorithm. Clearly step one needs $2c_{n-1}$ operations. Step two needs at most $c2^n$ operations
for some constant $c$. The same is true for step three - possibly enlarging $c$. Hence

$$
  c_{n} \leq 2c_{n-1} + 2c2^n .
$$

It is not hard to see that this implies

$$
  c_{n} \leq 2(n-1)c2^n + 2^{n-1} c_1 = O(n2^n) .
$$

It is also not hard to see that $n2^n$ is also a lower bound (up to a constant factor) for the
number of operations. QED.

**** Exercise 5.4
Give a decomposition of the controlled-$R_k$ gate into single qubit and =CNOT= gates.

***** Solution
Let us abbreviat $\theta_k=2\pi2^{-k}$. Note that $R_k=e^{\ii\theta_{k+1}}R_z(\theta_k)$. It is easy
to find a solution based on the ABC-construction from Figure 4.6 and the proof of Corollary 4.2.

In fact, the following circuit ($C=B=R_{k+1}^\dagger$, $A=R_k$, $\alpha=\theta_{k+1}$) implements $C(R_k)$:

#+RESULTS: exercise-5.4-circuit
:                                          ┌─────────┐
: q_0: ───────────────■─────────────────■──┤ R_{k+1} ├
:      ┌───────────┐┌─┴─┐┌───────────┐┌─┴─┐└─┬─────┬─┘
: q_1: ┤ R_{k+1}^† ├┤ X ├┤ R_{k+1}^† ├┤ X ├──┤ R_k ├──
:      └───────────┘└───┘└───────────┘└───┘  └─────┘

#+name: exercise-5.4-circuit
#+begin_src python :results replace :exports results
  from qiskit.circuit import Gate

  qc = QuantumCircuit(2)
  C=Gate("R_{k+1}^†", 1, [])
  qc.append(C, [1])
  qc.cx(0, 1)
  B=Gate("R_{k+1}^†", 1, [])
  qc.append(B, [1])
  qc.cx(0, 1)
  A=Gate("R_k", 1, [])
  qc.append(A, [1])
  R=Gate("R_{k+1}", 1, [])
  qc.append(R, [0])

  str(qc.draw('text'))
#+end_src

To see this recall that $XZX=-Z$. Hence by the functional calculus

$$
  XR_{k+1}^\dagger X = e^{-\ii\theta_{k+2}} XR_z(-2\pi2^{-k-1})X
  = e^{-\ii\theta_{k+2}} R_z(2\pi2^{-k-1}) = e^{-\ii\theta_{k+1}} R_{k+1} .
$$

The factor $e^{\ii\theta_{k+1}}$ gets compensated by the $R_{k+1}$ on the upper qubit. The claim
follows from this together with $R_k=R_{k+1}^2$. QED.

**** Exercise 5.5
Give a quantum circuit to perform the inverse quantum Fourier transform.

***** Solution
The standard way to get the invere of some circuit is to just write down all the gates in revers
order and conjugate them (replace $R_k$ by $R_k^\dagger$ in our case since =SWAP= and $H$ are
self-inverse).

Actually it is sufficient to /just/ replace all $R_k$ by $R_k^\dagger$ (and not reverse the gate
order). To see this, recall that the inverse Fourier transform is given by

$$
  x_k = \frac{1}{\sqrt{N}} \sum_{j=0}^{N-1} y_j e^{-\frac{2\pi\ii}{N}jk} .
$$

The difference to the Fourier transform itself is just the minus sign - which could be put into $j$
when deriving the product formula for the /inverse/ Fourier transform:

$$
  \FT^\dagger :
\, |j\rangle \mapsto
   \frac{\left(|0\rangle + e^{-2\pi\ii0.j_n}\right) \left(|0\rangle + e^{-2\pi\ii0.j_{n-1}j_n}\right)
   \cdots \left(|0\rangle + e^{-2\pi\ii0.j_1j_2\ldots j_n}\right)}{2^{n/2}} .
$$

**** Exercise 5.6 (Approximate quantum Fourier transform)
The quantum circuit construction of the quantum Fourier transform apparently requires gates of
exponential precision in the number of qubits used. However, such precision is never required in any
quantum circuit of polynomial size. For example, let $U$ be the ideal quantum Fourier transform on
$n$ qubits, and $V$ be the transform which results if the controlled-$R_k$ gates are performed to a
precision $\Delta=1/p(n)$ for some polynomial $p(n)$. Show that the error
$\norm{U-V}=\max_{|\psi\rangle}\norm{(U-V)|\psi\rangle$ scales as $\Theta(n^2/p(n))$, and thus
polynomial precision in each gate is sufficient to guarantee polynomial accuracy in the output
state.

***** Proof
This is actually a direct consequence of Box 4.1 and the fact that the implementation of the Fourier
transform has $m=\Theta(n^2)$ gates. In fact, writing $U=\prod_{i=1}^mU_i$ as the product of its
implementing gates, and similarly $V$ we see that

$$
  \norm{U-V} = \norm{\prod_{i=1}^mU_i - \prod_{i=1}^mV_i}
  \leq \sum_{i=1}^m \norm{U_i - V_i}
  \leq m \Delta = \Theta(n^2 / p(n)) .
$$

The first inequality is the second statement in Box 4.1 (errors of products of unitary operators
/at worst/ add up). QED.

**** Exercise 5.7
Additional insight into the circuit in Figure 5.2 may be obtained by showing, as you should now do,
that the effect of the sequence of controlled-$U$ operations like that in Figure 5.2 is to take the
state $|j\rangle|u\rangle$ to $|j\rangle\,U^j|u\rangle$ (Note that this does not depend on
$|u\rangle$ being an eigenstate of $U$.)

***** Proof
This is more or less obvious but let us go at least a little bit into detail.

Let $G_k$ for $k=0,\ldots,t-1$ be the $k$​-th of the controlled powers of $U$ (from the left as
viewed in the circuit, that is, in application order).

By definition we have

$$
  G_k |j\rangle |u\rangle = \begin{cases} |j\rangle |u\rangle & \text{if } j_k=0 \\ |j\rangle U^{2^k} |u\rangle & \text{if } j_k=1 \end{cases}
  = |j\rangle U^{j_k2^k} |u\rangle .
$$

Thus

$$
  \prod_{k=0}^{t-1} G_k |j\rangle |u\rangle = |j\rangle \prod_{k=0}^{t-1} U^{j_k2^k} |u\rangle
  = |j\rangle U^{\sum_{k=0}^{t-1} j_k 2^k} |u\rangle
  = |j\rangle U^j |u\rangle .
$$

QED.

**** Exercise 5.8
Suppose the phase estimation algorithm takes the state $|0\rangle|u\rangle$ to the state
$|\tilde{\varphi}_u\rangle|u\rangle$, so that given the input $|0\rangle(\sum_uc_u|u\rangle)$, the
algorithm outputs $\sum_uc_u|\tilde{\varphi}_u\rangle|u\rangle$. Show that if $t$ is chosen
according to (5.35), then the probability for measuring $\varphi_u$ accurate to $n$ bits at the
conclusion of the phase estimation algorithm is at least $|c_u|^2(1-\varepsilon)$.

***** Proof
The action of the phase estimation circuit is

$$
\,|0\rangle(\sum_uc_u|u\rangle) \mapsto \sum_uc_u|\tilde{\varphi}_u\rangle|u\rangle
$$

by linearity of the circuit - as claimed by the exercise statement. Tracing out the $u$​-register (in
the RHS) yields the following mixed state in the first register:

$$
  \rho = \sum_u |c_u|^2 |\tilde{\varphi}_u\rangle \langle\tilde{\varphi}_u| .
$$

Let us now consider /any/ of the eigenstates $|u\rangle$ - call it $|v\rangle$ to give it distinct
name. Let $b<2^t$ be any non-negative integer with $|\varphi_v-b|\,\leq\,e$, where $e$ is as in the
book, guaranteeing that $b$ approximates $\varphi_v$ by at least $n$ bits. The probability to
measure $b$ is given by:

$$
  p(b) = \trace{|b\rangle\langle b|\rho} = \trace{|b\rangle\langle b| \rho |b\rangle\langle b|}
  \geq \trace{|b\rangle\langle b| |c_v|^2|\tilde{\varphi}_v\rangle\langle\tilde{\varphi}_v| |b\rangle\langle b|}
  = |c_v|^2 |\langle b|\varphi_v\rangle|^2 .
$$

The inequality above follows from the fact that each summand in $\rho$, even when conjugated with
some projection, yields a non-negative contribution to the trace. Hence the probability to measure
one of the $b$ which approximate $\varphi_v$ by at least $n$ bits is at least
$|c_v|^2(1-\varepsilon)$ (by the choice of $t$ and what was shown in the book for the special case
$c_v=1$). QED.

**** Exercise 5.9
Let $U$ be a unitary transform with eigenvalues $\pm1$, which acts on a state $|\psi\rangle$. Using
the phase estimation procedure, construct a quantum circuit to collapse $|\psi\rangle$ into one or
the other of the two eigenspaces of $U$, giving also a classical indicator as to which space the
final state is in. Compare your result with Exercise 4.34.

***** Solution
In this case the two phases are $\varphi_+=0$ and $\varphi_-=1/2$. Since these two numbers can be
expressed /exactly/, utilizing just a single bit, it is sufficient to take the phase estimation
circuit with $t=1$ (any larger value would work too of course). Measuring $1$ (or more generally
$2^{t-1}$) means a collapse onto the $-1$ eigenstate. Measuring $0$ means a collapse onto the $+1$
eigenstate.

In hindsight we see that in exercise 4.34 we already used this special case of the phase estimation
circuit. We also note that the Hadamard gate is the Fourier transform on a single qubit.

**** Exercise 5.10
Show that the order of $x=5$ modulo $N=21$ is $6$.

***** Proof
It is probably easiest to just make a table:

| $i$           | 1 | 2 |  3 |  4 |  5 | 6 |
| $5^i \mod 21$ | 5 | 4 | 20 | 16 | 17 | 1 |

The powers of $x=5$ can be calculated sequentially by repeatedly multiplying by $5$ and taking the
rest after deviding by $21$. QED.

**** Exercise 5.11
Show that the order of $x$ satisfies $r\leq N$.

***** Proof
By the pigeonhole principle there are $a,b\in\{1,2,\ldots,N+1\}$ with $a < b$ such that
$x^a=x^b$. Since $x$ and $N$ are coprime we can divide this by $x^a$ (see also Exercise A4.12) and
obtain

$$
  x^{b-a} = 1 \mod N .
$$

Hence $r\leq b-a\leq N$. QED.

**** Exercise 5.12
Show that $U$ (see (5.36)) is unitary (Hint: $x$ is co-prime to $N$, and therefore has an inverse
modulo $N$).

***** Proof
Recall that $U$ only acts non-trivially on basis states $|i\rangle$ with $i < N$. In that case

$$
  U|i\rangle = |xi\mod N\rangle .
$$

It is sufficient to prove that the restriction of $U$ to the non-trivial sub-space is unitary. Note
that the mapping

$$
  \pi: i \mapsto xi \mod N
$$

is a permutation on $\{0,1,\ldots,N-1\}$ since $x$ has a multiplicative inverse modulo $N$. Observe that

$$
  \langle i| U^\dagger U|j\rangle = \langle\pi(i)|\pi(j)\rangle = \delta_{ij}
$$

since $\pi$ is a permutation. This implies that $U$ is unitary. QED.

- Remark :: We have actually shown that $U$ is a permutation on the computational basis.

**** Exercise 5.13
Prove (5.44). (Hint: $\sum_{s=0}^{r-1}\exp(-2\pi\ii sk/r)=r\delta_{k0}$.) In fact, prove that

$$
  \frac{1}{\sqrt{r}} \sum_{s=0}^{r-1} e^{2\pi\ii sk/r} |u_s\rangle = |x^k \mod N\rangle .
$$

***** Proof
Let us write $x^k$ instead of $x^k\mod N$ for short.

$$
  \frac{1}{\sqrt{r}} \sum_{s=0}^{r-1} e^{2\pi\ii sk/r} |u_s\rangle
  = \frac{1}{r} \sum_{s,l=0}^{r-1} e^{2\pi\ii s(k-l)/r} |x^l\rangle
  = \sum_{l=0}^{r-1} \delta_{kl} |x^l\rangle
  = |x^k\rangle .
$$

The second equality uses the hint given in the formulation of the exercise. QED.

**** TODO Exercise 5.14
The quantum state produced in the order-finding algorithm, before the inverse Fourier transform, is

$$
\, |\psi\rangle = \frac{1}{2^{t/2}} \sum_{j=0}^{2^t-1} |j\rangle U^j |1\rangle
  = \frac{1}{2^{t/2}} \sum_{j=0}^{2^t-1} |j\rangle |x^j \mod N \rangle ,
$$

if we initialize the second register as $|1\rangle$. Show that the same state is obtained if we
replace $U^j$ with a /different/ unitary transform $V$, which computes

$$
  V |j\rangle |k\rangle = |j\rangle |k + x^j \mod N\rangle ,
$$

and start the second register in the state $|0\rangle$. Also show how to construct $V$ using
$O(L^3)$ gates.

***** Proof
The first part of the claim, that we can replace the controlled $U^j$ by $V$ and $|1\rangle$ by
$|0\rangle$ without changing the output of the algorithm is obvious. It remains to show the $V$ can
be implemented by $O(L^3)$ gates.

* COMMENT References
# TODO: once the deployment uses org v9.5 or higher org-cite is properly supported and we can
# uncomment this section.
#+print_bibliography:
