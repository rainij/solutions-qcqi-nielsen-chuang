#+title:  Chapter 8
#+author: Reinhard Stahn
#+setupfile: ./inc/setupfile.org
#+include: ./inc/latex-macros.org
#+property: header-args:sage :session *sage-chapter-8* :tangle chapter_8.sage


#+toc: headlines 2

* Setup
** Imports
#+name: imports-chapter-8-1
#+begin_src sage
  from utils_sage import Id, X, Y, Z, delta, eps, inner
#+end_src

Let us set up some variables

#+name: global-variables
#+begin_src sage
  p, g = SR.var('p g', domain='positive')
  x, y, z, e = SR.var('x y z e', domain='real')
  u, v, w, s = SR.var('u v w s', domain='complex')

  # We want to use p as a probability, not sure if this does anything, but looks useful:
  assume(p <= 1)
  assume(g <= 1)
#+end_src

** Bloch sphere representation
*** Derivation of the formula for $M_{jk}$ and $c_k$
:PROPERTIES:
:CUSTOM_ID: chapter-8-bloch-M-c
:END:
For convenience I provide a derivation of formulas (8.91) and (8.92) for the
representation of a quantum operation on a single-qubit principal system:

\begin{align*}
  M_{jk} &= \sum_l \left[
    a_{lj} a_{lk}^* + a_{lj}^* a_{lk} +
    \left(\abs{\alpha_l}^2 - \sum_p \abs{a_{lp}}^2 \right) \delta_{jk} +
    \ii \sum_p \epsilon_{jkp} (\alpha_l a_{lp}^* - \alpha_l^* a_{lp})
  \right] , \\
  c_k &= 2 \ii \sum_l \sum_{jp} \epsilon_{jpk} a_{lj} a_{lp}^* .
\end{align*}

Here we assume that the operation elements look as follows:

$$
  E_l = \alpha_l + \sum_{k=1}^3 a_{lk} \sigma_k ,
$$

and satisfy the trace-preserving property $\sum_lE_l^\dagger\?E_l=1$ (here and in the
following I write scalars in place of multiples of the identity matrix). Let

$$
  \rho = \frac{1}{2} (1 + r_k \sigma_k) .
$$

Throughout this section (about Bloch sphere) let us apply a variant of *Einsteins
summation convention*. Whenever a free index appears twice in a /product expression/ we
sum over it. For example, the above formula for $\rho$ means

$$
  \rho = \frac{1}{2} (1 + \sum_k r_k \sigma_k) .
$$

As a special case we implicitly read $\abs{x_i}^2$ as $x_ix_i^*$ and hence imply summation
over $i$ in case of a square of an absolute value too. Let us start by considering the
trace-preserving condition

$$
  1 = E_l^\dagger E_l = (\alpha_l^* + a_{lp}^*\sigma_p) (\alpha_l + a_{lp}\sigma_q)
  = \abs{\alpha_l}^2 + \alpha_l^* a_{lp} \sigma_p + \alpha_l a_{lp}^* \sigma_p + a_{lp}^*a_{lp} \sigma_p \sigma_q .
$$

Note that $\sigma_p\sigma_q=\ii\epsilon_{pqk}\sigma_k+\delta_{pq}$. Hence

$$
  1 = \abs{\alpha_l}^2 + \abs{a_{lp}}^2 +
    2\Re(\alpha_la_{lk}^*)\sigma_k + \ii\epsilon_{pqk} a_{lp}^* a_{lq} \sigma_k .
$$

We can deduce the two constraints the coefficients $\alpha$ and $a$ have to satisfy in
order for the trace-preserving property to hold (we use here that the Pauli operators
together with the identity are a (orthonormal) basis of $\CC^{2\times2}$):

<<trace-preserving-condition-1>>
$$
  \abs{\alpha_l}^2 + \abs{a_{lp}}^2 = 1 ,
$$

and

<<trace-preserving-condition-2>>
$$
  \forall k: \; \ii\epsilon_{pqk} a_{lp}^* a_{lq} = -2\Re(\alpha_la_{lk}^*) .
$$

Now consider

$$
  2 \calE(\rho) =
  2 E_l \rho E_l^\dagger = (\alpha_l + a_{lp}\sigma_p) (1 + r_k \sigma_k) (\alpha_l^* + a_{lq}^*\sigma_q)
  =: I_1 + I_2 ,
$$

where the $I_1$ corresponds to the $1$ in the middle factor and $I_2$ to the $r_k\sigma_k$
in the middle factor. In case you wonder: the factor of $2$ at the front should make the
expression a bit simpler by avoiding numerous factors $1/2$ in the following.

\begin{align*}
  I_1 &= \abs{\alpha_l}^2 + \alpha_l a_{lp}^* \sigma_p + \alpha_l^* a_{lp} \sigma_p +
    a_{lp}a_{lq}^* \sigma_p\sigma_q \\
  &= \abs{\alpha_l}^2 + \abs{a_{lp}}^2 + 2\Re(\alpha_la_{lk}^*)\sigma_k
    + \ii\epsilon_{pqk} a_{lp} a_{lq}^* \sigma_k \\
  &= 1 + 2\ii \epsilon_{pqk} a_{lp} a_{lq}^* \sigma_k .
\end{align*}

For the last equality we used the [[trace-preserving-condition-1][first]] and [[trace-preserving-condition-2][second]] formula for the
trace-preservation. Since $I_1$ contains the part of $2\calE(\rho)=1+r_k'\sigma_k$ which
does not depend on on the $r_k$ we already proved the formula for $c_k$. The treatment of
$I_2$ is a bit more involved.

\begin{align*}
  I_2 &= \abs{\alpha_l}^2 r_k \sigma_k +
    \alpha_l a_{lp}^* r_k \sigma_k\sigma_p + \alpha_l^* a_{lp} r_k \sigma_p\sigma_k +
    a_{lp} a_{lq}^* r_k \sigma_p \sigma_k \sigma_q \\
  &= \abs{\alpha_l}^2 r_k \sigma_k +
    \alpha_l a_{lp}^* r_k (\ii\epsilon_{kpj}\sigma_j + \delta_{kp}) +
    \alpha_l^* a_{lp} r_k (-\ii\epsilon_{kpj}\sigma_j + \delta_{kp}) +
    a_{lp} a_{lq}^* r_k \sigma_p \sigma_k \sigma_q \\
  &=: I_{20} + I_{21} + I_{22} .
\end{align*}

Here $I_{22}$ stands for the last summand (the product of three Paulis), $I_{21}$ stands for
the two commands involving the $\delta_{kp}$. Finally $I_{20}$ is the rest. Note that
$I_{20}$ already corresponds to terms appearing in the formula for $M_{jk}$ and hence
needs no further treatment. We have

$$
  I_{21} = \alpha_l a_{lk}^* r_k + \alpha_l^* a_{lk} r_k
  = 2 \Re(\alpha_l a_{lk}^*) r_k .
$$

Note that this term cannot have any possible correspondence in $M$ (or $c$). Hence we
expect it to be cancelled by $I_{22}$. Therefore let us finally consider $I_{22}$. Note
that

$$
  \sigma_p \sigma_k \sigma_q = - \sigma_p \sigma_q \sigma_k + 2 \sigma_p \delta_{qk} .
$$

Hence

$$
  I_{22} = (- a_{lp} a_{lq}^* \sigma_p\sigma_q) r_k\sigma_k + 2 a_{lp} a_{lk}^* r_k \sigma_p
  =: J_1 + J_2 .
$$

Moreover

$$
  J_1 = (-\abs{a_{lp}}^2 - \ii\epsilon_{pqs}a_{lp}a_{lq}^* \sigma_s) r_k\sigma_k
  = -\abs{a_{lp}}^2 r_k\sigma_k - \ii\epsilon_{pqk}a_{lp}a_{lq}^* -
    \ii \epsilon_{pqs} a_{lp}a_{lq}^* \sigma_s (r_p \sigma_p + r_q \sigma_q)
  =: J_{10} + J_{11} + J_{12} .
$$

For the second equality I splitted the summation over $k$ into $k=s$ and $k\neq\?s$ (this
leads to a tiny clash with out summation convention but shouldn't be a major hurdle for
understanding the calculations). Note that $J_{10}$ corresponds to a term in $M$, so with
this one we are done. By [[trace-preserving-condition-2][trace-preservation]] we have that

$$
  J_{11} + I_{21} = 0 ,
$$

which is the awaited cancellation for $I_{21}$. So these terms are also done. Recall that
the only still open terms are $J_{12}$ and $J_2$. We will go on with the former.

$$
  J_{12} = -\ii a_{lp} a_{lq}^* \left( \epsilon_{pqs}
    \left[ r_p \ii \epsilon_{spq}\sigma_q + r_q \ii \epsilon_{sqp}\sigma_p \right] \right)
  = a_{lp} a_{lq}^* (r_p\sigma_q - r_q \sigma_p) .
$$

This can be nicely combined with $J_2$:

$$
  J_{12} + J_2 = a_{lp} a_{lq}^* r_p \sigma_q + a_{lp} a_{lq}^* r_q \sigma_p
  = a_{lk} a_{lj}^* r_k \sigma_j + a_{lj} a_{lk}^* r_k \sigma_j ,
$$

which yields the remaining terms in the formula for $M$. QED.

*** Sage code
The following function implements $M$ and $c$ from the previous section in sage.

#+name: single-qubit-operation-elements-bloch
#+begin_src sage
  def affine(*Es):
      """Maps a list of single-qubit operation elements to their Bloch-representation

      Args:
          Es: A list of single qubit operation elements, trace preserving.

      Returns:
          M, c: as in formulas (8.91) and (8.92)
      """
      N = len(Es)

      assert N != 0, "Need at least one operation element"
      assert all([len(E) == 4 for E in Es]), "Need 4 coefficients for each Ei"

      alpha = [E[0] for E in Es]
      bs = [E[1:4] for E in Es]

      M = [[sum(
            bs[l][j] * bs[l][k].conjugate() + bs[l][j].conjugate() * bs[l][k]
            + delta(j, k) * alpha[l] * alpha[l].conjugate()
            - delta(j, k) * sum(bs[l][p] * bs[l][p].conjugate() for p in range(3))
            + I * sum(eps(j, k, p)*(alpha[l]*bs[l][p].conjugate() - alpha[l].conjugate()*bs[l][p])
                      for p in range(3))
          for l in range(N)) for k in range(3)] for j in range(3)]

      c = [sum(sum(sum(
               2*i * eps(j, p, k) * bs[l][j] * bs[l][p].conjugate()
             for p in range(3)) for j in range(3)) for l in range(N))
           for k in range(3)]

      return simplify(matrix(M)), simplify(vector(c))


  def toPauli(M):
      """Takes a 2x2 matrix and returns its coefficients in the Pauli-Basis (I,X,Y,Z)."""
      assert M.dimensions() == (2, 2), "Expected a two dimensional matrix"
      return [inner(p/2, M) for p in [Id, X, Y, Z]]


  def affine2(*Ps):
      """Like affine but applies toPauli before that to accept the operator elements
      directly as matrices."""
      return affine(*[toPauli(p) for p in Ps])
#+end_src

Now we are prepared to consider the examples from the book. First let us consider the
*bit-flip*:

#+name: sage-bit-flip
#+begin_src sage :tangle no :results replace
  E0 = sqrt(p) * Id
  E1 = sqrt(1-p) * X

  M, c = affine(*[toPauli(E) for E in [E0, E1]])

  assert M == matrix.diagonal([1, 2*p-1, 2*p-1])
  assert c == vector([0, 0, 0])
  "PASSED"
#+end_src

#+RESULTS: sage-bit-flip
: 'PASSED'

#+RESULTS:
: 'PASSED'

Next consider the *amplitude damping*:

#+begin_src sage :tangle no :results replace
  E0 = matrix.diagonal([1, sqrt(1-g)])
  E1 = matrix([[0, sqrt(g)], [0, 0]])

  M, c = affine(*[toPauli(E) for E in [E0, E1]])
  M = M.expand()

  assert M == matrix.diagonal([sqrt(1-g), sqrt(1-g), 1-g])
  assert c == vector([0, 0, g])
  "PASSED"
#+end_src

#+RESULTS:
: 'PASSED'

For some exercises I think it is convenient to be able to perform (possibly
non-trace-preserving) single qubit operations. For this the Bloch sphere is not sufficient
anymore, but we still have a representation in $\RR^4$ (see my solution of [[#exercise-8.16][exercise
8.16]]). More precisely on the real subspace of $\CC^{2\times2}$ generated by the
Pauli-operators $(I,X,Y,Z)$.

#+name: single-qubit-operation
#+begin_src sage
  # A generalized density matrix and an arbitrary operator E:
  rho_gen = (e + x*X + y*Y + z*Z)
  E_gen = s*Id + u*X + v*Y + w*Z

  def qop1d(Es, rho):
      """Take a list of operator elements and apply the quantum operation to the given mixed
      single-qubit state. It returns the result as a vector in RR^4 wrt the Pauli basis."""
      rho1 = sum(E * rho * E.H for E in Es)
      return simplify(vector(toPauli(rho1)))
#+end_src

The corresponding matrix is given by

#+name: make_qop1d_matrix_4d
#+begin_src sage
  def make_qop1d_matrix_4d(Es):
      """Return the matrix representation on RR^4 of the operation given by the
      elements. Works for non-trace-preserving operations too."""
      bs = matrix.identity(4)
      return simplify(matrix([[b*qop1d(Es, rho=A) for A in [Id, X, Y, Z]] for b in bs]))
#+end_src

* Exercises
** Exercise 8.1 (Unitary evolution as a quantum operation)
:PROPERTIES:
:CUSTOM_ID: exercise-8.1
:END:
Pure states evolve under unitary transforms as $\ket{\psi}\mapsto\,U\ket{\psi}$. Show
that, equivalently, we may write $\rho\mapsto\calE(\rho)\equiv\,U\rho\,U^\dagger$,
for $\rho=\proj{\psi}$.

*** Proof
**** Preparation
This is a really basic question and it should actually be obvious /if/ you really
understand the bra-ket notation (beware however that it might /appear/ to be obvious if
you merely feel /familiar/ with it).

To give a meaningful solution beyond "it is obvious" we take a step back and recall what
the [[https://en.wikipedia.org/wiki/Bra%E2%80%93ket_notation][bra-ket]] notation actually means. In quantum mechanics we always work on (complex)
Hilbert spaces. A Hilbert space is a (complex) vector space $\calH$ equipped with a
[[https://en.wikipedia.org/wiki/Sesquilinear_form][sesquilinear form]], which has to obey certain axioms to be mentioned soon. We denote it by

$$
  (\ket{\psi}, \ket{\varphi}) .
$$

A sesquilinear form is a mapping $\calH\times\calH\to\CC$ which is linear in the second
argument and conjugate-linear in the first argument. For a Hilbert space we require in
addition that (*positivity*)

$$
  \forall \ket{\psi} \in \calH\backslash\{0\}: \; (\ket{\psi}, \ket{\psi}) > 0 ,
$$

and that (*symmetry*)

$$
  \forall \ket{\psi}, \ket{\varphi} \in \calH : \; (\ket{\psi},\ket{\varphi})
  = \overline{(\ket{\varphi},\ket{\psi})} .
$$

(The bar means /complex conjugation/.) Such a sesquilinear form is called a *scalar
product*. This is what makes a complex /[[https://en.wikipedia.org/wiki/Hilbert_space][Hilbert space]]/, a complex vector space equipped
with a scalar product. There are also real Hilbert spaces but we do not need them
here. Note that we are always talking about /finite/ dimensional vector spaces. In case of
infinite dimensional vector spaces a *[[https://en.wikipedia.org/wiki/Complete_metric_space][completeness]]* axiom is required in addition. (In the
finite dimensional case this axiom follows automatically from the [[https://en.wikipedia.org/wiki/Completeness_of_the_real_numbers][completeness]] axiom of
real (and hence complex) numbers).

In the framework of Dirac's bra-ket notation the kets are just the elements of the Hilbert
space. We already used this in the above introduction. The bras are elements of the /dual
space/ $\calH^*$ which is just the space of linear maps $\calH\to\CC$. For any
$\ket{\psi}\in\calH$ an example of such a map is given by

$$
  \ket{\varphi} \mapsto (\ket{\psi}, \ket{\varphi}) .
$$

<<exercise-8.1-canonical-iso>> In fact, one can prove that any element of $\calH^*$ (that
is, any linear map $\calH\to\CC$) can be written like this for a /unique/
$\ket{\psi}$. This is called the *canonical isomorphism* between $\calH$ and $\calH^*$ (it
is called /canonical/ since we could define it without knowing anything concrete about our
Hilbert space, in other words it is definable in the most abstract terms). Note that the
canonical isomorphism $\iota$ is /conjugate/ linear, that is,
$\iota(\lambda\ket{\psi})=\bra{\psi}\lambda^*$.

This canonical isomorphism actually motivates the bras. A bra $\bra{\psi}\in\calH^*$ is
the linear map given by

$$
  \bra{\psi} : \; \ket{\varphi} \mapsto \sprod{\psi}{\varphi} := (\ket{\psi}, \ket{\varphi}) .
$$

Having said that, terms like

$$
  \bra{\psi} U \ket{\varphi}
$$

are the same as

$$
  \bra{\psi} U \ket{\varphi} = (\bra{\psi}\circ U) \ket{\varphi} = (\ket{\psi}, U\ket{\varphi}) ,
$$

where $\circ$ denotes the composition of functions ($U$ and $\bra{\psi}$ as linear maps
are both functions of course). And of course, the bra-ket notation also makes the above
introduced notation for the scalar product obsolete since basically the bra and the ket
are the left and right half of the scalar product.

**** The actual proof
Let us return to the actual exercise. We use the above notation $(\ldots,\ldots)$ for the
scalar product to make the derivation clearer. Let $U$ be a unitary operator on $\calH$
and let

$$
  \rho = \rho_{\ket{\psi}} = \proj{\psi} .
$$

The task is to calculate $\rho_{U\ket{\psi}}$ and to show that it is equal to
$\calE(\rho_{\ket{\psi}})$. Note that $\rho$ is a linear map $\calH\to\calH$ given by

$$
  \rho \ket{\varphi} = \ket{\psi} \sprod{\psi}{\varphi} = (\ket{\psi}, \ket{\varphi}) \ket{\varphi} .
$$

Hence

\begin{align*}
  \rho_{U\ket{\psi}} \ket{\varphi} &= (U\ket{\psi}, \ket{\varphi}) U\ket{\psi} \\
  &= (\ket{\psi}, U^\dagger\ket{\varphi}) U\ket{\psi} \\
  &= \bra{\psi} U^\dagger \ket{\varphi} U\ket{\psi} \\
  &= U\ket{\psi} \bra{\psi} U^\dagger \ket{\varphi} \\
  &= U\rho_{\ket{\psi}} U^\dagger \ket{\varphi} .
\end{align*}

The first equality follows from the definition of $\rho_{\ket{\psi}}$. The second one
follows from the definition of the (hermitian) [[https://en.wikipedia.org/wiki/Hermitian_adjoint][adjoint]] operator. The third one is the
definition of the bras. The fourth equality just moves the complex number
$\bra{\psi}U\ket{\varphi}$ to the right. The last equation is again the definition of
$\rho_{\ket{\psi}}$.

Since the above eqation holds for all $\varphi$ we have

$$
  \rho_{U\ket{\psi}} = U\rho_{\ket{\psi}} U^\dagger .
$$

QED.

- Remark :: There is another slightly deeper way to see this result. Let us denote the
  above mentioned [[exercise-8.1-canonical-iso][canonical isomorphism]] by

  $$
  \iota(\ket{\psi}) = \bra{\psi} .
  $$

  It is not hard to show and extension of the conjugate-linearity property of the
  canonical isomorphism:

  $$
  \iota(U\ket{\psi}) = \iota(\ket{\psi}) U^\dagger = \bra{\psi} U^\dagger .
  $$

  In fact, the proof is even shorter than the proof of the claim of the exercise. That is,
  the /canonical/ way to associate a linear mapping $\calH^*\to\calH^*$ with $U$ is the
  right composition with $U^\dagger$. From this the claim of the exercise follows too.

** Exercise 8.2 (Measurement as a quantum operation)
Recall from Section 2.2.3 (on page 84) that a quantum measurement with outcomes labeled by
$m$ is described by a set of measurement operators $M_m$ such that
$\sum_mM_m^\dagger\,M_m=I$. Let the state of the system immediately before the measurement
be $\rho$. Show that for $\calE_m(\rho)=M_m\rho\,M_m^\dagger$, the state of the system
immediately after the measurement is

$$
  \frac{\calE_m(\rho)}{\trace{\calE_m(\rho)}} .
$$

Also show that the probability of obtaining this measurement result is
$p(m)=\trace{\calE_m(\rho)}$.

*** Solution
Clearly the exercise assumes that we only know the postulates of quantum mechanics for
/pure/ states as detailed in section 2.2.3 and not the generalization to mixed states as
detailed in 2.4.1. Otherwise the exercise would be a trivial restatement of the evolution
and measurement postulates.

Let us first assume that $\rho=\proj{\psi}$ is a pure state (just expressed as a density
matrix). In order to compute the trace of an operator $\sigma$ we can take /any/
orthonormal basis $\{e\}$ and have $\trace{\sigma}=\sum_{e}\bra{e}\sigma\ket{e}$. Let
$\sigma=\proj{\nu}$ with a not necessarily normalized non-zero $\ket{\nu}$. Without loss
of generality we may assume that $\ket{\nu}/\norm{\nu}$ is part of our chosen ONB (this
follows from the [[https://en.wikipedia.org/wiki/Gram%E2%80%93Schmidt_process][Gram-Schmidt]] procedure). Hence

<<exercise-8.2-1>>
$$
  \trace{\sigma} = \sum_{e} \bra{e}\proj{\nu}\ket{e}
  = \sprod{\nu}{\nu} \sprod{\nu}{\nu} / \norm{\nu}^2
  = \norm{\nu}^2 .
$$

Given a state $\ket{\psi}$ the post measurement state after measuring $m$ is
$M_m\ket{\psi}/\norm{M_m\ket{\psi}}$. From the reasoning in [[#exercise-8.1][exercise 1]] (that $U$ was a
unitary operator didn't really matter there) we deduce that the corresponding density
matrix is

$$
  \frac{M_m \rho M_m^\dagger}{\norm{M_m\ket{\psi}}^2} .
$$

Using [[exercise-8.2-1][the equation]] involving $\sigma$ (with $\ket{\nu}=M_m\ket{\psi}$) we see that
$\norm{M_m\ket{\psi}}^2=\trace{M_m\rho\,M_m^\dagger}$. Hence the post measurement state is

$$
  \frac{M_m \rho M_m^\dagger}{\trace{M_m\rho M_m^\dagger}} .
$$

The probability to measure $m$ (and to obtain this state) is

$$
  p(m) = \norm{M_m\ket{\psi}}^2 = \trace{M_m \rho M_m^\dagger} .
$$

This concludes the exercise for pure states. Let $\rho$ be a mixed state now. This means
that there is a decomposition

$$
  \rho = \sum_j p_j \proj{\psi_j}
$$

with strictly positive coefficients $p_j$ such that $\sum_jp_j=1$. The ensemble
interpretation says that having such a mixed state means that, upon measurement, one of
the pure states $\ket{\psi_j}$ is taken at random with probability $p_j$ and then the
measurement proceeds as in the pure state case. It is not a-priori clear that this is well
defined since the decomposition of $\rho$ into pure states is not unique (c.f. Theorem 2.6
on page 103). But let us ignore this for the moment. We will see that the obtained
probabilities and the post measurement states are independent of the concrete
decomposition, hence the problem solves itself.

According to the ensemble interpretation the probability to measure $m$ is

$$
  p(m) = \sum_j p(m|j) \, p_j = \sum_j \trace{M_m\proj{\psi_j} M_m^\dagger} \, p_j
  = \trace{M_m \rho M_m^\dagger} .
$$

Here

$$
  p(m|j) = \norm{M_m \ket{\psi_j}}^2 = \trace{M_m \proj{\psi_j} M_m^\dagger}
$$

is the conditioned probability to measure $m$ if we already know that the pure state
$\psi_j$ was chosen. Suppose we know that we measured $m$. What is the (mixed) state in
that case? We already know that with (conditioned) probability $p(j|m)$ the post
measurement state is

$$
  \frac{M_m\proj{\psi_j} M_m^\dagger}{p(m|j)} .
$$

But this is an ensemble of pure states! Hence, using $p(m|j)p_j=p(m\cap\,j)=p(j|m)p(m)$,
the corresponding mixed state is

$$
  \sum_j p(j|m) \frac{M_m\proj{\psi_j} M_m^\dagger}{p(m|j)}
  = \frac{1}{p(m)} \sum_j p_j M_m\proj{\psi_j} M_m^\dagger
  = \frac{M_m\rho M_m^\dagger}{p(m)}
  = \frac{M_m\rho M_m^\dagger}{\trace{M_m\rho M_m^\dagger}} .
$$

This concludes the exercise. But let is briefly mention that in case we do /not/ obtain
the outcome of the measurement the post measurement state is

<<exercise-8.2-measurment-operation>>
$$
  \sum_{m,j} p(m|j) p_j \, \frac{M_m \proj{\psi_j} M_m^\dagger}{p(m|j)}
  = \sum_m M_m \rho M_m^\dagger .
$$

- Remark :: Together with the conclusions from the actual exercise we can draw the
  following additional conclusion: If now we somehow obtain the measurement result than
  [[exercise-8.2-measurment-operation][this sum]] "collapses" into one of its summands (just normalized), with probability
  $\trace{M_m\rho\,M_m^\dagger}$ for each of them. That is, the measurement can be
  decomposed into two parts: First the state changes to

  $$
    \calE(\rho) = \sum_m \calE_m(\rho)
  $$

  and then (if we obtain the measurement result) the state "collapses" into
  $\calE_m(\rho)/\trace{\calE_m(\rho)}$ for one of the $m$ with probability
  $\trace{\calE_m(\rho)}$. So, the first part of the measurement can be expressed in terms
  of quantum operations. But not the second part (since it is not deterministic and cannot
  give rise to a mathematical function on density matrices).

** Exercise 8.3
Our derivation of the operator-sum representation implicitly assumed that the input and
output spaces for the operation were the same. Suppose a composite system AB initially in
an unknown quantum state $\rho$ is brought into contact with a composite system CD initially in
some standard state $\ket{0}$, and the two systems interact according to a unitary interaction
$U$. After the interaction we discard systems A and D, leaving a state $\rho'$ of system
BC. Show that the map $\calE(\rho)=\rho'$ satisfies

$$
  \calE(\rho) = \sum_k E_k \rho E_k^\dagger ,
$$

for some set of linear operators $E_k$ from the state space of system AB to the state
space of system BC, and such that $\sum_kE_k^\dagger\,E_k$.

*** Proof
Basically we do the same as the book for the special case of equal input and output
space. According to the exercise we have

$$
  \calE(\rho) = \ptrace{AD}{U \rho \otimes \proj{0} U^\dagger} .
$$

Let $\{e_k\}$ be an orthonormal basis of AD. Hence

$$
  \calE(\rho) = \sum_k \bra{e_k} U \rho \otimes \proj{0} U^\dagger \ket{e_k} .
$$

Thus, defining $E_k=\bra{e_k}U\ket{0}$, we have

$$
  \calE(\rho) = \sum_k E_k \rho E_k^\dagger .
$$

That is, $\calE$ has the required form. We only have to show the completeness property
$J:=\sum_kE_k^\dagger\,E_k=I_{AB}$. Note that $J=J^\dagger$ is self-adjoint and
positive-definite. Let $\rho$ be arbitrary and consider

$$
  1 = \ptrace{BC}{\calE(\rho)} = \sum_k \ptrace{BC}{E_k\rho E_k^\dagger}
  = \sum_k \ptrace{AB}{E_k^\dagger E_k \rho}
  = \ptrace{AB}{J^\dagger \rho} .
$$

Here we used the well-known /cyclicity property/ of the trace (which also holds for
(matching) rectangular matrices). Thus

<<exercise-8.3-1>>
$$
  \forall \rho : \; \trace{(J-I)^\dagger \rho} = 0 .
$$

Here the quantification runs over all density operators (hermitian, positive definite,
trace 1).

- Remark :: In case you wonder why I take the adjoint of $J$. We have that
  $S,T\mapsto\trace{S^\dagger\,T}$ turns the matrix space $\CC^{n\times\?n}$ into a
  complex Hilbert space. See e.g. the definition of a Hilbert-Schmidt operator on
  [[https://en.wikipedia.org/wiki/Hilbert%E2%80%93Schmidt_operator][wikipedia]] (it is about infinite dimensional spaces but just note that in finite
  dimensions every operator is a Hilbert-Schmidt operator). For this exercise it does not
  directly help us since the quantification [[exercise-8.3-1][above]] is /not/ over all
  $\rho\in\CC^{n\times\?n}$. But still nice to know üòâ.

Considering all rank-1 density matrices $\rho=\proj{\psi}$ we deduce

$$
  \forall \ket{\psi} : \; \trace{(J-I)^\dagger \proj{\psi}} = \bra{\psi} (J-I)^\dagger \ket{\psi} = 0 .
$$

(The first equality can either be seen by the cyclicity property of the trace or by using
an ONB which involves $\psi$ (but normalized) as one of its elements) But this can only be
true (for all normalized $\ket{\psi}$) if $J=I$. QED.

** Exercise 8.4 (Measurement)
:PROPERTIES:
:CUSTOM_ID: exercise-8.4
:END:
Suppose we have a single qubit principal system, interacting with a single qubit
environment through the transform

$$
  U = P_0 \otimes I + P_1 \otimes X
$$

where $X$ is the usual Pauli matrix (acting on the environment), and $P_0\equiv\proj{0}$,
$P_1\equiv\proj{1}$ are projectors (acting on the system). Give the quantum operation for
this process, in the operator-sum representation, assuming the environment starts in the
state $\ket{0}$.

*** Solution
Note that $U$ is nothing else than the =CNOT= gate. Let us label the environment by E. One
way to define the operation elements is

\begin{align*}
  E_0 &= \bra{0_E} U \ket{0_E} = P_0 \sprod{0_E}{0_E} + P_1 \bra{0_E}X\ket{0_E} = P_0 , \\
  E_1 &= \bra{1_E} U \ket{0_E} = P_0 \sprod{1_E}{0_E} + P_1 \bra{1_E}X\ket{0_E} = P_1 .
\end{align*}

(The $\ket{0_E}$ to the right of $U$ comes from the initial state of the environment.)
Hence

$$
  \calE(\rho) = P_0 \rho P_0 + P_1 \rho P_1 = \begin{bmatrix} \rho_{00} & 0 \\ 0 & \rho_{11} \end{bmatrix} .
$$

That is, this operation acts like the first part of a measurement. It describes the state
after a measurement in the Z-basis if nobody tells us the measurement outcome. Once we get
the outcome the state "collapses" to one of the two summands (properly normalized of
course). The respective probabilities are $\rho_{00}$ (for outcome $0$) and $\rho_{11}$
(for outcome $1$).

** Exercise 8.5 (Spin flips)
Just as in the previous exercise, but now let

$$
  U = \frac{1}{\sqrt{2}} \left( X \otimes I + Y \otimes X \right) .
$$

Give the quantum operation for this process, in the operator-sum representation.

*** Solution
First of all let us make sure that $U$ really is unitary. We have $U^\dagger=U$, hence

$$
  U^\dagger U = U^2 = \frac{1}{2} \left( X^2 \otimes I + Y^2 \otimes X^2 + (XY+YX)\otimes X \right) = I .
$$

Hence $U$ is indeed unitary. One way to define the operation elements is as follows:

\begin{align*}
  E_0 &= \bra{0_E} U \ket{0_E} = X \sprod{0_E}{0_E} + Y \bra{0_E}X\ket{0_E} = X , \\
  E_1 &= \bra{1_E} U \ket{0_E} = X \sprod{1_E}{0_E} + Y \bra{1_E}X\ket{0_E} = Y .
\end{align*}

Hence

$$
  \calE(\rho) = \frac{1}{2} \left(X \rho X + Y \rho Y \right)
  = \begin{bmatrix} \rho_{11} & 0 \\ 0 & \rho_{00} \end{bmatrix} .
$$

Interpreting this in the same way as in [[#exercise-8.4][exercise 8.4]] we deduce that $\calE$ corresponds to
a spin-flip followed by a measurement (without obtaining the measurement outcome).

** Exercise 8.6 (Composition of quantum operations)
Suppose $\calE$ and $\calF$ are quantum operations on the same quantum system. Show that
the composition $\calF\circ\calE$ is a quantum operation, in the sense that it has an
operator-sum representation. State and prove an extension of this result to the case where
$\calE$ and $\calF$ do not necessarily have the same input and output spaces.

*** Proof
Suppose

\begin{align*}
  \calE(\rho) &= \sum_i E_i \rho E_i^\dagger , \\
  \calF(\rho) &= \sum_j F_j \rho F_j^\dagger .
\end{align*}

Then

\begin{align*}
  \calF \circ \calE(\rho) = \sum_{ij} F_j E_i \rho E_i^\dagger F_j^\dagger .
\end{align*}

This suggests to use all the $F_jE_i$ as operation elements of the composition. That
$\calF\circ\calE$ is indeed a quantum operation now follows from

$$
  \sum_{ij} E_i^\dagger F_j^\dagger F_j E_i = \sum_i E_i^\dagger E_i = I .
$$

The proof directly generalizes (without any change) to the case where $\calE:A\to\?B$ and
$\calF:B\to\?C$. QED.

** Exercise 8.7
Suppose that instead of doing a projective measurement on the combined principal system
and environment we had performed a general measurement described by measurement operators
$\{M_m\}$. Find operator-sum representations for the corresponding quantum operations
$\{\calE_m\}$ on the principal system, and show that the respective measurement
probabilities are $\trace{\calE_m(\rho)}$.

*** Solution
Let $\sigma=\sum_jq_j\proj{j}$ be the state of the environment E. The generalized
operations look as follows

$$
  \calE_m(\rho) = \ptrace{E}{M_m U \rho\otimes\sigma U^\dagger M_m^\dagger} .
$$

According to the posutulates the probability to measure $m$, after an evolution with $U$,
is

$$
  p(m) = \trace{M_m U \rho\otimes\sigma U^\dagger M_m^\dagger} = \trace{\calE_m(\rho)} .
$$

Here we use the property $\trace{\ptrace{E}{A}}=\trace{A}$ of the partial trace. The
post-measurement state for the whole system is is

$$
  \frac{M_m U \rho\otimes\sigma U^\dagger M_m^\dagger}{p(m)} ,
$$

and for the principal system it is

$$
  \ptrace{E}{\frac{M_m U \rho\otimes\sigma U^\dagger M_m^\dagger}{p(m)}}
  = \frac{\calE_m(\rho)}{\trace{\calE_m(\rho)}} .
$$

It is not hard to see that for any choice of an ONB $\{e_k\}$ on E the operators

$$
  E_{jk} = \sqrt{q_j} \bra{e_k} M_m U \ket{j}
$$

are elements for the operation $\calE_m$, which also satisfy
$\sum\?E_{jk}^\dagger\?E_{jk}\leq\?I$:

$$
  \sum_{jk} E_{jk}^\dagger E_{jk}
  = \sum_{jk} q_j \bra{j}U^\dagger M_m^\dagger \ket{e_k} \bra{e_k} M_m U \ket{j}
  = \sum_j q_j \bra{j}U^\dagger M_m^\dagger M_m U \ket{j}
  \leq \sum_j q_j \bra{j}U^\dagger U \ket{j}
  = \sum_j q_j = I .
$$

** Exercise 8.8 (Non-trace-preserving quantum operations)
Explain how to construct a unitary operator for a system‚Äìenvironment model of a
non-trace-preserving quantum operation, by introducing an extra operator, $E_\infty$, into the
set of operation elements $E_k$, chosen so that when summing over the complete set of $k$,
including $k=\infty$, one obtains $\sum_kE_k^\dagger\?E_k=I$.

*** Solution
Let us define

$$
  E_\infty = \sqrt{I - \sum_k E_k^\dagger E_k} .
$$

Clearly $E_\infty^\dagger=E_\infty$ and

$$
  \sum_k' E_k^\dagger E_k = I .
$$

Here and in the following we let $\sum_k'$ denote the sum over all $k$ including
$k=\infty$. On the other hand $\sum_k$ excludes $k=\infty$.

As in the book consider an environment described by a Hilbert space which has a basis
$\{\ket{e_k}\}$ (including $k=\infty$). Define $U$ by

$$
  U \ket{\psi} \ket{e_0} \equiv \sum_k' E_k \ket{\psi} \ket{e_k}
$$

and unitary extension to the full system - exactly as in the book. Consider the following
projection defined on E:

$$
  P = I_E - \proj{e_\infty} .
$$

We shall prove that

$$
  \calE(\rho) = \ptrace{E}{PU \rho\otimes \proj{e_0} U^\dagger P} .
$$

In fact, the RHS equals

$$
  \ptrace{E}{\sum_{kl}' E_k \rho E_l^\dagger \otimes P \ket{e_k}\bra{e_l} P}
  = \ptrace{E}{\sum_{kl} E_k \rho E_l^\dagger \otimes \ket{e_k}\bra{e_l} }
  = \sum_{k} E_k \rho E_k^\dagger
  = \calE(\rho)
$$

as desired.

** Exercise 8.9 (Measurement model)
If we are given a set of quantum operations $\{\calE_m\}$ such that $\sum_m\calE_m$ is
trace-preserving, then it is possible to construct a measurement model giving rise to this
set of quantum operations. For each $m$, let $E_{mk}$ be a set of operation elements for
$\calE_m$. Introduce an environmental system, E, with an orthonormal basis $\ket{m,k}$ in
one-to-one correspondence with the set of indices for the operation elements. Analogously
to the earlier construction, define an operator $U$ such that

$$
  U \ket{\psi} \ket{e_0} = \sum_{mk} E_{mk} \ket{\psi} \ket{m,k} .
$$

Next, deÔ¨Åne projectors $P_m=\sum_k\proj{m,k}$ on the environmental system, E.  Show that
performing $U$ on $\rho\otimes\proj{e_0}$, then measuring $P_m$ gives $m$ with probability
$\trace{\calE_m(\rho)}$, and the corresponding post-measurement state of the principal
system is $\calE_m(\rho)/\trace{\calE_m(\rho)}$.

*** Solution
That $U$ can be extended to a unitary operator can be seen as in the other cases of
constructing an environment model. We have

\begin{align*}
  \ptrace{E}{P_m U \rho \otimes \proj{e_0} U^\dagger P_m}
  &= \ptrace{E}{\sum_{m,k,l} E_{mk}\rho E_{ml}^\dagger \otimes \ket{m,k}\bra{m,l}} \\
  &= \sum_{m,k} E_{mk}\rho E_{mk}^\dagger \\
  &= \calE_m(\rho) .
\end{align*}

Hence, using $\trace{\ptrace{E}{\ldots}}=\trace{\ldots}$, the probability to measure $m$
after applying $U$ to $\rho\otimes\proj{e_0}$ is

$$
  p(m) = \trace{P_m U \rho \otimes \proj{e_0} U^\dagger P_m} = \trace{\calE_m(\rho)} .
$$

The post-measurement state of the whole system is

$$
  \frac{P_m U \rho \otimes \proj{e_0} U^\dagger P_m}{p(m)} .
$$

Taking the partial trace of the environment yields the post-measurement state of the
principal system

$$
  \frac{\ptrace{E}{P_m U \rho \otimes \proj{e_0} U^\dagger P_m}}{p(m)}
  = \frac{\calE_m(\rho)}{\trace{\calE_m(\rho)}} .
$$

** Exercise 8.10
:PROPERTIES:
:CUSTOM_ID: exercise-8.10
:END:
Give a proof of Theorem 8.3 based on the freedom in the operator-sum representation, as
follows. Let $\{E_j\}$ be a set of operation elements for $\calE$. Define a matrix
$W_{jk}=\trace{E_j^\dagger\?E_k}$. Show that the matrix $W$ is Hermitian and of rank at
most $d^2$, and thus there is unitary matrix $u$ such that $uWu^\dagger$ is diagonal with
at most $d^2$ non-zero entries. Use $u$ to deÔ¨Åne a new set of at most $d^2$ non-zero
operation elements $\{F_j\}$ for $\calE$.

*** Proof 1
The statement is a direct consequence of the proof of Kraus's Theorem as given in the book
(Theorem 8.1). Recall that the diagonalization of $\sigma$

$$
  \sigma = \sum_{k=1}^M \proj{s_k}
$$

is used to define the operation elements by

$$
  E_k \ket{\psi} = \braket{\tilde{\psi}}{s_k}
$$

That is, there are precisely $M$ elements to be defined. How large can $M$ be? Recall that
$\sigma$ is a density matrix on the Hilbert space $\calH_R\otimes\calH_Q$ of the joint
system $RQ$. By assumption $d=\dim(\calH_Q)$ and by construction
$\dim(\calH_R)=\dim(\calH_Q)=d$. Hence

$$
  \dim(\calH_R\otimes\calH_Q) = d^2 .
$$

Hence $\sigma\in\CC^{d^2\times\?d^2}$ and therefore $M\leq\?d^2$. QED.

*** Proof 2
:PROPERTIES:
:CUSTOM_ID: exercise-8.10-proof-2
:END:
The matrix $W$ is hermitian because

$$
  W_{kj}^* = \trace{E_k^\dagger E_j}^*
  = \trace{(E_k^\dagger E_j)^\dagger}
  = \trace{E_j^\dagger E_k}
  = W_{jk} .
$$

Let $\calH$ be the $d$‚Äã-dimensional Hilbert space on which the $E_k$ operate. Recall that

$$
  A, B \mapsto \trace{A^\dagger B}
$$

is a scalar product on the $d^2$‚Äã-dimensional space of linear operators on $\calH$ (see
[[https://en.wikipedia.org/wiki/Hilbert%E2%80%93Schmidt_operator][Hilbert-Schmidt space]]). It turns it into a Hilbert space. The claim that
$\rank{W}\leq\?d^2$ thus follows from the following lemma (with $N=d^2$).

<<exercise-8.10-lemma>>
- Lemma :: Let $\{v_j\}_{j=1..M}$ be a bunch of vectors of an $N$‚Äã-dimensional complex
  Hilbert space $V$ and define

  $$
  W_{jk} = \braket{v_j}{v_k} .
  $$

  Then $\rank{W}\leq\?N$.

  - Proof :: Let $\{b_n\}_{n=1..N}$ be an ONB of $V$. Hence there are unique numbers
    $A_{jn}\in\CC$ such that

    $$
    v_j = \sum_{n=1}^N A_{jn} b_n .
    $$

    Interpreted as a matrix we have $A\in\CC^{M\times\?N}$, hence (the rank is always at
    most the minimum of the two dimensions)

    $$ \rank{A} \leq \min(M, N) \leq N . $$

    Consider

    $$
    W_{jk} = \braket{v_j}{v_k} = \sum_{nm} A_{jn}^* A_{km} \braket{b_n}{b_m}
    = \sum_n A_{jn}^* A_{kn}
    = (AA^\dagger)_{kj}
    $$

    Hence

    $$ W = \left(AA^\dagger \right)^\top $$

    Recall that transposition and conjugation does not change the rank of a
    matrix. Moreover $\rank{AB}\leq\min(\rank{A},\rank{B})$ for any two matrices
    $A,B$. The last thing follows easily from the characterization of the rank as the
    dimension of the image of a linear mapping. Hence

    $$
    \rank{W} \leq \rank{A} \leq N .
    $$

    QED.

Let $M$ be the number of elements. Hence $W\in\CC^{M\times\?M}$. Since $W$ is hermitian
there is a uniatry matrix $u\in\CC^{M\times\?M}$ such that

$$
  D = u W u^\dagger
$$

is diagonal. Observe that

$$
  D_{jk} = \sum_{mn} u_{jm} W_{mn} u_{kn}^*
  = \trace{\left(\sum_m u_{jm}^* E_m \right)^\dagger \left( \sum_n u_{kn}^* E_n \right)} .
$$

Hence defining $F_k=\sum_nu_{kn}^*E_n$ we have

$$
  D_{jk} = \trace{F_j^\dagger F_k} .
$$

We note two things:

- Since $D$ is diagonal the $F_j$ are actual orthogonal with respect to the
  Hilbert-Schmidt scalar product.
- Since $\rank{D}=\rank{W}\leq\?d^2$ only at most $d^2$ of the $F_j$ are non-zero
  ($\trace{F^\dagger\?F}=0$ implies $F=0$).

This concludes the proof. QED.

** Exercise 8.11
Suppose $\calE$ is a quantum operation mapping a $d$‚Äã-dimensional input space to a
$d'$‚Äã-dimensional output space. Show that $\calE$ can be described using a set of at most
$dd'$ operation elements $\{E_k\}$.

*** Proof
With a minor adaption we can reduce this to [[#exercise-8.10-proof-2][one of the proofs]] of [[#exercise-8.10][exercise 8.10]]. Let

$$
  d_1 = \max(d, d') .
$$

Then $E_k\in\CC^{d\times\?d'}$. By padding with zeros we can interpret the $E_k$ as
elements of a $dd'$‚Äã-dimensional subspace $V$ of $\CC^{d_1\times\?d_1}$. Note that this
does not affect the definition of $W$.

Now the proof of the special case $d=d'$ goes through as is. The crucial thing to note is
that the [[exercise-8.10-lemma][lemma]] has to be applied with $N=dd'$ and the just defined Hilbert space $V$. QED.

** WIP Exercise 8.12
Why can we assume that $O$ has determinant $1$ in the decomposition (8.93)?

# TODO: resolve the issue and check if det(M)>=0 is true. Remove the remark if yes.
<<remark-exercise-8.12>>
- Remark :: In /a sense/ my solution below solves the exercise. But I have the vague
  feeling that it is not meant like that. Playing around with examples I have the
  impression that $\det(M)\geq0$ just holds always. At the moment I can only prove this
  for a special case (see [[*Exercise 8.16][exercise 8.16]]). I do not even know if it is hard to prove. I
  have the feeling that it should not be so hard, but I still do not see it.

*** Maybe not a solution
As a real orthogonal matrix $O$ has $\det(O)=\pm1$. To see this recall that the
determinant is the product of all eigenvalues which are /complex/ number of modulus 1 for
an orthogonal matrix (which is unitary if interpreted as a complex matrix). But the
determinant of a real matrix is real, hence only $\pm1$ is possible for their product.

If the determinant is already $1$ we are done. Otherwise just replace $O$ by $-O$ and $S$
by $-S$. Of course this we destroy the property that $S$ is positive.

** Exercise 8.13
Show that unitary transformations correspond to rotations of the Bloch sphere.

*** Solution
Probably the idea is to prove it via the findings of the section (probably using the
formulas for $M_{jk}$ and $c_k$). Why else would this problem be in this chapter? But I
have not succeeded in doing so.

On the other hand we already know that claim and used it in earlier chapters. Therefore I
only sketch the proof. Essentially the problem is equivalent to [[file:chapter_4.org::#exercise-4-6][exercise 4.6]]. To see this
recall that every unitary operator is equal to some rotation $R_{\hat{n}}(\theta)$ around
some axis and some angle - up to a global phase. I have also made a small discussion for
the (easy) step to generalize the statement of the exercise to density matrix in [[file:chapter_4.org::thm-pauli-rotations-as-3d-rotations][chapter
4]].

** Exercise 8.14
Show that $\det(S)$ (From the polar decomposition of $M=OS$) need not be positive.

- Remark :: I assume that /positive/ means /strictly greater than zero/ here. Sometimes
  zero is included for positivity so it is always a bit unclear what is meant. There are
  two reasons to see it this way:

  - The /polar decomposition/ explicitly states that there is an orthogonal matrix $O$ and
    a /positive/ matrix $S$ (Moreover $S$ is unique and $O$ is unique on the support of
    $S$). Coincidentally here we already have a case were /positive/ actually means that
    $0$ is included, because it is defined as

    $$ \forall\ket{\psi}\neq0: \; \bra{\psi} S \ket{\psi} \geq 0 . $$

    In particular $S=0$, or more generally that the kernel of $S$ is non-trivial, is a
    possibility.

    But /positivity/ implies $\det(S)\geq0$. Hence $0$ can be the only violation of being
    "positive". Hence the strict interpretation of "positive" in this exercise. A loop
    hole would be that the exercise is somehow meant in some other way going away from the
    polar decomposition.
  - The second reason is that I believe that $\det(M)\geq0$ always holds. See also my
    [[remark-exercise-8.12][remark]] in exercise 8.12. If this is true I do not see any way to interpret the
    exercise in a way such that /not positive/ means /strictly negative/.

*** Solution
For the /bit-flip/ ($E_0=\sqrt{p}I$, $E_1=\sqrt{1-p}X$) we have

$$
  M = \diag(1, 2p-1, 2p-1)
$$

(and $c=0$). See chapter 8.3.3 or look into my [[sage-bit-flip][sage code]]. Clearly for $p=1/2$ we have
$\det(M)=0$. In that case $S=\sqrt{M^\dagger\?M}=M$ (and you could choose $O=I$). Hence
also $\det(S)=0$.

** Exercise 8.15
Suppose a projective measurement is performed on a single qubit in the basis $\ket{+}$,
$\ket{-}$, where $\ket{\pm}=(\ket{0}\pm\ket{1})/\sqrt{2}$. In the event that we are
ignorant of the result of the measurement, the density matrix evolves according to the
equation

$$
  \rho \mapsto \calE(\rho) = \proj{+}\rho\proj{+} + \proj{-}\rho\proj{-} .
$$

Illustrate this transformation on the Bloch sphere.

*** Solution
We reduce this to a known problem by transforming the operation into a phase-flip. This
has the advantage that we already know what it does in the Bloch-sphere, and even if not,
it is an easier problem since we can work in the standard basis (and know for example how
the matrices of the Pauli matrices look like in that basis).

Let $H=(X+Z)/\sqrt{2}$ be the Hadamard transform (note that $H^\dagger=H$ and
$H^2=1$). Recall that it swaps $X$ and $Z$ as well their eigenspace projectors
($\ket{\pm}$ are the eigenvectors of $X$). Hence

$$
  \calE'(\rho) = H \calE(H\rho H) H = \proj{0}\rho\proj{0} + \proj{1}\rho\proj{1} .
$$

Note that $\calE'$ is just the phase flip and we already know what it is. In the Bloch
sphere it corresponds to a projection onto the z-axis (see chapter 8.3.3):

$$
  M' = \diag(0, 0, 1), \; c' = 0 .
$$

In the Bloch-sphere interpretation of unitary operator $H$ acts as a rotation around
$(\hat{x}+\hat{z})/\sqrt{2}$ by 180¬∞. It swaps $\hat{x}$ and $\hat{z}$ and negates
$\hat{y}$, that is, as a rotation in the Bloch sphere $\rho\mapsto\?H\rho\?H$ is given by
this matrix:

$$
  T = \begin{bmatrix}
    0 &  0 & 1 \\
    0 & -1 & 0 \\
    1 &  0 & 0 \end{bmatrix} .
$$

Hence the following describes $\calE$:

$$
  M = TM'T = \diag(1, 0, 0), \; c = Tc' = 0 .
$$

** Exercise 8.16
:PROPERTIES:
:CUSTOM_ID: exercise-8.16
:END:
The graphical method for understanding single qubit quantum operations was derived for
trace-preserving quantum operations. Find an explicit example of a non-trace-preserving
quantum operation which cannot be described as a deformation of the Bloch sphere, followed
by a rotation and a displacement.

*** Solution
Before delivering an example I find it instructive to discover what violations are even
possible from dropping the trace preservation property. Hence the solution is divided into
two parts.

**** What does still hold?
Let $E$ be an /arbitrary/ linear operator on $\CC^2$ and let us consider the following
quantum operation

$$
  \calE(\rho) = E \rho E^\dagger .
$$

Note that /physicality/ ($\trace{\calE(\rho)}\leq1$) might be violated for some $\rho$ but
for this exercise physicality is not really relevant. It could always be restored by
multiplication with a small $\varepsilon\?>\?0$.

Note that from Kraus' theorem we know that an arbitrary single-qubit operation needs up to
four operation elements (c.f. [[#exercise-8.10][exercise 8.10]]). We try to generalize some of our findings at
the end. But for now let us only consider the one-element case.

Normally $\calE$ only acts on density operators, that is, operators of the form

$$
  \rho = 1 + x X + y Y + z Z ,
$$

where $x,y,z\in\RR$. *For notational convenience we left out the factor $1/2$.* It does
not really matter for our purposes. Note that the space of such matrices is a
three-dimensional /real-affine/ subspace of $\CC^{2\times2}\equiv\CC^4$. We already know
from the book (see also [[#chapter-8-bloch-M-c][my calculations]] above) that trace-preserving operations map this
space into an real-affine subspace of $\CC^{2\times2}$. Fixing $I$ as the origin of these
spaces the resulting mapping is real-affine-linear (not sure how to say it correctly).

It simplifies matters to consider the larger (four-dimensional) real /linear/ (without the
/affine/) subspace $S$ consisting of the following matrices:

$$
  \rho = e + x X + y Y + z Z ,
$$

where $e,x,y,z\in\RR$. Note that /any/ matrix in $\CC^{2\times2}$ can be written like that
but with /complex/ coefficients (indeed: $I,X,Y,Z$ is an ONB with respect to the scalar
product $A,B\mapsto\trace{A^\dagger\?B}$). In particular $E$ can be written as

$$
  E = sI + uX + vY + wZ
$$

for $s,u,v,w\in\CC$. Let us prove the following Lemma.

- Lemma :: Any quantum operation (trace-preserving or not) acts as a /real/-linear map
  from $S$ to itself.
  - Proof :: Let us conveniently write $\rho=(e,x,y,z)$ in the basis $(I,X,Y,Z)$. We have

    $$
    X\rho Y = (-\ii z, y, x, \ii e) \text{ and } Y\rho X = (\ii z, y, x, -\ii e) .
    $$

    Certainly you can see the pattern here and generalize it to the other two
    Pauli-operator pairs. Moreover

    $$
    X\rho X = (e, x, -y, -z) ,
    $$

    and analogously for the other two Pauli-operators. Hence

    $$ \rho\mapsto\?uX\rho\?u^*X = (\chi e, \chi x, -\chi y, -\chi z) $$

    where $\chi=\abs{u}^2$. Hence this type of transformation is /real/-linear. On the
    other hand it is easy to see that

    $$
    uX \rho v^*Y + vY \rho u^* X = (-\beta z, \alpha y, \alpha x, \beta e)
    $$

    where $\alpha=2\Re(u^*v)$ and $\beta=\ii\?uv^*-\ii\?u^*v=2\Im(u^*v)$. Hence this
    transformation is also real-linear. Observe that

    $$
    E \rho E^\dagger
    $$

    can be decomposed into a sum of transformations similar to the proceeding ones. Hence
    it is real linear too. Since a quantum operation is a sum of such one-element
    operations it follows that any quantum operation is real linear. QED.


Clearly a map is trace-preserving if it maps the affine subspace described by $e=1$ into
itself (works for any affine subspace defined by setting $e$ to a non-zero
constant). Hence, we derived in a slightly different way the conclusion that
trace-preserving quantum operations correspond to mappings within the Bloch-space.

It would be interesting to /characterize/ what maps are possible. I believe they are
characterized by $\det(M)\geq0$ (where $M:\RR^4\to\RR^4$ for the non-trace-preserving
maps). At least for single-element operations we can use sage to verify that the
determinant is always non-negative:

#+name: proof-positive-det-single-element
#+begin_src sage :tangle no :results replace :cache yes
  E = s*Id + u*X + v*Y + w*Z
  M = make_qop1d_matrix_4d([E])
  factor(det(M))
#+end_src

#+RESULTS[f0410405cc09c57bb8f535542e044932c95081a9]:
: (s^2 - u^2 - v^2 - w^2)^2*(conjugate(s)^2 - conjugate(u)^2 - conjugate(v)^2 - conjugate(w)^2)^2

So for $\calE(\rho)=E\rho\?E^\dagger$ with an arbitrary $E=s+uX+vY+wZ$ we have

$$
  \det(M) = \abs{s^2-u^2-v^2-w^2}^4 .
$$

In principle the most general operation can be constructed from four single operation
elements (see [[*Exercise 8.10][exercise 8.10]]). However the symbolic determinant as computed by =sage= is
too complicated to see a pattern (or to use =factor=).

**** Example
We have seen in the first part of the solution that non-trace-preserving operation can at
least be interpreted in $\RR^4$. I also conjectured that this representation has
non-negative determinant. For trace preserving operations this would imply that the
determinant with respect to $\RR^3$ is also positive.

The following is an example for a non-trace-preserving operation with negative determinant
with respect to $\RR^3$:

$$
  E_0 = I, \quad E_1 = X + \ii Y .
$$

Indeed, for $\rho=(e,x,y,z)$ with respect to the Pauli basis $(I,X,Y,Z)$ (recall $e=1$ for
density matrices) we have

$$
  \calE(\rho) = (3e-2z,x,y,2e-z) .
$$

The following sage code "proves" it:

#+begin_src sage :tangle no :results replace
  E0 = Id
  E1 = X + i*Y
  rho = e*Id + x*X + y*Y + z*Z

  qop1d([E0, E1], rho)
#+end_src

#+RESULTS:
: (3*e - 2*z, x, y, 2*e - z)

If we project this into the three dimensional Bloch-space the corresponding matrix is
$\diag(1,1,-1)$, which has a negative determinant. Hence it cannot be represented as a
deformation of the Bloch sphere, followed by a rotation and a displacement. Otherwise the
determinant would be non-negative (as is the case in $\RR^4$).
