<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="author" content="Reinhard Stahn"/><title>Chapter 10</title><link rel="icon" type="image/x-icon" sizes="any" href="./favicon/favicon.ico"/><!-- https://simplecss.org - License: MIT - We are using ./simple.css from commit dcb3545f2304356985c99acce9471ba3f559976b from https://github.com/kevquirk/simple.css --><link rel="stylesheet" href="./css/simple.css"/><link rel="stylesheet" href="./css/style.css"/><script src="./js/perf.js"></script><script src="./js/mathjax.js"></script><script async="" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha384-Wuix6BuhrWbjDBs24bXrjf4ZQ5aFeFWBuKkFekO2t8xFU0iNaLQfp2K6/1Nxveei" crossorigin="anonymous"></script></head><body><nav><a href="index.html">HOME</a></nav><h1 class="title">Chapter 10</h1>\[
\newcommand{\BB}{\mathbb{B}}
\newcommand{\CC}{\mathbb{C}}
\newcommand{\HH}{\mathbb{H}}
\newcommand{\KK}{\mathbb{K}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\QQ}{\mathbb{Q}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\ii}{\mathrm{i}}
\newcommand{\jj}{\mathrm{j}}
\newcommand{\kk}{\mathrm{k}}
\newcommand{\dd}{\mathrm{d}}
\newcommand{\FT}{\mathcal{F}} % Fourier Transform
\newcommand{\tto}{\twoheadrightarrow}
\newcommand{\inv}{^{-1}}
\newcommand{\RF}{\mathrm{RF}}
\newcommand{\sys}{\mathrm{sys}}
\newcommand{\diag}{\mathrm{diag}}
\newcommand{\calE}{\mathcal{E}}
\newcommand{\calF}{\mathcal{F}}
\newcommand{\calH}{\mathcal{H}}
\newcommand{\calR}{\mathcal{R}}
\newcommand{\abs}[1]{\left|#1\right|}
\newcommand{\norm}[1]{\|#1\|}
\newcommand{\sprod}[2]{\langle#1|#2\rangle} % deprecated, use braket instead.
\newcommand{\braket}[2]{\langle#1|#2\rangle} % scalar product
\newcommand{\ptrace}[2]{\mathrm{tr}_{#1}\left(#2\right)}
\newcommand{\trace}[1]{\mathrm{tr}\left(#1\right)}
\newcommand{\rank}[1]{\mathrm{rank}\left(#1\right)}
\newcommand{\floor}[1]{\lfloor#1\rfloor}
\newcommand{\ceil}[1]{\lceil#1\rceil}
\newcommand{\bra}[1]{\langle#1|}
\newcommand{\ket}[1]{|#1\rangle}
\newcommand{\proj}[1]{\ket{#1}\bra{#1}}
\newcommand{\mean}[1]{\langle#1\rangle}
\newcommand{\wt}[1]{\mathrm{wt}\left(#1\right)}
\newcommand{\prob}[1]{\mathrm{Prob}\left[#1\right]}
\newcommand{\orac}{\mathrm{Orac}}
\newcommand{\?}{} % sometimes I need just a separator other than whitespace
\]
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org5198ecb">Setup</a>
<ul>
<li><a href="#orgd34897a">Imports</a></li>
<li><a href="#org730f20b">Utility code</a></li>
<li><a href="#org2399bef">Notation</a></li>
<li><a href="#org741746f">Stabilizer codes</a></li>
<li><a href="#chapter-10-css-as-stabilizer">CSS codes in the stabilizer formalism</a></li>
</ul>
</li>
<li><a href="#orga8bc1d7">Exercises</a>
<ul>
<li><a href="#orga1c677a">Exercise 10.1</a></li>
<li><a href="#orgf2a1138">Exercise 10.2</a></li>
<li><a href="#orgcd1aa20">Exercise 10.3</a></li>
<li><a href="#org5765a7c">Exercise 10.4</a></li>
<li><a href="#orgc6732b8">Exercise 10.5</a></li>
<li><a href="#org662ece9">Exercise 10.6</a></li>
<li><a href="#orgaadbb71">Exercise 10.7</a></li>
<li><a href="#org11b3293">Exercise 10.8</a></li>
<li><a href="#orgfa85ef0">Exercise 10.9</a></li>
<li><a href="#orgf261fe3">Exercise 10.10</a></li>
<li><a href="#orgad531c4">Exercise 10.11</a></li>
<li><a href="#org315c3a7">Exercise 10.12</a></li>
<li><a href="#org3a421d6">Exercise 10.13</a></li>
<li><a href="#org2df9501">Exercise 10.14</a></li>
<li><a href="#orgc8e7caf">Exercise 10.15</a></li>
<li><a href="#org3abb17c">Exercise 10.16</a></li>
<li><a href="#org005dd7d">Exercise 10.17</a></li>
<li><a href="#exercise-10.18">Exercise 10.18</a></li>
<li><a href="#orgcf4d047">Exercise 10.19</a></li>
<li><a href="#exercise-10.20">Exercise 10.20</a></li>
<li><a href="#orgeb33287">Exercise 10.21 (Singleton bound)</a></li>
<li><a href="#org933d991">Exercise 10.22</a></li>
<li><a href="#org67719ca">Exercise 10.23</a></li>
<li><a href="#org0f06680">Exercise 10.24</a></li>
<li><a href="#org4d5672d">Exercise 10.25</a></li>
<li><a href="#orgc259128">Exercise 10.26</a></li>
<li><a href="#org0b44888">Exercise 10.27</a></li>
<li><a href="#orgee48312">Exercise 10.28</a></li>
<li><a href="#org93d22c4">Exercise 10.29</a></li>
<li><a href="#org206da1a">Exercise 10.30</a></li>
<li><a href="#org675a973">Exercise 10.31</a></li>
<li><a href="#orgff4d3bf">Exercise 10.32</a></li>
<li><a href="#exercise-10.33">Exercise 10.33</a></li>
<li><a href="#orgd6210ae">Exercise 10.34</a></li>
<li><a href="#exercise-10.35">Exercise 10.35</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-org5198ecb" class="outline-2">
<h2 id="org5198ecb">Setup</h2>
<div class="outline-text-2" id="text-org5198ecb">
</div>
<div id="outline-container-orgd34897a" class="outline-3">
<h3 id="orgd34897a">Imports</h3>
<div class="outline-text-3" id="text-orgd34897a">
<div class="org-src-container">
<pre class="src src-sage" id="org34c0168"><span class="org-keyword">from</span> utils_sage <span class="org-keyword">import</span> ket
<span class="org-keyword">from</span> chapter_8_sage <span class="org-keyword">import</span> make_operation
</pre>
</div>
</div>
</div>
<div id="outline-container-org730f20b" class="outline-3">
<h3 id="org730f20b">Utility code</h3>
<div class="outline-text-3" id="text-org730f20b">
<div class="org-src-container">
<pre class="src src-sage" id="orga1e8112"><span class="org-variable-name">g</span> <span class="org-operator">=</span> SR.var(<span class="org-string">"g"</span>, domain<span class="org-operator">=</span><span class="org-string">"positive"</span>)
<span class="org-variable-name">a</span>, <span class="org-variable-name">b</span> <span class="org-operator">=</span> SR.var(<span class="org-string">"a b"</span>, domain<span class="org-operator">=</span><span class="org-string">"complex"</span>)
assume(g <span class="org-operator">&lt;=</span> 1)
</pre>
</div>
</div>
</div>

<div id="outline-container-org2399bef" class="outline-3">
<h3 id="org2399bef">Notation</h3>
<div class="outline-text-3" id="text-org2399bef">
<p>
Below we use \(\BB=\mathrm{GF}(2)=\ZZ_2\) to denote the field of two elements. This models a
<i>bit</i>.
</p>
</div>
</div>

<div id="outline-container-org741746f" class="outline-3">
<h3 id="org741746f">Stabilizer codes</h3>
<div class="outline-text-3" id="text-org741746f">
<p>
The purpose of this section is to complement chapter 10.5. From the book I am missing some
concrete statement on how <i>exactly</i> stabilizer codes are characterized. I try to do this
in the <a href="#org3edacf0">fundamental theorem</a> of stabilizer codes below.
</p>

<p>
Let \(G_n\) be the Pauli group. As in the book let \(V_S=\{v|\forall\?g\in\?S:gv=v\}\) for a
subgroup \(S\) of \(G_n\). Note that any element of \(G_n\) can be represented as
</p>

<p>
<a id="orga4b49df"></a>
\[
  g = \alpha \bigotimes_{j=1}^n N_j ,
\]
</p>

<p>
where \(\alpha\in\langle\ii\rangle=\{1,-1,\ii,-\ii\}\) and \(N_j\in\{I,X,Y,Z\}\). An easy to
prove but important observation is that
</p>

<dl class="org-dl">
<dt>Lemma</dt><dd>For all \(g,h\in\?G_n\) we have \(gh=\pm\?hg\). That is, if two elements of the
Pauli group do not commute then \(gh=-hg\).
<dl class="org-dl">
<dt>Proof</dt><dd>This directly follows from the commutator relation of the Pauli
matrices. QED.</dd>
</dl></dd>
</dl>

<p>
Define a group homomorphism \(r:G_n\to\BB^{2n}\) by the following table
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">\(N_j\)</th>
<th scope="col" class="org-left">\(r(g)_j\)</th>
<th scope="col" class="org-left">\(r(g)_{n+j}\)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">\(I\)</td>
<td class="org-left">\(0\)</td>
<td class="org-left">\(0\)</td>
</tr>

<tr>
<td class="org-left">\(X\)</td>
<td class="org-left">\(1\)</td>
<td class="org-left">\(0\)</td>
</tr>

<tr>
<td class="org-left">\(Y\)</td>
<td class="org-left">\(1\)</td>
<td class="org-left">\(1\)</td>
</tr>

<tr>
<td class="org-left">\(Z\)</td>
<td class="org-left">\(0\)</td>
<td class="org-left">\(1\)</td>
</tr>
</tbody>
</table>

<p>
By group homomorphism we mean that \(r(gg')=r(g)+r(g')\) and \(r(g\inv)=-r(g)\) (note that
\(-r(g)=r(g)\) as we have \(\BB\) as the base field).
</p>

<p>
Let \(g_1,\ldots,g_l\in\?G_n\) and let \(S=\langle\?g_1,\ldots,g_l\rangle\). Early on in chapter 10.5 we have seen that
</p>

<p>
<a id="org81c0854"></a>
</p>
<dl class="org-dl">
<dt>Lemma</dt><dd>If \(V_S\) is non-trivial then \(-I\notin\?S\) and all the \(g_j\) commute.
<dl class="org-dl">
<dt>Proof</dt><dd>See chapter 10.5.1 for the simple proof.</dd>
<dt>Remark</dt><dd>In Proposition 10.5 in the book the reverse direction is proved and moreover
it is shown that \(\dim(V_S)=2^k\) if \(l=n-k\).</dd>
</dl></dd>
</dl>

<p>
In the following we want to better understand the condition from the Lemma. Therefore let
us define the corresponding <b>check matrix</b> \(G\in\BB^{l\times2n}\) by
</p>

<p>
\[
  G_{ij} = r(g_i)_j
\]
</p>

<dl class="org-dl">
<dt>Theorem</dt><dd><p>
Let \(\Lambda=X\otimes\?I_n\) and let
</p>

<p>
\[
  \beta = r(g)\Lambda r(h)^T \; (\in \BB) .
  \]
</p>

<p>
Then \(gh=(-1)^\beta\?hg\) for all \(g,h\in\?G_n\). In particular \(g\) and \(h\) commute iff
\(\beta=0\).
</p>
<dl class="org-dl">
<dt>Proof</dt><dd>See <a href="#exercise-10.33">exercise 10.33</a>.</dd>
</dl></dd>
</dl>

<p>
As a corollary we get a nice way to check whether \(S\) is abelian or not:
</p>

<p>
<a id="org350a0a1"></a>
</p>
<dl class="org-dl">
<dt>Theorem</dt><dd>The \(g_1,\ldots,g_l\) commute iff \(G\Lambda\?G^T=0\in\BB^{l\times\?l}\).</dd>
</dl>

<p>
It is left to find a nice way to check whether \(-I\notin\?S\) and how to characterize
independent generators. This is the purpose of the following series of theorems.
</p>

<p>
<a id="orgcb0e8ff"></a>
</p>
<dl class="org-dl">
<dt>Theorem</dt><dd><p>
The following assertions are equivalent
</p>
<ol class="org-ol">
<li>\(-I\notin\?S\) .</li>
<li>\(r\) is injective .</li>
</ol>

<dl class="org-dl">
<dt>Proof</dt><dd><dl class="org-dl">
<dt>(1) → (2)</dt><dd>Note that \(r\) is injective if \(r(g)=0\) has only one solution
(\(g=I\)). Clearly \(r(g)=0\) iff \(N_j=I\) for all \(j\). Hence \(g=\pm\?I\) or
\(g=\pm\ii\?I\). By (1) only \(g=I\) is possible.</dd>
<dt>(2) → (1)</dt><dd>This follows from \(r(-I)=0=r(I)\). Hence \(r\) cannot be injective
whenever \(-I\in\?S\).</dd>
</dl>
<p>
QED.
</p></dd>
</dl></dd>
</dl>

<p>
<a id="org0d1d509"></a>
</p>
<dl class="org-dl">
<dt>Theorem</dt><dd><p>
Assume that \(-I\notin\?S\). The following assertions are equivalent:
</p>
<ol class="org-ol">
<li>The \(g_1,\ldots,g_l\) are independent.</li>
<li>\(\rank{G}=l\).</li>
</ol>

<p>
The implication <b>(2) → (1)</b> holds even without assuming \(-I\notin\?S\).
</p>
<dl class="org-dl">
<dt>Proof</dt><dd><dl class="org-dl">
<dt>(1) → (2)</dt><dd>This follows from the fact that an injective group homomorphism maps
independent sets to independent sets. By a <a href="#orgcb0e8ff">previous theorem</a> \(r\) is injective. Hence
the rows of \(G\) are independent as elements of the group \(\BB^{2n}\). But this means
they are independent as elements of the vector space \(\BB^{2n}\).</dd>
<dt>(2) → (1)</dt><dd>From (2) we deduce that the \(r(g_j)\) are independent. But this implies
that the \(g_j\) must be independent. This holds even without the assumption that \(r\)
is injective.</dd>
</dl>
<p>
QED.
</p></dd>
</dl></dd>
</dl>

<p>
<a id="org962c4a2"></a>
</p>
<dl class="org-dl">
<dt>Theorem</dt><dd><p>
Assume that \(\rank{G}=l\). The following assertions are equivalent
</p>
<ol class="org-ol">
<li>\(-I\notin\?S\),</li>
<li>\(\alpha_j=\pm1\) for all \(j\),</li>
</ol>

<p>
<a href="#orga4b49df">where</a> \(g_j=\alpha_j\bigotimes_jN_j\).
</p>
<dl class="org-dl">
<dt>Proof</dt><dd><dl class="org-dl">
<dt>(1) → (2)</dt><dd>Since \(g_j=\alpha_j^2I=\pm\?I\) we see that \(-I\notin\?S\) implies
\(\alpha_j\neq\pm\ii\) for all \(j\).</dd>

<dt>(2) → (1)</dt><dd><p>
Assume to the contrary that \(-I\in\?S\). There is a non-zero \(x\in\ZZ^l\)
such that \(-I=\prod_jg_j^{x_j}\) (we may assume that \(x_j\in\{0,1,2,3\}\)). Hence
</p>

<p>
\[
      0 = r(-I) = \sum_{j=1}^n x_j r(g_j) = x G .
      \]
</p>

<p>
Since \(\rank{G}=l\) (as matrix over \(\BB\)) we have that \(x_j\in\{0,2\}\) for all
\(j\). But \(g_j^2=\alpha_j^2I\) and hence \(\alpha_j=\pm\ii\) for at least one \(j\) -
contradicting (2).
</p></dd>
</dl>
<p>
QED.
</p></dd>
</dl></dd>
</dl>

<p>
We are in a position to state and prove the main theorem of this section:
</p>

<p>
<a id="org3edacf0"></a>
</p>
<dl class="org-dl">
<dt>Fundamental theorem on stabilizer codes</dt><dd><p>
The non-trivial stabilizer codes are given by
all check matrices \(G\in\BB^{l\times2n}\) (for any \(n\) and \(l\)), corresponding to a set
of generators \(g_1,\ldots,g_l\in\?G_n\), which satisfy
</p>
<ol class="org-ol">
<li>\(\alpha_j=\pm1\) (c.f. <a href="#orga4b49df">representation</a> of \(g_j\)),</li>
<li>\(\rank{G}=l\) ,</li>
<li>\(G\Lambda\?G^T=0\in\BB^{l\times\?l}\) .</li>
</ol>

<p>
In that case the \(g_j\) commute, are independent and the dimension of the code is
\(2^{n-l}\).
</p>

<p>
Moreover, two stabilizer codes \(C\) and \(C'\) which have the same check matrix \(G\) (and
hence only differ in the signs \(\alpha_j\)) are equivalent in the sense that there exists
a Pauli operator \(g\in\?G_n\) such that \(C'=gC\).
</p>

<dl class="org-dl">
<dt>Remark</dt><dd>Because of the statement about equivalent stabilizer codes one might set
\(\alpha_j=1\) for simplicity. Under this convention the check matrix describes the
stabilizer code completely.</dd>

<dt>Proof</dt><dd><p>
Let \(V_S\) be a non-trivial stabilizer code. Let \(g_1,\ldots,g_l\) be a an
independent set of generators. By proposition 10.5 (or the <a href="#org81c0854">Lemma</a> above) we have
\(-I\notin\?S\) and all \(g_j\) commute. By independence of \(g_j\) and \(-I\notin\?S\) we
<a href="#org0d1d509">deduce</a> that \(\rank{G}=l\). From this and again using \(-I\notin\?S\) we <a href="#org962c4a2">deduce</a> that
\(\alpha_j=\pm1\) for all \(j\). Finally, the fact that the generators commute is
<a href="#org350a0a1">equivalent</a> to \(G\Lambda\?G^T=0\). This shows one part of the claim.
</p>

<p>
Let us now assume the conditions 1 to 3. From (1) and (2) we <a href="#org962c4a2">deduce</a> that
\(-I\notin\?S\). (3) is <a href="#org350a0a1">equivalent</a> to all \(g_j\) commuting. By proposition 10.5 this
implies that \(V_S\) is non-trivial.
</p>

<p>
The claim about the dimension of the code is contained in proposition 10.5.
</p>

<p>
Finally let us show that two stabilizer codes which differ only in \(\alpha\) are
equivalent in the sense stated. For concreteness let \(C\) be the code with all
\(\alpha_j=1\) and let \(C'\) be another code with the same check matrix and signs
\(\alpha_j=\chi_j=\pm1\). The claim actually follows from the proof of proposition
10.5. In fact, if \(P^{(0,\ldots,0)}_S\) is the projector of \(C\) then clearly
\(P^{\chi}_S\) is the projector of \(C'\). The proof showed that there exists a
\(g_{\chi}\in\?G_n\) such that
\(g_{\chi}P^{(0,\ldots,0)}_Sg_{\chi}^\dagger=P^{\chi}_S\). QED.
</p></dd>
</dl></dd>
</dl>
</div>
</div>

<div id="outline-container-chapter-10-css-as-stabilizer" class="outline-3">
<h3 id="chapter-10-css-as-stabilizer">CSS codes in the stabilizer formalism</h3>
<div class="outline-text-3" id="text-chapter-10-css-as-stabilizer">
<p>
There is a subtle error on page 456 which explains how the parity check matrices of a CSS
code map to the generators in the stabilizer formalism.
</p>

<p>
They say that the \(g_j\) containing the \(X\) correspond to the check matrix of \(C_1\) and
that the \(g_j\) containing the \(Z\) correspond to the check matrix of \(C_2^\top\). Actually
it is the other way round. This doesn't affect the example (Steane code) because the
parity check matrices are identical for \(C_1\) and \(C_2^\top\). But it might be
confusing. Hence I take the opportunity to lay out the translation for the general case.
</p>

<p>
Recall that a \([n,k_1-k_2]\) CSS code is constructed from two linear codes \(C_1\)
(\([n,k_1]\)) and \(C_2\) (\([n,k_2]\)) with \(C_2\subset\?C_1\). The code words are given by
</p>

<p>
\[
  \ket{x+C_2} = \frac{1}{\sqrt{\abs{C_2}}} \sum_{y\in C_2} \ket{x + y}
\]
</p>

<p>
where \(x+C_2\) is from the quotient space \(C_1/C_2\). Let \(A\in\BB^{(n-k_1)\times\?n}\) be
the parity check matrix of \(C_1\) and let \(B\in\BB^{k_2\times\?n}\) be the parity check
matrix of \(C_2^\top\). Let
</p>

<p>
<a id="org2bbb2cc"></a>
</p>
\begin{align*}
  g_i &= \bigotimes_{j=1}^n X^{B_{ij}}, \text{ for } i=1..k_2, \\
  g_{k_2+i} &= \bigotimes_{j=1}^n Z^{A_{ij}}, \text{ for } i=1..(n-k_1). \\
\end{align*}

<p>
<a id="orgf0bf142"></a>
</p>
<dl class="org-dl">
<dt>Theorem</dt><dd><a href="#org2bbb2cc">These</a> \(n-(k_1-k_2)\) Pauli operators are the stabilizer for the CSS code of
\(C_1\) over \(C_2\).
<dl class="org-dl">
<dt>Proof</dt><dd>We provide a proof in the <a href="#exercise-10.32-solution">solution</a> of exercise 10.32.</dd>
</dl></dd>
</dl>

<p>
The check matrix of the CSS code is given by the following block matrix
</p>

<p>
\[
  \begin{bmatrix} B & 0 \\ 0 & A \end{bmatrix} .
\]
</p>
</div>
</div>
</div>

<div id="outline-container-orga8bc1d7" class="outline-2">
<h2 id="orga8bc1d7">Exercises</h2>
<div class="outline-text-2" id="text-orga8bc1d7">
</div>
<div id="outline-container-orga1c677a" class="outline-3">
<h3 id="orga1c677a">Exercise 10.1</h3>
<div class="outline-text-3" id="text-orga1c677a">
<p>
Verify that the encoding circuit in Figure 10.2 works as claimed.
</p>

<pre class="example">

|psi&gt;: ──■────■──
       ┌─┴─┐  │
|0&gt;_0: ┤ X ├──┼──
       └───┘┌─┴─┐
|0&gt;_1: ─────┤ X ├
            └───┘
</pre>
</div>


<div id="outline-container-org4e1ad4e" class="outline-4">
<h4 id="org4e1ad4e">Solution</h4>
<div class="outline-text-4" id="text-org4e1ad4e">
<p>
This is really just observing that the circuit acts like this on the <i>relevant</i> basis
states
</p>

\begin{align*}
  \ket{000} &\mapsto \ket{000} , \\
  \ket{100} &\mapsto \ket{111} . \\
\end{align*}

<p>
The rest follows by linearity.
</p>
</div>
</div>
</div>

<div id="outline-container-orgf2a1138" class="outline-3">
<h3 id="orgf2a1138">Exercise 10.2</h3>
<div class="outline-text-3" id="text-orgf2a1138">
<p>
The action of the bit flip channel can be described by the quantum operation
\(\calE(\rho)=(1-p)\rho+pX\rho\?X\). Show that this may be given an alternate operator-sum
representation, as \(\calE(\rho)=(1-2p)\rho+2pP_+\rho\?P_++2pP_-\rho\?P_-\) where \(P_+\) and
\(P_-\) are projectors onto the \(+1\) and \(-1\) eigenstates of \(X\),
\((\ket{0}+\ket{1})/\sqrt{2}\) and \((\ket{0}+\ket{1})/\sqrt{2}\) respectively.  This latter
representation can be understood as a model in which the qubit is left alone with
probability \(1-2p\), and is ‘measured’ by the environment in the \(\ket{+}\), \(\ket{-}\) basis
with probability \(2p\).
</p>
</div>

<div id="outline-container-org81966f5" class="outline-4">
<h4 id="org81966f5">Proof</h4>
<div class="outline-text-4" id="text-org81966f5">
<p>
Note that \(X=P_+-P_-\) and \(I=P_++P_-\). Hence
</p>

<p>
\[
  X\rho X = P_+\rho P_+ + P_-\rho P_- - (P_+\rho P_- + P_-\rho P_+)
  = 2(P_+\rho P_+ + P_-\rho P_-) - I\rho I .
\]
</p>

<p>
Hence
</p>

<p>
\[
  \calE(\rho) = (1 - 2p)\rho + 2p (P_+\rho P_+ + P_-\rho P_-) .
\]
</p>

<p>
QED.
</p>
</div>
</div>
</div>

<div id="outline-container-orgcd1aa20" class="outline-3">
<h3 id="orgcd1aa20">Exercise 10.3</h3>
<div class="outline-text-3" id="text-orgcd1aa20">
<p>
Show by explicit calculation that measuring \(Z_1Z_2\) followed by \(Z_2Z_3\) is equivalent,
up to labeling of the measurement outcomes, to measuring the four projectors defined by
(10.5)–(10.8), in the sense that both procedures result in the same measurement statistics
and post-measurement states.
</p>
</div>

<div id="outline-container-org1a64a4c" class="outline-4">
<h4 id="org1a64a4c">Proof</h4>
<div class="outline-text-4" id="text-org1a64a4c">
<p>
Let us define the following projectors
</p>

\begin{align*}
  P_{ijk} &= \proj{i}\otimes\proj{j}\otimes\proj{k} , \\
  P_{ijx} &= \proj{i}\otimes\proj{j}\otimes I , \\
  P_{xij} &= I\otimes \proj{i}\otimes\proj{j} .
\end{align*}

<p>
That is, the \(x\) has a special meaning and just stands for the place where the identity
acts. Define \(P_{ixx}\) etc analogously. Note that e.g. \(P_{ixx}P_{xjx}=P_{ijx}\). Since
\(Z_1=P_{0xx}-P_{1xx}\), \(Z_2=P_{x0x}-P_{x1x}\), \(Z_3=P_{xx0}-P_{xx1}\) we have the following
spectral decomposition of the observables we are interested in:
</p>

\begin{align*}
  Z_1Z_2 &= P_{00x} + P_{11x} - P_{01x} - P_{10x} , \\
  Z_2Z_3 &= P_{x00} + P_{x11} - P_{x01} - P_{x10} .
\end{align*}

<p>
Let \(P_j\) for \(j=0..3\) be the projectors from (10.5) to (10.8). If we measure for example
\(+1\) for \(Z_1Z_2\) and \(+1\) for \(Z_2Z_3\) this corresponds to the projection (note: the
order of the projections is not important due to commutativity)
</p>

<p>
\[
  (+1, +1):\; (P_{00x} + P_{11x})(P_{x00} + P_{x11}) = P_{000} + P_{111} = P_0 .
\]
</p>

<p>
In the same way the other three measurements can be mapped to the \(P_j\) too:
</p>

\begin{align*}
  &(+1, -1):\; (P_{00x} + P_{11x})(P_{x01} + P_{x10}) = P_{001} + P_{110} = P_3 , \\
  &(-1, +1):\; (P_{01x} + P_{10x})(P_{x00} + P_{x11}) = P_{100} + P_{011} = P_1 , \\
  &(-1, -1):\; (P_{01x} + P_{10x})(P_{x01} + P_{x10}) = P_{101} + P_{010} = P_2 .
\end{align*}

<p>
Hence the projectors are the same, just re-labeled. QED.
</p>
</div>
</div>
</div>

<div id="outline-container-org5765a7c" class="outline-3">
<h3 id="org5765a7c">Exercise 10.4</h3>
<div class="outline-text-3" id="text-org5765a7c">
<p>
Consider the three qubit bit flip code. Suppose we had performed the error syndrome
measurement by measuring the eight orthogonal projectors corresponding to projections onto
the eight computational basis states.
</p>

<ol class="org-ol">
<li>Write out the projectors corresponding to this measurement, and explain how the
measurement result can be used to diagnose the error syndrome: either no bits flipped or
bit number \(j\) flipped, where \(j\) is in the range one to three.</li>
<li>Show that the recovery procedure works only for computational basis states.</li>
<li>What is the minimum fidelity for the error-correction procedure?</li>
</ol>
</div>

<div id="outline-container-org2b55b3c" class="outline-4">
<h4 id="org2b55b3c">Solution for part 1</h4>
<div class="outline-text-4" id="text-org2b55b3c">
<p>
The projectors are just \(P_j=\proj{j}\) for \(j=0..7\) (note that the binary representations
for the numbers from \(0\) to \(7\) are \(000\), \(001\), \(010\), \(011\), \(100\), \(101\), \(110\),
\(111\)). A corresponding observable distinguishing each projector would be
\(A=\sum_jj\proj{j}\).
</p>

<p>
Recall that the encoded state is \(\ket{\psi}=a\ket{000}+b\ket{111}\). Let \(k=0\), \(k=1\),
\(k=2\), \(k=3\) denote <i>no error</i>, <i>error in qubit 1, 2, 3</i>, respectively. Let \(M_k\) be the
set of possible measurements for the given value of \(k\). We have
</p>

<p>
<a id="orgd9b23e8"></a>
</p>
\begin{align*}
  M_0 &= \{0, 7\} , \\
  M_1 &= \{1, 6\} , \\
  M_2 &= \{2, 5\} , \\
  M_3 &= \{4, 3\} .
\end{align*}

<p>
Moreover, measuring \(0,1,2,4\) happens with probability \(\abs{a}^2\) and measuring \(7,6,5,3\)
happens with probability \(\abs{b}^2\) (conditioned on a fixed value for \(j\)). Since the
four sets are disjoint we can infer the error (the value of \(k\)) from the measurement
(e.g. measuring \(1\) or \(6\) implies that the error was \(k=1\) (with certainty if only one of
the three errors "is allowed" to happen)).
</p>
</div>
</div>

<div id="outline-container-org40922ad" class="outline-4">
<h4 id="org40922ad">Solution for part 2</h4>
<div class="outline-text-4" id="text-org40922ad">
<p>
If we measure \(j\) and infer the error \(k\) <a href="#orgd9b23e8">according to the sets</a> \(M_k\) we would correct it
by applying \(X_k\) to the state. In other words, the following quantum operation \(\calR\)
performs the syndrome measurement followed by the recovery:
</p>

\begin{align*}
  E_0 &= P_0, \\ E_1 &= X_1P_1, \\ E_2 &= X_2P_2, \\ E_3 &= X_3P_3, \\
  E_4 &= X_3P_4, \\ E_5 &= X_2P_5, \\ E_6 &= X_1P_6, \\ E_7 &= P_7 .
\end{align*}

<p>
Note that \(\calR\) is indeed trace-preserving (\(\sum_jE_j^\dagger\?E_j)=I\)). Recall
\(\ket{\psi}=a\ket{000}+b\ket{111}\). Then (the <i>no error</i> case)
</p>

<p>
\[
  \calR(\ket{\psi}) = \abs{a}^2 \proj{000} + \abs{b}^2 \proj{111} .
\]
</p>

<p>
The same formula holds for \(\ket{\psi}\) replaced by \(X_k\ket{\psi}\) (\(k=1..3\)). Hence, for
the following noise channel
</p>

<p>
\[
  \calE(\rho) = (1-p)\rho + \sum_{k=1}^3 p_k X_k \rho X_k
\]
</p>

<p>
where \(\sum_kp_k=p\) (this implies trace-preservation, but we could more generally assume
\(\ldots\leq\?p\), meaning that with certain probability "something else" happens), which
stands for having at most one bit-flip (with probability \(p_k\) at position \(k\)), we have
</p>

<p>
\[
  \calR\circ\calE(\ket{\psi}) = \abs{a}^2 \proj{000} + \abs{b}^2 \proj{111} .
\]
</p>

<p>
(If \(\calE\) was not trace-preserving the RHS would have a factor \(1-p+\sum_jp_j\).) Hence
the bit-flip error gets indeed corrected, but unwanted side effects happen too. The final
state after recovery is either \(\ket{000}\) (probability \(\abs{a}^2\)) or \(\ket{111}\)
(probability \(\abs{b}^2\)). That is the state collapses to a basis state. This is only
correct if \(\ket{\psi}\) was already in a basis state (\(a=0\) or \(b=0\)) - which is the claim
of part 2.
</p>
</div>
</div>

<div id="outline-container-org789ee4b" class="outline-4">
<h4 id="org789ee4b">Solution for part 3</h4>
<div class="outline-text-4" id="text-org789ee4b">
<p>
Let us consider two cases:
</p>

<ol class="org-ol">
<li>We do not get to know the results of the syndrome measurement.</li>
<li>We get to know the results of the syndrome measurement.</li>
</ol>

<p>
In case 1 the whole error correction procedure is given by \(\calR\) from the solution of
part 2. Let \(\rho=\calR\circ\calE(\ket{\psi})\). Then
</p>

<p>
\[
  F(\ket{\psi},\rho) = \sqrt{\bra{\psi}\rho\ket{\psi}} = \sqrt{\abs{a}^4 + \abs{b}^4} .
\]
</p>

<p>
Since \(\abs{a}^2+\abs{b}^2=1\) the minimum occurs at \(\abs{a}^2=\abs{b}^2=1/2\). Hence
\(F\geq1/\sqrt{2}\) in that case.
</p>

<p>
In case 2 the post-correction state \(\rho\) is either \(\ket{000}\) (probability \(\abs{a}^2\))
or \(\ket{111}\) (probability \(\abs{b}^2\)). Hence
</p>

<p>
\[
  F(\ket{\psi},\rho) \in \left\{\sqrt{\braket{\psi}{i_L}\braket{i_L}{\psi}} \; \middle| \; i\in\{0,1\}\right\}
  = \{\abs{a}, \abs{b}\} ,
\]
</p>

<p>
where the first alternative occurs with probability \(\abs{a}^2\) and the second one with
\(\abs{b}^2\).
</p>

<p>
In both cases the minimial fidelity does not depend on the specifics of the noise model
and in particular is always bad if \(\abs{a}\) and \(\abs{b}\) are bounded away from \(0\) (or
equivalently, from \(1\)).
</p>

<dl class="org-dl">
<dt>Remark</dt><dd><p>
The minimum fidelity of case 1 is the weighted root square mean of the two
possible fidelities of case 2. The weights are \(\abs{a}^2\) and \(\abs{b}^2\). See e.g.
<a href="https://en.wikipedia.org/wiki/Generalized_mean">generalized mean</a> on wikipedia for more infos. To make this more apparent consider
\(\sigma=p\proj{0}+(1-p)\proj{1}\) (and \(\ket{\psi}=a\ket{0}+b\ket{1}\)):
</p>

<p>
\[
  F(\ket{\psi},\sigma) = \sqrt{\bra{\psi}\sigma\ket{\psi}} = \sqrt{p\abs{a}^2+(1-p)\abs{b}^2} .
  \]
</p>

<p>
Here \(p\) and \(1-p\) are the weights.
</p></dd>
</dl>
</div>
</div>
</div>

<div id="outline-container-orgc6732b8" class="outline-3">
<h3 id="orgc6732b8">Exercise 10.5</h3>
<div class="outline-text-3" id="text-orgc6732b8">
<p>
Show that the syndrome measurement for detecting phase flip errors in the Shor code
corresponds to measuring the observables \(A=X_1X_2X_3X_4X_5X_6\) and
\(B=X_4X_5X_6X_7X_8X_9\).
</p>
</div>

<div id="outline-container-exercise-10.5-solution" class="outline-4">
<h4 id="exercise-10.5-solution">Proof</h4>
<div class="outline-text-4" id="text-exercise-10.5-solution">
<p>
Let us denote
</p>

\begin{align*}
  \ket{\pi} &= \frac{1}{\sqrt{2}} (\ket{000} + \ket{111}) , \\
  \ket{\mu} &= \frac{1}{\sqrt{2}} (\ket{000} - \ket{111}) .
\end{align*}

<p>
With this notation the Shor code is given by
</p>

\begin{align*}
  \ket{0_L} &= \ket{\pi\pi\pi} , \\
  \ket{1_L} &= \ket{\mu\mu\mu} , \\
\end{align*}

<p>
Hence we have the following encoding:
</p>

<p>
\[
  \ket{\psi} = \ket{\psi_0} = a\ket{0_L} + b\ket{1_L} = a\ket{\pi\pi\pi} + b\ket{\mu\mu\mu} .
\]
</p>

<p>
In this notation a phase flip error is represented naturally. For example a phase flip in
one of the three qubits in the first block of \(\ket{\psi}\) is given by
</p>

<p>
\[
  \ket{\psi_1} = a\ket{\mu\pi\pi} + b\ket{\pi\mu\mu} .
\]
</p>

<p>
It doesn't matter in which of the three qubits, it always leads to the same state. The
other two errors (phase flip in the second or third block) are given by
</p>

\begin{align*}
  \ket{\psi_2} &= a\ket{\pi\mu\pi} + b\ket{\mu\pi\mu} , \\
  \ket{\psi_3} &= a\ket{\pi\pi\mu} + b\ket{\mu\mu\pi} .
\end{align*}

<p>
Now observe that
</p>

\begin{align*}
  X_1X_2X_3 \ket{\pi} &= + \ket{\pi} , \\
  X_1X_2X_3 \ket{\mu} &= - \ket{\mu} .
\end{align*}

<p>
Hence e.g. measuring a state \(\ket{ijk}\) (\(i,j,k\in\{\pi,\mu\}\)) with respect to \(A\)
detects if \(i=j\) (measurement result: \(+1\)) or \(i\neq\?j\) (measurement result:
\(+1\)). Because of their special structure this translates to \(\ket{\psi_k}\). For the four
errors (first one is <i>no error</i>) we get the following measurement results (each with
certainty):
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-right" />

<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-right">\(k\) (\(\ket{\psi_k}\))</th>
<th scope="col" class="org-right">\(A\)</th>
<th scope="col" class="org-right">\(B\)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">0</td>
<td class="org-right">+1</td>
<td class="org-right">+1</td>
</tr>

<tr>
<td class="org-right">1</td>
<td class="org-right">-1</td>
<td class="org-right">+1</td>
</tr>

<tr>
<td class="org-right">2</td>
<td class="org-right">-1</td>
<td class="org-right">-1</td>
</tr>

<tr>
<td class="org-right">3</td>
<td class="org-right">+1</td>
<td class="org-right">-1</td>
</tr>
</tbody>
</table>

<p>
Hence we can infer the syndrome \(k\) (which error occured) from the measurement - as
desired. QED.
</p>
</div>
</div>
</div>

<div id="outline-container-org662ece9" class="outline-3">
<h3 id="org662ece9">Exercise 10.6</h3>
<div class="outline-text-3" id="text-org662ece9">
<p>
Show that recovery from a phase flip on any of the first three qubits may be accomplished
by applying the operator \(Z_1Z_2Z_3\).
</p>
</div>

<div id="outline-container-org75d6e34" class="outline-4">
<h4 id="org75d6e34">Proof</h4>
<div class="outline-text-4" id="text-org75d6e34">
<p>
Let us reuse the notation from the <a href="#exercise-10.5-solution">solution</a> of exercise 10.5. Clearly
</p>

<p>
\[
  Z_1Z_2Z_3 \ket{\pi} = \ket{\mu} \text{ and } Z_1Z_2Z_3 \ket{\mu} = \ket{\pi} .
\]
</p>

<p>
An error in the first three qubits means that the corresponding state is
\(\ket{\psi_1}\). By the above we have:
</p>

<p>
\[
  Z_1Z_2Z_3 \ket{\psi_1} = \ket{\psi} .
\]
</p>

<p>
QED.
</p>
</div>
</div>
</div>

<div id="outline-container-orgaadbb71" class="outline-3">
<h3 id="orgaadbb71">Exercise 10.7</h3>
<div class="outline-text-3" id="text-orgaadbb71">
<p>
Consider the three qubit bit flip code of Section 10.1.1, with corresponding projector
\(P=\proj{000}+\proj{111}\). The noise process this code protects against has operation
elements
</p>

<p>
\[
  \left\{ \sqrt{(1-p)^3}I, \sqrt{p(1-p)^2}X_1, \sqrt{p(1-p)^2}X_2, \sqrt{p(1-p)^2}X_3 \right\} ,
\]
</p>

<p>
where \(p\) is the probability that a bit flips. Note that this quantum operation \(\calE\) is
not trace-preserving, since we have omitted operation elements corresponding to bit flips
on two and three qubits. Verify the quantum error-correction conditions for this code and
noise process.
</p>
</div>

<div id="outline-container-org78cfe57" class="outline-4">
<h4 id="org78cfe57">Solution</h4>
<div class="outline-text-4" id="text-org78cfe57">
<p>
Clearly \(PX_iX_jP=\delta_{ij}P\). Hence
</p>

\begin{align*}
  P E_0^\dagger E_0 P &= (1-p)^3 P , \\
  P E_i^\dagger E_i P &= p(1-p)^2 P \text{ for } i=1..3 , \\
  P E_i^\dagger E_j P &= 0 \text{ for } i\neq j .
\end{align*}

<p>
Hence the conditions are satisfied and there exists an error correction procedure \(\calR\)
for this noise.
</p>
</div>
</div>

<div id="outline-container-org0c16cbe" class="outline-4">
<h4 id="org0c16cbe">Bonus: Calculating the recovery procedure</h4>
<div class="outline-text-4" id="text-org0c16cbe">
<p>
By the previous calculation and Theorem 10.1 there exists a trace-preserving quantum
operation \(\calR\) such that
</p>

<p>
\[
  \calR \circ \calE (P\rho P) = [(1-p)^3 + 3p(1-p)^2] \, P \rho P .
\]
</p>

<p>
The concrete form of the proportionality factor follows from (10.25) as it equals
\(\sum_kd_{kk}\). Since this is a trace this formula would even be true if \((d_{ij})\) wasn't
already diagonal.
</p>

<p>
To compute the Kraus matrices \(R_k\) of \(\calR\) we need the \(E_k\) such that the \((d_{ij})\)
are diagonal. This is already the case
</p>

<p>
\[
  d = \diag((1-p)^3, p(1-p)^2, p(1-p)^2, p(1-p)^2) .
\]
</p>

<p>
From the proof of Theorem 10.1 we know that
</p>

<p>
\[
  R_k = U_k^\dagger P_k
\]
</p>

<p>
where \(P_k=U_kPU_k^\dagger\) and \(E_kP=\sqrt{d_{kk}}U_kP\) is a polar decomposition. The
\(P_k\) are the projectors onto \(E_kC\) (\(C\) being the code space onto which \(P\)
projects). The diagonality of \((d_{ij})\) implies that \(P_iP_j=\delta_{ij}P_i\) (meaning
that the error subspaces are orthogonal to each other).
</p>

<p>
Clearly we can set \(U_0=I\) (it is only uniquely defined on the image of \(P\)). For \(k=1\) we
have
</p>

<p>
\[
  E_1 P = \sqrt{p(1-p)^2} X_1 P .
\]
</p>

<p>
This is already a polar decomposition (the Pauli operators are unitary). Hence we can just
set \(U_1=X_1\) and analogously \(U_k=X_k\) for \(k=1..3\). Hence
</p>

\begin{align*}
  P_0 &= \proj{000} + \proj{111} , \\
  P_1 &= \proj{100} + \proj{011} , \\
  P_2 &= \proj{010} + \proj{101} , \\
  P_3 &= \proj{001} + \proj{110} .
\end{align*}

<p>
Note that this corresponds to the already in (10.5-10.8) introduced syndrome measurement
operators. The Kraus matrices of \(\calR\) are
</p>

<p>
\[
  R_k = U_k^\dagger P_k = \begin{cases} IP = P & \text{for } k = 0 , \\
    X_k X_kPX_k = PX_k & \text{for } k \in \{1,2,3\} . \end{cases}
\]
</p>
</div>
</div>
</div>

<div id="outline-container-org11b3293" class="outline-3">
<h3 id="org11b3293">Exercise 10.8</h3>
<div class="outline-text-3" id="text-org11b3293">
<p>
Verify that the three qubit phase flip code \(\ket{0_L}=\ket{+++}\), \(\ket{1_L}=\ket{---}\)
satisfies the quantum error-correction conditions for the set of error operators
\(\{I,Z_1,Z_2,Z_3\}\).
</p>
</div>

<div id="outline-container-org9377d72" class="outline-4">
<h4 id="org9377d72">Solution 1</h4>
<div class="outline-text-4" id="text-org9377d72">
<p>
Let us reduce this to the bit flip code. To convert to the bit flip code we only have to
conjugate the projector of the code and the Kraus operators of the errors by
\(H^{\otimes3}\) (Hadamard).
</p>

<p>
\[
  \proj{000} + \proj{111} = H^{\otimes3} \proj{+++} + \proj{---} H^{\otimes3}
\]
</p>

<p>
and
</p>

<p>
\[
  X_k = H^{\otimes3} Z_k H^{\otimes3} .
\]
</p>

<p>
Let \(P\) be the projector of the phase flip code and let \(E_i\) be the mentioned errors it
corrects. Let \(Q\) and \(F_j\) be the same thing for the bit flip.
</p>

<p>
\[
  P E_i^\dagger E_j P = H^{\otimes3} Q F_i^\dagger F_j Q H^{\otimes3}
  = H^{\otimes3} \delta_{ij} Q H^{\otimes3}
  = \delta_{ij} P .
\]
</p>

<p>
In the second equality we used what we already know about the bit flip code.
</p>
</div>
</div>

<div id="outline-container-orge71ddc8" class="outline-4">
<h4 id="orge71ddc8">Solution 2</h4>
<div class="outline-text-4" id="text-orge71ddc8">
<p>
We can also verify this explicitly. Let \(P=P_{+++}+P_{---}\) be the projector onto the
code, where we use the notation \(P_{ijk}=\proj{ijk}\). Clearly
\(PE_i^\dagger\?E_iP=PIP=P\). Moreover
</p>

<p>
\[
  PZ_1P = (P_{+++} + P_{---})(P_{-++} + P_{+--}) = 0
\]
</p>

<p>
and
</p>

<p>
\[
  PZ_1Z_2P = (P_{+++} + P_{---})(P_{--+} + P_{++-}) = 0 .
\]
</p>

<p>
Similarly \(PIZ_jP=PZ_iZ_jP=0\) for \(i\neq\?j\). Hence \(PE_i^\dagger\?E_iP=\delta_{ij}\).
</p>
</div>
</div>
</div>

<div id="outline-container-orgfa85ef0" class="outline-3">
<h3 id="orgfa85ef0">Exercise 10.9</h3>
<div class="outline-text-3" id="text-orgfa85ef0">
<p>
Again, consider the three qubit phase flip code. Let \(P_i\) and \(Q_i\) be the projectors
onto the \(\ket{0}\) and \(\ket{1}\) states, respectively, of the \(i\)​th qubit. Prove that the
three qubit phase flip code protects against the error set \({I,P_1,Q_1,P_2,Q_2,P_3,Q_3}\).
</p>
</div>

<div id="outline-container-orgce5c463" class="outline-4">
<h4 id="orgce5c463">Solution</h4>
<div class="outline-text-4" id="text-orgce5c463">
<p>
Recall that the phase flip code corrects the errors \(I\), \(Z_1\), \(Z_2\), and \(Z_3\). By
theorem 10.2 linear combinations of these errors are corrected too. Note that we have
</p>

\begin{align*}
  P_k &= \frac{1}{2} (I + Z_k) , \\
  Q_k &= \frac{1}{2} (I - Z_k) .
\end{align*}

<p>
Hence those errors are corrected too.
</p>
</div>
</div>
</div>

<div id="outline-container-orgf261fe3" class="outline-3">
<h3 id="orgf261fe3">Exercise 10.10</h3>
<div class="outline-text-3" id="text-orgf261fe3">
<p>
Explicitly verify the quantum error-correction conditions for the Shor code, for the error
set containing \(I\) and the error operators \(X_j,Y_j,Z_j\) for \(j=1\) through \(9\).
</p>
</div>

<div id="outline-container-orgecc7e12" class="outline-4">
<h4 id="orgecc7e12">Solution</h4>
<div class="outline-text-4" id="text-orgecc7e12">
<p>
Let us denote
</p>

\begin{align*}
  \ket{\pi} &= \frac{1}{\sqrt{2}} (\ket{000} + \ket{111}) , \\
  \ket{\mu} &= \frac{1}{\sqrt{2}} (\ket{000} - \ket{111}) .
\end{align*}

<p>
The Shor code is given by he projector
</p>

<p>
\[
  P = \proj{\pi\pi\pi} + \proj{\mu\mu\mu} .
\]
</p>

<p>
It is not hard to see that the errors transform the code space into a set of mutually
orthogonal subspaces - with one exception. The effect of \(Z_j\) is the same if \(j\) stays
within one "block" (there are three block \(\{1,2,3\}\), \(\{4,5,6\}\), and
\(\{7,8,9\}\)). Hence:
</p>

<p>
\[
  PE_i^\dagger E_j P = \begin{cases}
    P & \text{if } i=j \text{ or } E_i,E_j \text{ both Z on same block} , \\
    0 & \text{else} .
  \end{cases}
\]
</p>
</div>
</div>
</div>

<div id="outline-container-orgad531c4" class="outline-3">
<h3 id="orgad531c4">Exercise 10.11</h3>
<div class="outline-text-3" id="text-orgad531c4">
<p>
Construct operation elements for a single qubit quantum operation \(\calE\) that upon input
of any state \(\rho\) replaces it with the completely randomized state \(I/2\). It is amazing
that even such noise models as this may be corrected by codes such as the Shor code!
</p>
</div>

<div id="outline-container-orgd0dac51" class="outline-4">
<h4 id="orgd0dac51">Solution</h4>
<div class="outline-text-4" id="text-orgd0dac51">
<p>
We already know that the quantum operation
</p>

<p>
\[
  \calE(\rho) = \frac{1}{2} I
\]
</p>

<p>
is the depolarizing channel with \(p=1\). By (8.102) this is equal to
</p>

<p>
\[
  \calE(\rho) = \frac{1}{4} (I\rho I + X\rho X + Y\rho Y + Z\rho Z) .
\]
</p>

<p>
Hence the relevant operation elements are
</p>

<p>
\[
  \left\{\frac{1}{2}I, \frac{1}{2}X, \frac{1}{2}Y, \frac{1}{2}Z \right\} .
\]
</p>
</div>
</div>
</div>

<div id="outline-container-org315c3a7" class="outline-3">
<h3 id="org315c3a7">Exercise 10.12</h3>
<div class="outline-text-3" id="text-org315c3a7">
<p>
Show that the fidelity between the state \(\ket{0}\) and \(\calE(\proj{0})\) is \(\sqrt{1-2p/3}\)
and use this to argue that the minimum fidelity for the depolarizing channel is
\(\sqrt{1-2p/3}\).
</p>
</div>

<div id="outline-container-orgaee1894" class="outline-4">
<h4 id="orgaee1894">Solution 1</h4>
<div class="outline-text-4" id="text-orgaee1894">
<p>
Let us follow the hint of the book.
</p>

<p>
\[
  F(\ket{0}, \calE(\proj{0}))
  = \sqrt{(1-p) + \frac{p}{3}(\bra{0}X\ket{0}^2 + \bra{0}Y\ket{0}^2 + \bra{0}Z\ket{0}^2)}
  = \sqrt{(1-p) + \frac{p}{3}}
  = \sqrt{1-\frac{2p}{3}} .
\]
</p>

<p>
Let \(\ket{\psi}\) be an arbitrary state and \(U\) be a unitary operator such that
\(\ket{\psi}=U\ket{0}\). Then
</p>

<p>
\[
  F(\ket{\psi}, \calE(\proj{\psi})) = F(U\ket{0}, U\calE(\proj{0})U^\dagger)
  = F(\ket{0}, \calE(\proj{0})) = \sqrt{1-\frac{2p}{3}} .
\]
</p>

<p>
In the second equality we used that the fidelity is invariant under unitary transformations.
</p>
</div>
</div>

<div id="outline-container-org5f62853" class="outline-4">
<h4 id="org5f62853">Solution 2</h4>
<div class="outline-text-4" id="text-org5f62853">
<p>
We could also prove the claim by using an alternative formula for the depolarizing channel:
</p>

<p>
\[
  \calE(\rho) = \frac{2p}{3} I + \left(1 - \frac{4p}{3}\right) \rho .
\]
</p>

<p>
(compare equations (8.100) and (8.102).) Hence
</p>

<p>
\[
  F(\ket{\psi}, \calE(\proj{\psi})) = \sqrt{\frac{2p}{3} + \left(1 - \frac{4p}{3}\right)}
  = \sqrt{1-\frac{2p}{3}} .
\]
</p>
</div>
</div>

<div id="outline-container-orgb7084f9" class="outline-4">
<h4 id="orgb7084f9">Solution 3</h4>
<div class="outline-text-4" id="text-orgb7084f9">
<p>
Yet another approach first calculates
</p>

<p>
\[
  F(\ket{\psi}, \calE(\proj{\psi}))
  = \sqrt{(1-p) + \frac{p}{3}(\bra{\psi}X\ket{\psi}^2 + \bra{\psi}Y\ket{\psi}^2 + \bra{\psi}Z\ket{\psi}^2)} .
\]
</p>

<p>
Recall the representation \(\proj{\psi}=2\inv(I+\vec{r}\cdot\vec{\sigma})\) of a qubit in
the bloch sphere (\(\abs{\vec{r}}=1\)). One can show that
</p>

<p>
\[
  \bra{\psi}Z\ket{\psi} = r_z
\]
</p>

<p>
and analogous formulas for \(r_x\) and \(r_y\). Hence
</p>

<p>
\[
  F(\ket{\psi}, \calE(\proj{\psi})) = \sqrt{(1-p) + \frac{p}{3}\abs{\vec{r}}^2} = \sqrt{1-\frac{2p}{3}} .
\]
</p>

<dl class="org-dl">
<dt>Remark</dt><dd><p>
To see e.g.
</p>

<p>
\[
  \bra{\psi}Z\ket{\psi} = r_z
  \]
</p>

<p>
observe that
</p>

<p>
\[
  \bra{\psi}Z\ket{\psi} = \trace{\proj{\psi}Z} = r_z .
  \]
</p>

<p>
In the last equality we used that the Pauli matrices (including \(I\)) are an orthogonal
set with respect to the Hilbert-Schmidt scalar product (with norm \(\sqrt{2}\) for each
base vector). The other two formulas for \(r_x\) and \(r_y\) follow along the same lines.
</p>

<p>
If you want to see the last equality directly, observe that (using \(S=\sqrt{Z}\))
</p>

<p>
\[
  \trace{\proj{\psi}Z} = \trace{S\proj{\psi}S}
  \]
</p>

<p>
and use \(SIS=Z\), \(SXS=\ii\?X\), \(SYS=\ii\?Y\), \(SZS=I\) (only the last term has a non-zero
trace).
</p></dd>
</dl>
</div>
</div>
</div>

<div id="outline-container-org3a421d6" class="outline-3">
<h3 id="org3a421d6">Exercise 10.13</h3>
<div class="outline-text-3" id="text-org3a421d6">
<p>
Show that the minimum fidelity \(F(\ket{\psi},\calE(\proj{\psi}))\) when \(\calE\) is the
amplitude damping channel with parameter \(\gamma\), is \(\sqrt{1-\gamma}\).
</p>
</div>

<div id="outline-container-org4047d85" class="outline-4">
<h4 id="org4047d85">Proof</h4>
<div class="outline-text-4" id="text-org4047d85">
<p>
Let us use sage to get an algebraic expression for \(F\). First define amplitude damping
</p>

<div class="org-src-container">
<pre class="src src-sage"><span class="org-variable-name">E0</span> <span class="org-operator">=</span> matrix.diagonal([1, sqrt(1<span class="org-operator">-</span>g)])
<span class="org-variable-name">E1</span> <span class="org-operator">=</span> matrix([[0, sqrt(g)], [0, 0]])
<span class="org-variable-name">AD</span> <span class="org-operator">=</span> make_operation([E0, E1])
</pre>
</div>

<p>
Now we can use this to compute \(F\):
</p>

<div class="org-src-container">
<pre class="src src-sage"><span class="org-variable-name">psi</span> <span class="org-operator">=</span> a<span class="org-operator">*</span>ket(<span class="org-string">'0'</span>) <span class="org-operator">+</span> b<span class="org-operator">*</span>ket(<span class="org-string">'1'</span>)
<span class="org-variable-name">psi_mat</span> <span class="org-operator">=</span> matrix(psi).T
<span class="org-variable-name">rho</span> <span class="org-operator">=</span> AD(psi_mat<span class="org-operator">*</span>psi_mat.H).simplify_full()
(psi.conjugate() <span class="org-operator">*</span> rho <span class="org-operator">*</span> psi).simplify_full()
</pre>
</div>

<pre class="example">
2*a*b*sqrt(-g + 1)*conjugate(a)*conjugate(b) + a^2*conjugate(a)^2 + b^2*conjugate(b)^2 + (a*b*conjugate(a)*conjugate(b) - b^2*conjugate(b)^2)*g
</pre>


<p>
This looks a bit ugly so let us rewrite this:
</p>

<p>
\[
  F = \abs{a}^4 + \abs{b}^4 + \gamma(\abs{a}^2 \abs{b}^2 - \abs{b}^4) + 2\sqrt{1-\gamma}\, \abs{a}^2\abs{b}^2 .
\]
</p>

<p>
Substituting \(x=\abs{a}^2\) and \(y=\abs{b}^2\) this can be written as:
</p>

<p>
\[
  F = \sqrt{f(x,y)} = \sqrt{x^2 + y^2 + \gamma (xy - y^2) + 2\sqrt{1-\gamma} \, xy} ,
\]
</p>

<p>
under the constraint \(x+y=1\) and \(x,y\geq0\). Thus we have to solve a constrained
minimization problem. There are two possibilities. The first one is that the minimum
occurs at the boundaries of the feasible region. Therefore let us calculate
</p>

\begin{align*}
  f(1,0) &= 1 , \\
  f(0,1) &= 1 - \gamma .
\end{align*}

<p>
The second possibility is that the minimum occurs in the inside of the feasible region. In
that case we might try to find it by the method of Lagrange multipliers:
</p>

\begin{align*}
  \partial_x f(x, y) &= 2x + (\gamma + 2\sqrt{1-\gamma}) y = \lambda \cdot 1 , \\
  \partial_y f(x, y) &= 2(1-\gamma)y + (\gamma + 2\sqrt{1-\gamma}) x = \lambda \cdot 1 .
\end{align*}

<p>
This looks a bit complicated so let us change the strategy a bit by defining a
parameterization of the feasible region
</p>

<p>
\[
  g(s) = f(s,1-s) .
\]
</p>

<p>
Abbreviating \(\alpha=\gamma+2\sqrt{1-\gamma}\) we see that
</p>

\begin{align*}
  g'(s) &= \partial_x f(s,1-s) - \partial_y f(s,1-s) \\
  &= (\alpha + 2\gamma - 2) - 2(\gamma + \alpha - 2) s \\
  &=: c_0 - c_1 s .
\end{align*}

<p>
Observe that \(\alpha+\gamma\geq2\). Hence \(c_0,c_1\geq0\) which implies that there is a
\(s_0\geq0\) such that \(g\) is increasing for \(s\leq\?s_0\) and decreasing afterwards (note
also that \(s_0\) could be larger than \(1\)). Hence a local extremum can only be a local
maximum and the minimum is indeed obtained at the boundary:
</p>

<p>
\[
  f(0, 1) = g(0) = 1 - \gamma .
\]
</p>

<p>
Hence \(F_{\min}=\sqrt{1-\gamma}\) . QED.
</p>
</div>
</div>
</div>

<div id="outline-container-org2df9501" class="outline-3">
<h3 id="org2df9501">Exercise 10.14</h3>
<div class="outline-text-3" id="text-org2df9501">
<p>
Write an expression for a generator matrix encoding \(k\) bits using \(r\) repetitions for
each bit. This is an \([rk,k]\) linear code, and should have an \(rk\times\?k\) generator
matrix.
</p>
</div>

<div id="outline-container-exercise-10.14-solution" class="outline-4">
<h4 id="exercise-10.14-solution">Solution</h4>
<div class="outline-text-4" id="text-exercise-10.14-solution">
<p>
Let \(\mathbb{1}_r\in\?\BB^r\) be the vector containing just ones. A generator for this code
is given by the tensor product
</p>

<p>
\[
  G = I_k \otimes \mathbb{1}_r .
\]
</p>

<p>
This naturally reproduces the special cases \(r=3\), \(k\in\{1,2\}\) from the book.
</p>
</div>
</div>
</div>

<div id="outline-container-orgc8e7caf" class="outline-3">
<h3 id="orgc8e7caf">Exercise 10.15</h3>
<div class="outline-text-3" id="text-orgc8e7caf">
<p>
Show that adding one column of \(G\) to another results in a generator matrix generating the
same code.
</p>
</div>

<div id="outline-container-orga7c9103" class="outline-4">
<h4 id="orga7c9103">Proof</h4>
<div class="outline-text-4" id="text-orga7c9103">
<p>
Let \((e_j)\) be the standard basis vectors in \(\BB^k\). The code generated by \(G\) is just
the image \(C=G\BB^k\) of \(G\) which in turn is given by all linear combinations of
\((Ge_j)\). Let \(G'\) be the generator found by adding column \(k\) to column \(l\neq\?k\).
</p>

<p>
We have to show that \(C=G'\BB^k\). For this in turn it suffices to show that \((G'e_j)\)
spans \(C\). First of all observe that
</p>

<p>
\[
  Ge_j = G'e_j \text{ for } j \neq l .
\]
</p>

<p>
Hence it suffices to show that \(\{Ge_k,Ge_l\}\) spans the same space as
\(\{G'e_k,G'e_l\}\). Observe that
</p>

\begin{align*}
  G' e_l &= Ge_k + Ge_l , \\
  G e_l &= G'e_k + G'e_l .
\end{align*}

<p>
This shows the claim. QED.
</p>
</div>
</div>
</div>

<div id="outline-container-org3abb17c" class="outline-3">
<h3 id="org3abb17c">Exercise 10.16</h3>
<div class="outline-text-3" id="text-org3abb17c">
<p>
Show that adding one row of the parity check matrix to another does not change the
code. Using Gaussian elimination and swapping of bits it is therefore possible to assume
that the parity check matrix has the standard form \([A|I_{n-k}]\), where \(A\) is an
\((n-k)\times\?k\) matrix.
</p>
</div>

<div id="outline-container-org3fbf1eb" class="outline-4">
<h4 id="org3fbf1eb">Proof</h4>
<div class="outline-text-4" id="text-org3fbf1eb">
<p>
Recall that a code \(C\), in terms of a parity check matrix \(H\), is defined as
</p>

<p>
\[
  y \in C \Leftrightarrow \forall i: \sum_j H_{ij} y_j = 0 .
\]
</p>

<p>
Let \(H'\) be a matrix obtained from \(H\) by adding row \(k\) to row \(l\). Let \(C'\) be the code
defined by \(H'\). We have to show \(C'=C\). Let \(y\in\?C\). Then we have
</p>

<p>
\[
  \forall i\neq l: \sum_j H'_{ij} y_j = 0 .
\]
</p>

<p>
because for those \(i\) we have \(H'_{ij}=H_{ij}\). Moreover
</p>

<p>
\[
  \sum_j H'_{lj} y_j = \sum_j H_{kj} y_j + \sum_j H_{lj} y_j =  0 ,
\]
</p>

<p>
by definition of \(H'\). Hence \(y\in\?C'\). Since \(y\in\?C\) was arbitrary this shows
\(C\subseteq\?C'\). By symmetry we also have \(C'\subseteq\?C\). In fact, \(H\) can be obtained
from \(H'\) by adding row \(k\) to line \(l\) so the same reasoning applies to the reverse
inclusion. QED.
</p>
</div>
</div>
</div>

<div id="outline-container-org005dd7d" class="outline-3">
<h3 id="org005dd7d">Exercise 10.17</h3>
<div class="outline-text-3" id="text-org005dd7d">
<p>
Find a parity check matrix for the \([6,2]\) repetition code defined by the generator matrix in
(10.54).
</p>

\begin{bmatrix}
1 & 0 \\
1 & 0 \\
1 & 0 \\
0 & 1 \\
0 & 1 \\
0 & 1 \\
\end{bmatrix}
</div>

<div id="outline-container-org64fd978" class="outline-4">
<h4 id="org64fd978">Solution</h4>
<div class="outline-text-4" id="text-org64fd978">
<p>
Let \(G_1\) and \(H_1\) be the generator and parity check matrix for \(k=1\) bits (see equations
(10.53) and (10.58)). We have
</p>

<p>
\[
  G_2 = I_2 \otimes G_1 .
\]
</p>

<p>
(C.f. the <a href="#exercise-10.14-solution">solution</a> of exercise 10.14.) This suggests to define
</p>

<p>
\[
  H_2 = I_2 \otimes H_1 = \begin{bmatrix}
    1 & 1 & 0 & 0 & 0 & 0 \\
    0 & 1 & 1 & 0 & 0 & 0 \\
    0 & 0 & 0 & 1 & 1 & 0 \\
    0 & 0 & 0 & 0 & 1 & 1
  \?\end{bmatrix} .
\]
</p>

<p>
This clearly does the job. It makes sense to compare this to <a href="#exercise-10.18">exercise 10.18</a>.
</p>
</div>
</div>
</div>

<div id="outline-container-exercise-10.18" class="outline-3">
<h3 id="exercise-10.18">Exercise 10.18</h3>
<div class="outline-text-3" id="text-exercise-10.18">
<p>
Show that the parity check matrix \(H\) and generator matrix \(G\) for the same linear code
satisfy \(HG=0\).
</p>
</div>

<div id="outline-container-org5d486d2" class="outline-4">
<h4 id="org5d486d2">Proof</h4>
<div class="outline-text-4" id="text-org5d486d2">
<p>
Recall that a code \(C\) is just the image of the generator \(C=G\BB^k\). On the other hand it
can be defined as the kernel of the parity check matrix: \(C=\{y|Hy=0\}\). Since every code
word has the form \(y=Gx\) we see that \(HGx=0\) for every \(x\). Hence the claim follows. QED.
</p>
</div>
</div>
</div>

<div id="outline-container-orgcf4d047" class="outline-3">
<h3 id="orgcf4d047">Exercise 10.19</h3>
<div class="outline-text-3" id="text-orgcf4d047">
<p>
Suppose an \([n,k]\) linear code \(C\) has a parity check matrix of the form \(H=[A|I_{n-k}]\),
for some \((n-k)\times\?k\) matrix \(A\). Show that the corresponding generator matrix is
</p>

<p>
\[
  G = \left[ \begin{array}{c} I_k \\ \hline -A \end{array} \right]
\]
</p>

<p>
(Note that \(-A=A\) since we are working modulo 2; however, this equation also holds for
linear codes over more general ﬁelds than \(\ZZ_2\).)
</p>
</div>

<div id="outline-container-orge44c890" class="outline-4">
<h4 id="orge44c890">Solution</h4>
<div class="outline-text-4" id="text-orge44c890">
<p>
Clearly \(G\) has rank \(k\). Hence its images has the same dimension as the kernel of \(H\)
(which is \(k\)). We only have to verify that \(HG=0\) (c.f. <a href="#exercise-10.18">exercise 10.18</a>). But this is
easy:
</p>

<p>
\[
  HG = A I_k - I_{n-k} A = A - A = 0 .
\]
</p>
</div>
</div>
</div>

<div id="outline-container-exercise-10.20" class="outline-3">
<h3 id="exercise-10.20">Exercise 10.20</h3>
<div class="outline-text-3" id="text-exercise-10.20">
<p>
Let \(H\) be a parity check matrix such that any \(d-1\) columns are linearly independent, but
there exists a set of \(d\) linearly dependent columns. Show that the code defined by \(H\)
has distance \(d\).
</p>
</div>

<div id="outline-container-org0c795b8" class="outline-4">
<h4 id="org0c795b8">Proof</h4>
<div class="outline-text-4" id="text-org0c795b8">
<p>
Let us divide the proof into two parts. In part one we assume that \(H\) has \(d\) linearly
<i>dependent</i> columns. In part two we assume that every \(d-1\) columns are linearly
<i>independent</i>.
</p>

<dl class="org-dl">
<dt>Part 1</dt><dd><p>
Assume that \(H\) has \(d\) linearly <i>dependent</i> columns \(c_1,\ldots,c_d\). We want
to show that there exists a \(y\in\?C\) (i.e. \(y\in\BB^n\) such that \(Hy=0\)) with
\(\wt{y}\leq\?d\).
</p>

<p>
Linear dependence means that there exist coefficients \(\alpha_i\in\BB\) such that
</p>

<p>
\[
  0 = \sum_i \alpha_i c_i .
  \]
</p>

<p>
Without loss of generality we may assume that all \(\alpha_i\) are equal to \(1\). Otherwise
there would exist a subset of \(d'\?<\?d\) columns such that this is fulfilled.
</p>

<p>
Let \(J=\{i_1,\ldots,i_d\}\) be the indices of these columns in \(H\). Let \(y\in\BB^n\) be
such that \(y_i=1\) if \(i\in\?J\) and \(y_i=0\) otherwise. By construction we have \(\wt{y}=d\)
and \(Hy=0\). This shows the claim of part 1.
</p></dd>
<dt>Part 2</dt><dd><p>
Assume that every \(d-1\) columns are linearly <i>independent</i>. We have to show
that \(Hy=0\) implies \(\wt{y}\geq\?d\).
</p>

<p>
The assumption implies that every for every \(y\) with \(\wt{y}\leq\?d-1\) we have
\(Hy\neq0\). But this is equivalent to the claim.
</p></dd>
</dl>

<p>
Taking parts 1 and 2 together we see that \(d(C)=d\) is equivalent to: Any \(d-1\) columns of
\(H\) are linearly independent but there exist \(d\) columns which are linearly
dependent. QED.
</p>
</div>
</div>
</div>

<div id="outline-container-orgeb33287" class="outline-3">
<h3 id="orgeb33287">Exercise 10.21 (Singleton bound)</h3>
<div class="outline-text-3" id="text-orgeb33287">
<p>
Show that an \([n,k,d]\) code must satisfy \(n-k\geq\?d-1\).
</p>
</div>

<div id="outline-container-orgce2bcda" class="outline-4">
<h4 id="orgce2bcda">Proof</h4>
<div class="outline-text-4" id="text-orgce2bcda">
<p>
This follows directly from <a href="#exercise-10.20">exercise 10.20</a>. In fact, the parity check matrix
\(H\in\BB^{(n-k)\times\?n}\) of the code must have full rank \(n-k\) in order for the code
space to be \(k\)​-dimensional (otherwise it would be bigger and there could be no bijection
between the code words and the elements of \(\BB^k\)).
</p>

<p>
On the other hand, from \(d(C)=d\), using exercise 10.20, we see that the rank of \(H\) must
be at least \(d-1\). Hence \(n-k\geq\?d-1\). QED.
</p>
</div>
</div>
</div>

<div id="outline-container-org933d991" class="outline-3">
<h3 id="org933d991">Exercise 10.22</h3>
<div class="outline-text-3" id="text-org933d991">
<p>
Show that all Hamming codes have distance \(3\), and thus can correct an error on a single
bit. The Hamming codes are therefore \([2^r-1,2^r-r-1,3]\) codes.
</p>
</div>

<div id="outline-container-orgcc3c31f" class="outline-4">
<h4 id="orgcc3c31f">Proof</h4>
<div class="outline-text-4" id="text-orgcc3c31f">
<p>
The parity check matrix of the Hamming code is made of matrices with columns \(h_j\) being
the binary representation of \(j\) for \(j\in\{1,\ldots,2^r-1\}\). Hence
</p>

<p>
\[
  h_1 + h_2 = h_3 ,
\]
</p>

<p>
implying that the first three columns are linearly dependent. On the other hand any two
columns are linearly independent since
</p>

<p>
\[
  h_i + h_j = 0
\]
</p>

<p>
implies \(i=j\). Now the claim follows from <a href="#exercise-10.20">exercise 10.20</a>. QED.
</p>
</div>
</div>
</div>

<div id="outline-container-org67719ca" class="outline-3">
<h3 id="org67719ca">Exercise 10.23</h3>
<div class="outline-text-3" id="text-org67719ca">
<p>
Prove the Gilbert–Varshamov bound: Let \(\varepsilon\?>0\) and \(0\?<\delta\?<\?1/2\). There
exists an \([n,k,d]\) code such that
</p>

<p>
\[
  R \geq 1 - H(\delta) - \varepsilon ,
\]
</p>

<p>
where \(R=k/n\) is the <i>rate</i> of the code, \(\delta\leq(d-1)/n\), and
\(H(x)=-x\log_2(x)-(1-x)\log_2(x)\). In other words, for a given relative distance
\(\delta\?<\?1/2\) there is always a corresponding code whose transmission rate is not too
bad.
</p>

<dl class="org-dl">
<dt>Remark</dt><dd><ul class="org-ul">
<li>For \(\varepsilon=0\) this is equivalent to the orginial exercise. The proof <i>suggests</i>
that it is necessary to have \(\varepsilon\?>\?0\). Moreover the <a href="https://en.wikipedia.org/wiki/Gilbert%E2%80%93Varshamov_bound_for_linear_codes">wikipedia</a> version of
the theorem also has it. Hence I believe this is just an error in the exercise.</li>
<li>Another reason why I reformulated the statement is the following: In the original
statement I originally imagined \(t\) to be fixed. But then if you only consider large
\(n\) this isn't really useful since a code with very many bits has also a large "attack
surface" for errors. So it is more natural to consider a relative quantity instead.</li>
<li>The authors write "The proof of the Gilbert–Varshamov bound is quite simple &#x2026;". I do
not share this assessment. Maybe my solution is more complicated than it should
be. But in my opinion most exercises in part III of the book (so far) are much easier.</li>
</ul></dd>
</dl>
</div>

<div id="outline-container-org0a05cf0" class="outline-4">
<h4 id="org0a05cf0">Proof</h4>
<div class="outline-text-4" id="text-org0a05cf0">
<p>
In this proof we use the so called <a href="https://en.wikipedia.org/wiki/Probabilistic_method">probabilistic method</a> which seems to be the standard way
to prove this bound (see e.g. <a href="https://en.wikipedia.org/wiki/Gilbert%E2%80%93Varshamov_bound_for_linear_codes">wikipedia</a> for the general case of linear codes over finite
fields).
</p>

<p>
Let \(n\geq\?k\) to be fixed later. The main idea is to consider a uniform probability
distribution over \(\BB^{n\times\?k}\) and draw random generators \(G\) from it (let us
denote the generated code by \(C\)). The idea is to show that there is a non-zero
probability that the drawn generator generates a code with the desired properties.
</p>

<p>
Note one subtle thing here: the generator must be injective in order to generate a
\(k\)​-dimensional code. Therefore consider the following lemma.
</p>

<dl class="org-dl">
<dt>Lemma</dt><dd>For all \(n\geq\?k\) let \(P(n,k)\) be the probability that a uniformly at random
drawn matrix \(G\in\BB^{n\times\?k}\) has rank \(k\). There exists a constant \(P_\infty\?>\?0\)
(which does not depend on \(n\) or \(k\)) such that \(P(n,k)\geq\?P_\infty\).
<dl class="org-dl">
<dt>Proof</dt><dd><p>
Clearly \(P(n,k)\geq\?P(k,k)\). So we only have to consider the case \(n=k\). For
\(l\leq\?k\) let \(P_l\) be the probability that a random matrix from \(\BB^{l\times\?k}\)
has rank \(l\). Clearly
</p>

<p>
\[ P_1 = (2^k - 1) / 2^k = 1 - 2^{-k} \]
</p>

<p>
because there is only one vector (the zero vector) which leads to a single rowed
rank-zero matrix. Observe that
</p>

<p>
\[ P_{l+1} = P_l \cdot (2^k - 2^l) /2^k . \]
</p>

<p>
This is because in order to have \(l+1\) independent rows you first need \(l\) independent
rows and the last row has to be outside the \(l\)​-dimensional subspace (with \(2^l\)
elements) of the first \(l\) rows. Hence
</p>

<p>
\[ P(k,k) = P_k = \prod_{j=1}^{k} (1 - 2^{-j}) \geq \prod_{j=1}^{\infty} (1 - 2^{-j}) =: P_\infty > 0 . \]
</p>

<p>
QED.
</p></dd>
</dl></dd>
</dl>

<p>
Our goal is to prove that for sufficiently large \(n\) (considering also non-injective \(G\))
</p>

<p>
<a id="org66b3035"></a>
\[
  \prob{d(C)\geq d} > P_\infty
\]
</p>

<p>
because then
</p>

<p>
\[
  \prob{d(C)\geq d \text{ and } \rank{G}=k} \geq  \prob{d(C)\geq d} - P_\infty > 0 .
\]
</p>

<p>
which proves the claim. Let us estimate the probability that the distance of the code is
<i>not</i> at least \(d\). In order to show the above <a href="#org66b3035">bound</a> it suffices to show that the
following can be made arbitrary small (for large \(n\)):
</p>

<p>
<a id="org8daf8c7"></a>
\[
  \prob{d(C)\leq d-1} \leq \sum_{x\in\BB^k\backslash\{0\}} \prob{\wt{Gx} \leq d-1} = \frac{V_d}{2^{n-k}} .
\]
</p>

<p>
The first inequality follows from the fact that the event \(d(C)\leq\?d-1\) is equivalent to
the event that at least one of the code words has distance at most \(d-1\) (also use the
sub-additivity of probabilities). For the equality on the right let us first note that for
each \(x\) the code word \(Gx\) is uniformly distributed (each column of \(G\) is uniformly
distrubuted and so is each sum of columns). Hence \(\prob{\wt{Gx}\leq\?d-1}=V_d/2^n\) where
</p>

<p>
\[
  V_d = \sum_{i=0}^{d-1} \binom{n}{i}
\]
</p>

<p>
is the number of potential code words with weight at most \(d-1\).
</p>

<dl class="org-dl">
<dt>Lemma</dt><dd>\(V_d\leq2^{H(\delta)n}\) if \(\delta\leq1/2\), where \(\delta=(d-1)/n\).
<dl class="org-dl">
<dt>Remark</dt><dd>A reverse inequality is is also true: \(V_d\geq2^{H(\delta)n+o(n)}\). This can
be seen from Stirlings formula. Actually I knew this reverse inequality already since
I solved exercise 6.14, see e.g. <a href="chapter_6.html#org4ad963a">here</a> to get an idea for the proof. This is the reason
I found it natural to connect \(V_d\) to the entropy. I was a bit surprised to find out
that the \(V_d\leq\ldots\) inequality has such a clean form (no Landau notation).</dd>
<dt>Proof</dt><dd><p>
The claim follows from this:
</p>

<p>
\[
      \sum_{i=0}^{d-1} \binom{n}{i} 2^{-H(\delta)n}
      = \sum_{i=0}^{d-1} \binom{n}{i} \delta^{d-1} (1-\delta)^{n-d+1}
      \leq \sum_{i=0}^{d-1} \binom{n}{i} \delta^j (1-\delta)^{j-d}
      = (\delta + (1 - \delta))^n
      = 1 .
    \]
</p>

<p>
For the inequality in the middle it is important to have \(\delta\leq1/2\). The last
equality is just the binomial formula. QED.
</p></dd>
</dl></dd>
</dl>

<p>
Using the lemma in <a href="#org8daf8c7">the estimate</a> for the probability that \(d(C)\leq\?d-1\) we get
</p>

<p>
\[
  P := \prob{d(C)\leq d-1} \leq \left[\frac{2^{H(\delta)+O(n\inv)}}{2^{1-R}}\right]^n
  = \left[\frac{2^{R+o(1)}}{2^{1-H(\delta)}}\right]^n .
\]
</p>

<p>
Here we choose \(d\) minimal so that \(\delta\leq(d-1)/n\) holds. Hence \(\delta=(d-1+O(1))/n\)
which explains the \(O(n\inv)\) in the inequalities above.
</p>

<p>
Let us suppose we can choose \(R\) such that
</p>

\begin{align*}
  R &\geq 1 - H(\delta) - \varepsilon , \\
  R + o(1) &\leq 1 - H(\delta) - \varepsilon/2 , \\
\end{align*}

<p>
Then we would have \(P\leq2^{-\varepsilon\?n/2}\) which is arbitrary small if \(n\) is large
enough - which proves the <a href="#org66b3035">desired bound</a>. But since \(R=k/n\) this is indeed possible if we
choose \(n\) large enough and \(k\) appropriately. QED.
</p>
</div>
</div>
</div>

<div id="outline-container-org0f06680" class="outline-3">
<h3 id="org0f06680">Exercise 10.24</h3>
<div class="outline-text-3" id="text-org0f06680">
<p>
Show that a code with generator matrix G is weakly self-dual if and only if \(G^TG=0\).
</p>
</div>

<div id="outline-container-org122d3c1" class="outline-4">
<h4 id="org122d3c1">Proof</h4>
<div class="outline-text-4" id="text-org122d3c1">
<p>
Weakly self dual means \(C\subseteq\?C^{\bot}\). Hence
</p>

<p>
\[
  H^{\bot} G = 0 ,
\]
</p>

<p>
where \(G\) is the generator of \(C\) and \(H^\bot\) the parity check matrix of \(C^\bot\). But
a parity check matrix of \(C^\bot\) is \(H^\bot=G^T\). QED.
</p>
</div>
</div>
</div>

<div id="outline-container-org4d5672d" class="outline-3">
<h3 id="org4d5672d">Exercise 10.25</h3>
<div class="outline-text-3" id="text-org4d5672d">
<p>
Let \(C\) be a linear code. Show that if \(x\in\?C^\bot\) then
\(\sum_{y\in\?C}(-1)^{x\cdot\?y}=\abs{C}\), while if \(x\notin\?C^\bot\) then
\(\sum_{y\in\?C}(-1)^{x\cdot\?y}=0\).
</p>
</div>

<div id="outline-container-org9d62c87" class="outline-4">
<h4 id="org9d62c87">Proof</h4>
<div class="outline-text-4" id="text-org9d62c87">
<p>
By definition of dual codes we have \(x\cdot\?y=0\) if \(x\in\?C^\bot\) and \(y\in\?C\). Hence,
in that case
</p>

<p>
\[
  \sum_{y\in\?C}(-1)^{x\cdot y} = \sum_{y\in\?C} 1 = \abs{C}
\]
</p>

<p>
Assume now that \(x\in\?C^\bot\). Hence there exists a \(\tilde{y}\in\?C\) such that
\(x\cdot\?\tilde{y}=1\). Let us decompose \(C=C'\oplus\?\tilde{y}\BB\). Hence
</p>

<p>
\[
  \sum_{y\in C}(-1)^{x\cdot y}
  = \sum_{y'\in C'} \sum_{\alpha=0}^1 (-1)^{y'\cdot x + \alpha\tilde{y}\cdot x}
  = \sum_{y'\in C'} 0
  = 0 .
\]
</p>

<p>
QED.
</p>
</div>
</div>
</div>

<div id="outline-container-orgc259128" class="outline-3">
<h3 id="orgc259128">Exercise 10.26</h3>
<div class="outline-text-3" id="text-orgc259128">
<p>
Suppose \(H\) is a parity check matrix. Explain how to compute the transformation
\(\ket{x}\ket{0}\mapsto\ket{x}\ket{Hx}\) using a circuit composed entirely of <code>CNOT</code> gates.
</p>
</div>

<div id="outline-container-org678a905" class="outline-4">
<h4 id="org678a905">Solution</h4>
<div class="outline-text-4" id="text-org678a905">
<p>
Let us explain it on the specific example of the \([3,1]\) repetition code:
</p>

<p>
\[
  H = \begin{bmatrix} 1 & 1 & 0 \\ 0 & 1 & 1 \end{bmatrix} .
\]
</p>

<p>
A corresponding circuit would be
</p>

<pre class="example" id="orga49f9ea">

a_0: ──■─────────────────
       │
a_1: ──┼────■────■───────
       │    │    │
a_2: ──┼────┼────┼────■──
     ┌─┴─┐┌─┴─┐  │    │
b_0: ┤ X ├┤ X ├──┼────┼──
     └───┘└───┘┌─┴─┐┌─┴─┐
b_1: ──────────┤ X ├┤ X ├
               └───┘└───┘
</pre>

<p>
The idea is that for each \((i,j)\) with \(H_{ij}=1\) we have a <code>CNOT</code> with control at target
\(b_i\) and control \(a_j\).
</p>
</div>
</div>
</div>

<div id="outline-container-org0b44888" class="outline-3">
<h3 id="org0b44888">Exercise 10.27</h3>
<div class="outline-text-3" id="text-org0b44888">
<p>
Show that the codes defined by
</p>

<p>
\[
  \ket{x+C_2} = \frac{1}{\sqrt{\abs{C_2}}} \sum_{y\in\?C_2} (-1)^{u\cdot y} \ket{x+y+v}
\]
</p>

<p>
and parameterized by \(u\) and \(v\) are equivalent to \(\mathrm{CSS}(C_1,C_2)\) in the sense
that they have the same error-correcting properties. These codes, which we’ll refer to as
\(\mathrm{CSS}_{u,v}(C_1,C_2)\), will be useful later in our study of quantum key
distribution, in Section 12.6.5.
</p>
</div>

<div id="outline-container-org115b7d9" class="outline-4">
<h4 id="org115b7d9">Sketch of a solution</h4>
<div class="outline-text-4" id="text-org115b7d9">
<p>
By using \(X\), \(Z\), and Hadamard gates one can unitarily transform the code into the
following form
</p>

<p>
\[
  \ket{x+C_2} = \frac{1}{\sqrt{\abs{C_2}}} \sum_{y\in\?C_2} (-1)^{u\cdot x} \ket{x+y}
  = (-1)^{u\cdot x} \frac{1}{\sqrt{\abs{C_2}}} \sum_{y\in\?C_2} \ket{x+y} .
\]
</p>

<p>
Basically we introduce errors \(e_1=v\) and \(e_2=u\) on purpose to accomplish that. Now it is
not hard to verify that the factor \((-1)^{u\cdot\?x}\) does not interfere with the analysis
from the book.
</p>
</div>
</div>
</div>

<div id="outline-container-orgee48312" class="outline-3">
<h3 id="orgee48312">Exercise 10.28</h3>
<div class="outline-text-3" id="text-orgee48312">
<p>
Verify that the transpose of the matrix in (10.77) is the generator of the \([7,4,3]\)
Hamming code.
</p>
</div>

<div id="outline-container-org5c70072" class="outline-4">
<h4 id="org5c70072">Solution</h4>
<div class="outline-text-4" id="text-org5c70072">
<p>
The claim follows essentially from the following calculation:
</p>

<div class="org-src-container">
<pre class="src src-sage"><span class="org-comment-delimiter"># </span><span class="org-comment">Standard parity check matrix for the [7,3] Hamming code:</span>
<span class="org-variable-name">H</span> <span class="org-operator">=</span> matrix(GF(2), [
    [0, 0, 0, 1, 1, 1, 1],
    [0, 1, 1, 0, 0, 1, 1],
    [1, 0, 1, 0, 1, 0, 1],
])

<span class="org-comment-delimiter"># </span><span class="org-comment">We want to check that this is indeed a generator:</span>
<span class="org-variable-name">G</span> <span class="org-operator">=</span> matrix(GF(2), [
    [1, 0, 0, 0, 0, 1, 1],
    [0, 1, 0, 0, 1, 0, 1],
    [0, 0, 1, 0, 1, 1, 0],
    [0, 0, 0, 1, 1, 1, 1],
]).T

<span class="org-keyword">assert</span> H<span class="org-operator">*</span>G <span class="org-operator">==</span> matrix.zero(3, 4)
<span class="org-string">"PASSED"</span>
</pre>
</div>

<pre class="example">
'PASSED'
</pre>


<p>
One important thing to note is that \(G\) has full rank (obviously). Hence \(HG=0\) is
sufficient to prove \(G\) to be a generator of the \([7,4]\) Hamming code.
</p>
</div>
</div>
</div>

<div id="outline-container-org93d22c4" class="outline-3">
<h3 id="org93d22c4">Exercise 10.29</h3>
<div class="outline-text-3" id="text-org93d22c4">
<p>
Show that an arbitrary linear combination of any two elements of \(V_S\) is also in
\(V_S\). Therefore, \(V_S\) is a subspace of the \(n\) qubit state space. Show that \(V_S\) is the
intersection of the subspaces fixed by each operator in \(S\) (that is, the eigenvalue one
eigenspaces of elements of \(S\)).
</p>
</div>

<div id="outline-container-orgfc2c5a9" class="outline-4">
<h4 id="orgfc2c5a9">Solution</h4>
<div class="outline-text-4" id="text-orgfc2c5a9">
<p>
We have
</p>

\begin{align*}
  V_S &= \{v | \forall g\in S: gv = v\} \\
  &= \bigcap_{g\in S} \{v | gv = v\} \\
  &= \bigcap_{g\in S} \ker(g-I) .
\end{align*}

<p>
Since the kernel of a linear operator is a linear subspace and since the intersection of
linear subscpaces is again linear the claim follows.
</p>
</div>
</div>
</div>

<div id="outline-container-org206da1a" class="outline-3">
<h3 id="org206da1a">Exercise 10.30</h3>
<div class="outline-text-3" id="text-org206da1a">
<p>
Show that \(-I\notin\?S\) implies \(\pm\ii\?I\notin\?S\).
</p>
</div>

<div id="outline-container-org4237c41" class="outline-4">
<h4 id="org4237c41">Proof</h4>
<div class="outline-text-4" id="text-org4237c41">
<p>
Recall the elementary logical rule that \(\neg\?a\Rightarrow\neg\?b\) is equivalent to
\(a\Leftarrow\?b\). Hence, we have to prove that \(\pm\ii\?I\in\?S\) implies \(-I\in\?S\). But
this is obvious! QED.
</p>
</div>
</div>
</div>

<div id="outline-container-org675a973" class="outline-3">
<h3 id="org675a973">Exercise 10.31</h3>
<div class="outline-text-3" id="text-org675a973">
<p>
Suppose \(S\) is a subgroup of \(G_n\) generated by elements \(g_1,\ldots,g_l\). Show that all
the elements of \(S\) commute if and only if \(g_i\) and \(g_j\) commute for each pair \(i\), \(j\).
</p>

<dl class="org-dl">
<dt>Remark</dt><dd>The claim remains true if we replace \(G_n\) by any group. This follows from the
proof below.</dd>
</dl>
</div>

<div id="outline-container-org2944393" class="outline-4">
<h4 id="org2944393">Proof</h4>
<div class="outline-text-4" id="text-org2944393">
<p>
One direction of the implication is obvious. Therefore let us just prove the other
direction.
</p>

<p>
Assume that all \(g_i\) and \(g_j\) commute. One can show that every \(g\in\?S\) can be
represented (not necessarily uniquely) as
</p>

<p>
\[
  g = \prod_{j=1}^l g_j^{x_j}
\]
</p>

<p>
where \(x_j\in\ZZ\), and that inversion and products are represented as follows
</p>

\begin{align*}
  g\inv &= \prod_{j=1}^l g_j^{-x_j} \\
  g\cdot h &= \prod_{j=1}^l g_j^{x_j+y_j}
\end{align*}

<p>
where \(h=\prod_{j=1}^lg_j^{y_j}\). More precisely: if we already know that \(g\) and \(h\) have
such a representation then from commutativity the representations for \(g\inv\) and \(gh\)
easily follow. Now observe that the set \(S'\) of \(g\) which can be represented like this
must be contained in \(S\) (because the \((g_j)\) generate \(S\)). But we have just seen that
making products and inverses doesn't take us outside of \(S'\). Hence \(S'=S\) as claimed.
</p>

<p>
But now it is obvious that \(S\) is abelian because the standard representations of \(gh\) and
\(hg\) are the same. QED.
</p>

<dl class="org-dl">
<dt>Remark</dt><dd>Above we used the fact that if \(g_i\) and \(g_j\) commute then also \(g_i^x\) and
\(g_j^y\) commute for any \(x,y\in\ZZ\). This is clear for non-negative \(x\), \(y\). The
general case follows from the fact that \(g_j\) and \(g_i\inv\) commute. In fact, let
\(a=g_j\inv\?g_i\) and \(b=g_ig_j\inv\). Since \(g_i\) and \(g_j\) commute we have
\(g_ja=g_jb\). But this implies \(a=b\).</dd>
</dl>
</div>
</div>
</div>

<div id="outline-container-orgff4d3bf" class="outline-3">
<h3 id="orgff4d3bf">Exercise 10.32</h3>
<div class="outline-text-3" id="text-orgff4d3bf">
<p>
Verify that the generators in Figure 10.6 stabilize the codewords for the Steane code, as
described in Section 10.4.2.
</p>
</div>

<div id="outline-container-exercise-10.32-solution" class="outline-4">
<h4 id="exercise-10.32-solution">Solution</h4>
<div class="outline-text-4" id="text-exercise-10.32-solution">
<p>
Note that there is a <a href="#chapter-10-css-as-stabilizer">subtle error</a> in the paragraph right before the exercise. Moreover I
think it makes sense to prove a more <a href="#orgf0bf142">general theorem</a> given in the intro section of this
site. So let us do this.
</p>

<p>
An element of the CSS code looks like this
</p>

<p>
\[
  \ket{x+C_2} = \frac{1}{\sqrt{\abs{C_2}}} \sum_{y\in C_2} \ket{x + y} ,
\]
</p>

<p>
where \(x\in\?C_1\). Recall that \(C_2\subseteq\?C_1\). Hence all the \(x+y\) above also belong
to \(C_1\). Hence \(A(x+y)=0\). Hence for all \(i=1..(n-k_1)\) we have
</p>

\begin{align*}
  g_{k_2+i}\ket{x+C_2} &= \frac{1}{\sqrt{\abs{C_2}}} \sum_{y\in C_2} \bigotimes_{j=1}^n Z^{A_{ij}} \ket{x + y} \\
  &= \frac{1}{\sqrt{\abs{C_2}}} \sum_{y\in C_2} \underbrace{(-1)^{A_i\cdot(x+y)}}_{= 1} \ket{x + y} \\
  &= \ket{x+C_2} .
\end{align*}

<p>
(I write \(A_i\) for the \(i\)​-th row of \(A\).) Hence the \(g_{k_2+1}\) stabilize the code. To
prove the same statement for \(g_i\) with \(i=1..k_2\) we switch to the X-basis by applying
the Hadamard transform to the state. Note that this transform changes the \(X\) in the
definition of the \(g_i\) to \(Z\). As in section 10.4.2 we see that
</p>

<p>
\[
  H^{\otimes n} \ket{x+C_2} = \sqrt{\frac{\abs{C_2}}{2^n}} \sum_{z\in C_2^\top} (-1)^{x\cdot z} \ket{z} .
\]
</p>

<p>
Hence we see in a similar way as in the first part that
</p>

\begin{align*}
  H^{\otimes n} g_{i}\ket{x+C_2}
  &= H^{\otimes n} g_{i} H^{\otimes n}H^{\otimes n} \ket{x+C_2} \\
  &= \sqrt{\frac{\abs{C_2}}{2^n}} \sum_{z\in C_2^\top} (-1)^{x\cdot z} \bigotimes_{j=1}^n Z^{B_{ij}} \ket{z} \\
  &= \sqrt{\frac{\abs{C_2}}{2^n}} \sum_{z\in C_2^\top} (-1)^{x\cdot z} \underbrace{(-1)^{B_i\cdot z}}_{= 1} \ket{z} \\
  &= H^{\otimes n} \ket{x+C_2} .
\end{align*}

<p>
By dividing away the Hadamard transform we see that the \(g_i\) for \(i=1..k_2\) stabilize the
CSS code too. This already shows the claim of the exercise.
</p>

<p>
In order to finish the proof of the theorem we need to show that the given generators do
not stabilize an even larger space than the desired CSS code. But this is basically a
dimensionality argument. By design the CSS code has dimension \(2^{k}\) where
\(k=k_1-k_2\). On the other hand under certain conditions a stabilizer code with \(n-k\)
generators has the same dimension. Said conditions are that \(-I\notin\?S\) and that the
generators commute (Proposition 10.5). The latter is clear from the form of the
generators. The former follows from the fact that the parity check matrices have full
rank. QED.
</p>
</div>
</div>
</div>

<div id="outline-container-exercise-10.33" class="outline-3">
<h3 id="exercise-10.33">Exercise 10.33</h3>
<div class="outline-text-3" id="text-exercise-10.33">
<p>
Show that \(g\) and \(g'\) commute if and only if \(r(g)\Lambda\?r(g')^T=0\). (In the check
matrix representation, arithmetic is done modulo two.)
</p>
</div>

<div id="outline-container-orgdf24fc4" class="outline-4">
<h4 id="orgdf24fc4">Solution</h4>
<div class="outline-text-4" id="text-orgdf24fc4">
<p>
Let \(\beta=r(g)\Lambda\?r(g')^T\) (which is an element of \(\BB\)). We will show that
</p>

<p>
\[
  gg' = (-1)^\beta g'g ,
\]
</p>

<p>
which implies the claim of the exercise. Let us write
</p>

\begin{align*}
  g &= \alpha \bigotimes_{j=1}^n N_j , \\
  g' &= \alpha' \bigotimes_{j=1}^n N'_j ,
\end{align*}

<p>
where \(N_j,N'_j\in\{I,X,Y,Z\}\), and \(\alpha,\alpha'\in\{1,-1,\ii,-\ii\}\). Without loss of
generality we may assume \(\alpha=\alpha'=1\). Moreover let us split \(r=r_x\oplus\?r_z\)
where \(r_x\) is responsible for the first \(n\) bits and \(r_z\) for the last \(n\) bits. We have
</p>

<p>
\[
  \beta = r_x(g) \cdot r_z(g') + r_z(g) \cdot r_x(g')
  = \sum_{j=1}^n \underbrace{r_x(N_j) \cdot r_z(N'_j) + r_z(N_j) \cdot r_x(N'_j)}_{=:\beta_j} .
\]
</p>

<p>
It is not hard to verify that \(N_jN'_j=(-1)^{\beta_j}N'_jN_j\). Hence
\(gg'=(-1)^{\sum_j\beta_j}g'g\). QED.
</p>
</div>
</div>
</div>

<div id="outline-container-orgd6210ae" class="outline-3">
<h3 id="orgd6210ae">Exercise 10.34</h3>
<div class="outline-text-3" id="text-orgd6210ae">
<p>
Let \(S=\langle\?g_1,\ldots,g_l\rangle\). Show that \(-I\) is not an element of \(S\) if and
only if \(g_j^2=I\) for all \(j\), and \(g_j\neq-I\) for all \(j\).
</p>

<dl class="org-dl">
<dt>Remark</dt><dd>The implication \(-I\notin\?S\Rightarrow\ldots\) is just <a href="#exercise-10.35">exercise 10.35</a>. The
other direction is actually wrong.</dd>
</dl>
</div>

<div id="outline-container-org73e44d9" class="outline-4">
<h4 id="org73e44d9">Counterexamples</h4>
<div class="outline-text-4" id="text-org73e44d9">
<p>
The claim of the exercise is wrong. To see this consider the following counterexample. Let
</p>

<p>
\[
  g_1 = X, \; g_2 = Z .
\]
</p>

<p>
Clearly \(g_j^2=I\) for all \(j\), and \(g_j\neq-I\) for all \(j\). On the other hand
\(XZXZ=-ZZ=-I\) and hence \(-I\in\?S\). One might wonder if the claim becomes true if one
assumes that the \(g_j\) commute (and are independent). But this is also not true as the
following counterexample shows:
</p>

<p>
\[
  g_1 = Z, \; g_2 = -Z .
\]
</p>
</div>
</div>
</div>

<div id="outline-container-exercise-10.35" class="outline-3">
<h3 id="exercise-10.35">Exercise 10.35</h3>
<div class="outline-text-3" id="text-exercise-10.35">
<p>
Let \(S\) be a subgroup of \(G_n\) such that \(-I\) is not an element of \(S\). Show that \(g^2=I\)
for all \(g\in\?S\), and thus \(g^\dagger=g\).
</p>

<dl class="org-dl">
<dt>Remark</dt><dd>The original exercise contained the additional implication that \(g\in\?-I\) for
all \(g\in\?S\) but this is a slightly too trivial conclusion if you already assume that
\(-I\notin\?S\) - in my opinion.</dd>
</dl>
</div>

<div id="outline-container-org8d83563" class="outline-4">
<h4 id="org8d83563">Proof</h4>
<div class="outline-text-4" id="text-org8d83563">
<p>
Recall that any \(g\in\?G_n\) has the form
</p>

\begin{align*}
  g &= \alpha \bigotimes_{j=1}^n N_j ,
\end{align*}

<p>
where \(N_j\in\{I,X,Y,Z\}\), and \(\alpha\in\{1,-1,\ii,-\ii\}\). Hence
\(g^2=\alpha^2I=\pm\?I\). By \(-I\notin\?S\) we must have \(g^2=I\) as desired. QED.
</p>
</div>
</div>
</div>
</div>
<footer class="footer"><p>Made by <a href="https://github.com/rainij">Reinhard Stahn</a> with <a href="https://www.gnu.org/software/emacs/">Emacs</a> 29.1.90 (<a href="https://orgmode.org">Org</a> mode 9.6.10)</p><p>Find the source code on <a href="https://github.com/rainij/solutions-qcqi-nielsen-chuang">Github</a></p></footer></body></html>